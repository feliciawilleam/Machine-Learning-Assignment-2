{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-Keras_Sydney prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciawilleam/Machine-Learning-Assignment-2/blob/master/Neural_Keras_Sydney_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQL0umj0cS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Link to Google Drive File\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDW23VopqQ3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1wgGUzBD8wA1LNMCg4gwhrTvnIH8yGTBQ' # The shareable link"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PQH-WYqqsXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe95f12e-d7f6-4052-ffcb-6502baf9492c"
      },
      "source": [
        "fluff, id = link.split('=')\n",
        "print (id)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1wgGUzBD8wA1LNMCg4gwhrTvnIH8yGTBQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emujOYnxqd8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1154
        },
        "outputId": "a63544f0-0bcc-444f-81af-301fe5392c66"
      },
      "source": [
        "#data nameis df\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('weatherAUS.csv')  \n",
        "df = pd.read_csv('weatherAUS.csv')\n",
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
            "0       2008-12-01   Albury     13.4  ...         No      0.0            No\n",
            "1       2008-12-02   Albury      7.4  ...         No      0.0            No\n",
            "2       2008-12-03   Albury     12.9  ...         No      0.0            No\n",
            "3       2008-12-04   Albury      9.2  ...         No      1.0            No\n",
            "4       2008-12-05   Albury     17.5  ...         No      0.2            No\n",
            "5       2008-12-06   Albury     14.6  ...         No      0.0            No\n",
            "6       2008-12-07   Albury     14.3  ...         No      0.0            No\n",
            "7       2008-12-08   Albury      7.7  ...         No      0.0            No\n",
            "8       2008-12-09   Albury      9.7  ...         No      1.4           Yes\n",
            "9       2008-12-10   Albury     13.1  ...        Yes      0.0            No\n",
            "10      2008-12-11   Albury     13.4  ...         No      2.2           Yes\n",
            "11      2008-12-12   Albury     15.9  ...        Yes     15.6           Yes\n",
            "12      2008-12-13   Albury     15.9  ...        Yes      3.6           Yes\n",
            "13      2008-12-14   Albury     12.6  ...        Yes      0.0            No\n",
            "14      2008-12-16   Albury      9.8  ...        NaN      0.0            No\n",
            "15      2008-12-17   Albury     14.1  ...         No     16.8           Yes\n",
            "16      2008-12-18   Albury     13.5  ...        Yes     10.6           Yes\n",
            "17      2008-12-19   Albury     11.2  ...        Yes      0.0            No\n",
            "18      2008-12-20   Albury      9.8  ...         No      0.0            No\n",
            "19      2008-12-21   Albury     11.5  ...         No      0.0            No\n",
            "20      2008-12-22   Albury     17.1  ...         No      0.0            No\n",
            "21      2008-12-23   Albury     20.5  ...         No      0.0            No\n",
            "22      2008-12-24   Albury     15.3  ...         No      0.0            No\n",
            "23      2008-12-25   Albury     12.6  ...         No      0.0            No\n",
            "24      2008-12-26   Albury     16.2  ...         No      0.0            No\n",
            "25      2008-12-27   Albury     16.9  ...         No      0.0            No\n",
            "26      2008-12-28   Albury     20.1  ...         No      0.0            No\n",
            "27      2008-12-29   Albury     19.7  ...         No      1.2           Yes\n",
            "28      2008-12-30   Albury     12.5  ...        Yes      0.8            No\n",
            "29      2008-12-31   Albury     12.0  ...         No      0.0            No\n",
            "...            ...      ...      ...  ...        ...      ...           ...\n",
            "142163  2017-05-26    Uluru     14.3  ...         No      0.0            No\n",
            "142164  2017-05-27    Uluru      9.3  ...         No      0.0            No\n",
            "142165  2017-05-28    Uluru      8.0  ...         No      0.0            No\n",
            "142166  2017-05-29    Uluru     12.7  ...         No      0.0            No\n",
            "142167  2017-05-30    Uluru      9.4  ...         No      0.0            No\n",
            "142168  2017-05-31    Uluru      5.4  ...         No      0.0            No\n",
            "142169  2017-06-01    Uluru      5.6  ...         No      0.0            No\n",
            "142170  2017-06-02    Uluru      1.5  ...         No      0.0            No\n",
            "142171  2017-06-03    Uluru      3.8  ...         No      0.0            No\n",
            "142172  2017-06-04    Uluru      4.5  ...         No      0.0            No\n",
            "142173  2017-06-05    Uluru      4.9  ...         No      0.0            No\n",
            "142174  2017-06-06    Uluru      1.2  ...         No      0.0            No\n",
            "142175  2017-06-07    Uluru      0.5  ...         No      0.0            No\n",
            "142176  2017-06-08    Uluru      4.0  ...         No      0.0            No\n",
            "142177  2017-06-09    Uluru      3.4  ...         No      0.0            No\n",
            "142178  2017-06-10    Uluru      3.2  ...         No      0.0            No\n",
            "142179  2017-06-11    Uluru      2.4  ...         No      0.0            No\n",
            "142180  2017-06-12    Uluru      5.1  ...         No      0.0            No\n",
            "142181  2017-06-13    Uluru      2.5  ...         No      0.0            No\n",
            "142182  2017-06-14    Uluru      2.3  ...         No      0.0            No\n",
            "142183  2017-06-15    Uluru      2.6  ...         No      0.0            No\n",
            "142184  2017-06-16    Uluru      5.2  ...         No      0.0            No\n",
            "142185  2017-06-17    Uluru      6.4  ...         No      0.0            No\n",
            "142186  2017-06-18    Uluru      8.0  ...         No      0.0            No\n",
            "142187  2017-06-19    Uluru      7.4  ...         No      0.0            No\n",
            "142188  2017-06-20    Uluru      3.5  ...         No      0.0            No\n",
            "142189  2017-06-21    Uluru      2.8  ...         No      0.0            No\n",
            "142190  2017-06-22    Uluru      3.6  ...         No      0.0            No\n",
            "142191  2017-06-23    Uluru      5.4  ...         No      0.0            No\n",
            "142192  2017-06-24    Uluru      7.8  ...         No      0.0            No\n",
            "\n",
            "[142193 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqPIkGVgc_Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166dXDngj9tG",
        "colab_type": "text"
      },
      "source": [
        "Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ijNh4c75s60",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3UawS0d8Y9",
        "colab_type": "code",
        "outputId": "95e3ff0f-207d-49cf-f04d-1183d4efd53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#checking the labels\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.2</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "0  2008-12-01   Albury     13.4  ...         No      0.0            No\n",
              "1  2008-12-02   Albury      7.4  ...         No      0.0            No\n",
              "2  2008-12-03   Albury     12.9  ...         No      0.0            No\n",
              "3  2008-12-04   Albury      9.2  ...         No      1.0            No\n",
              "4  2008-12-05   Albury     17.5  ...         No      0.2            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnN5fPzweN8u",
        "colab_type": "code",
        "outputId": "52b66a0f-ef1d-44dc-9611-d5e55b1d1877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1778
        }
      },
      "source": [
        "labels_map = {}\n",
        "inv_labels_map = {}\n",
        "count = 0\n",
        "for label in df['Location']:\n",
        "  if(label in labels_map):\n",
        "    continue\n",
        "  labels_map[label] = count\n",
        "  inv_labels_map[count] = label\n",
        "  count = count + 1\n",
        "  \n",
        "  print(\"Label Map: \", labels_map)\n",
        "  print(\"No. of Labels are: \", count)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Map:  {'Albury': 0}\n",
            "No. of Labels are:  1\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1}\n",
            "No. of Labels are:  2\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2}\n",
            "No. of Labels are:  3\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3}\n",
            "No. of Labels are:  4\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4}\n",
            "No. of Labels are:  5\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5}\n",
            "No. of Labels are:  6\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6}\n",
            "No. of Labels are:  7\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7}\n",
            "No. of Labels are:  8\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8}\n",
            "No. of Labels are:  9\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9}\n",
            "No. of Labels are:  10\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10}\n",
            "No. of Labels are:  11\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11}\n",
            "No. of Labels are:  12\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12}\n",
            "No. of Labels are:  13\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13}\n",
            "No. of Labels are:  14\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14}\n",
            "No. of Labels are:  15\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15}\n",
            "No. of Labels are:  16\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16}\n",
            "No. of Labels are:  17\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17}\n",
            "No. of Labels are:  18\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18}\n",
            "No. of Labels are:  19\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19}\n",
            "No. of Labels are:  20\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20}\n",
            "No. of Labels are:  21\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21}\n",
            "No. of Labels are:  22\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22}\n",
            "No. of Labels are:  23\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23}\n",
            "No. of Labels are:  24\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24}\n",
            "No. of Labels are:  25\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25}\n",
            "No. of Labels are:  26\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26}\n",
            "No. of Labels are:  27\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27}\n",
            "No. of Labels are:  28\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28}\n",
            "No. of Labels are:  29\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29}\n",
            "No. of Labels are:  30\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30}\n",
            "No. of Labels are:  31\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31}\n",
            "No. of Labels are:  32\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32}\n",
            "No. of Labels are:  33\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33}\n",
            "No. of Labels are:  34\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34}\n",
            "No. of Labels are:  35\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35}\n",
            "No. of Labels are:  36\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36}\n",
            "No. of Labels are:  37\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37}\n",
            "No. of Labels are:  38\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38}\n",
            "No. of Labels are:  39\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39}\n",
            "No. of Labels are:  40\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40}\n",
            "No. of Labels are:  41\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41}\n",
            "No. of Labels are:  42\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42}\n",
            "No. of Labels are:  43\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43}\n",
            "No. of Labels are:  44\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43, 'Launceston': 44}\n",
            "No. of Labels are:  45\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43, 'Launceston': 44, 'AliceSprings': 45}\n",
            "No. of Labels are:  46\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43, 'Launceston': 44, 'AliceSprings': 45, 'Darwin': 46}\n",
            "No. of Labels are:  47\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43, 'Launceston': 44, 'AliceSprings': 45, 'Darwin': 46, 'Katherine': 47}\n",
            "No. of Labels are:  48\n",
            "Label Map:  {'Albury': 0, 'BadgerysCreek': 1, 'Cobar': 2, 'CoffsHarbour': 3, 'Moree': 4, 'Newcastle': 5, 'NorahHead': 6, 'NorfolkIsland': 7, 'Penrith': 8, 'Richmond': 9, 'Sydney': 10, 'SydneyAirport': 11, 'WaggaWagga': 12, 'Williamtown': 13, 'Wollongong': 14, 'Canberra': 15, 'Tuggeranong': 16, 'MountGinini': 17, 'Ballarat': 18, 'Bendigo': 19, 'Sale': 20, 'MelbourneAirport': 21, 'Melbourne': 22, 'Mildura': 23, 'Nhil': 24, 'Portland': 25, 'Watsonia': 26, 'Dartmoor': 27, 'Brisbane': 28, 'Cairns': 29, 'GoldCoast': 30, 'Townsville': 31, 'Adelaide': 32, 'MountGambier': 33, 'Nuriootpa': 34, 'Woomera': 35, 'Albany': 36, 'Witchcliffe': 37, 'PearceRAAF': 38, 'PerthAirport': 39, 'Perth': 40, 'SalmonGums': 41, 'Walpole': 42, 'Hobart': 43, 'Launceston': 44, 'AliceSprings': 45, 'Darwin': 46, 'Katherine': 47, 'Uluru': 48}\n",
            "No. of Labels are:  49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYkY6A1pf0r_",
        "colab_type": "code",
        "outputId": "9e426fd8-ac32-412a-a870-6cf48c0571ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1154
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
            "0       2008-12-01   Albury     13.4  ...         No      0.0            No\n",
            "1       2008-12-02   Albury      7.4  ...         No      0.0            No\n",
            "2       2008-12-03   Albury     12.9  ...         No      0.0            No\n",
            "3       2008-12-04   Albury      9.2  ...         No      1.0            No\n",
            "4       2008-12-05   Albury     17.5  ...         No      0.2            No\n",
            "5       2008-12-06   Albury     14.6  ...         No      0.0            No\n",
            "6       2008-12-07   Albury     14.3  ...         No      0.0            No\n",
            "7       2008-12-08   Albury      7.7  ...         No      0.0            No\n",
            "8       2008-12-09   Albury      9.7  ...         No      1.4           Yes\n",
            "9       2008-12-10   Albury     13.1  ...        Yes      0.0            No\n",
            "10      2008-12-11   Albury     13.4  ...         No      2.2           Yes\n",
            "11      2008-12-12   Albury     15.9  ...        Yes     15.6           Yes\n",
            "12      2008-12-13   Albury     15.9  ...        Yes      3.6           Yes\n",
            "13      2008-12-14   Albury     12.6  ...        Yes      0.0            No\n",
            "14      2008-12-16   Albury      9.8  ...        NaN      0.0            No\n",
            "15      2008-12-17   Albury     14.1  ...         No     16.8           Yes\n",
            "16      2008-12-18   Albury     13.5  ...        Yes     10.6           Yes\n",
            "17      2008-12-19   Albury     11.2  ...        Yes      0.0            No\n",
            "18      2008-12-20   Albury      9.8  ...         No      0.0            No\n",
            "19      2008-12-21   Albury     11.5  ...         No      0.0            No\n",
            "20      2008-12-22   Albury     17.1  ...         No      0.0            No\n",
            "21      2008-12-23   Albury     20.5  ...         No      0.0            No\n",
            "22      2008-12-24   Albury     15.3  ...         No      0.0            No\n",
            "23      2008-12-25   Albury     12.6  ...         No      0.0            No\n",
            "24      2008-12-26   Albury     16.2  ...         No      0.0            No\n",
            "25      2008-12-27   Albury     16.9  ...         No      0.0            No\n",
            "26      2008-12-28   Albury     20.1  ...         No      0.0            No\n",
            "27      2008-12-29   Albury     19.7  ...         No      1.2           Yes\n",
            "28      2008-12-30   Albury     12.5  ...        Yes      0.8            No\n",
            "29      2008-12-31   Albury     12.0  ...         No      0.0            No\n",
            "...            ...      ...      ...  ...        ...      ...           ...\n",
            "142163  2017-05-26    Uluru     14.3  ...         No      0.0            No\n",
            "142164  2017-05-27    Uluru      9.3  ...         No      0.0            No\n",
            "142165  2017-05-28    Uluru      8.0  ...         No      0.0            No\n",
            "142166  2017-05-29    Uluru     12.7  ...         No      0.0            No\n",
            "142167  2017-05-30    Uluru      9.4  ...         No      0.0            No\n",
            "142168  2017-05-31    Uluru      5.4  ...         No      0.0            No\n",
            "142169  2017-06-01    Uluru      5.6  ...         No      0.0            No\n",
            "142170  2017-06-02    Uluru      1.5  ...         No      0.0            No\n",
            "142171  2017-06-03    Uluru      3.8  ...         No      0.0            No\n",
            "142172  2017-06-04    Uluru      4.5  ...         No      0.0            No\n",
            "142173  2017-06-05    Uluru      4.9  ...         No      0.0            No\n",
            "142174  2017-06-06    Uluru      1.2  ...         No      0.0            No\n",
            "142175  2017-06-07    Uluru      0.5  ...         No      0.0            No\n",
            "142176  2017-06-08    Uluru      4.0  ...         No      0.0            No\n",
            "142177  2017-06-09    Uluru      3.4  ...         No      0.0            No\n",
            "142178  2017-06-10    Uluru      3.2  ...         No      0.0            No\n",
            "142179  2017-06-11    Uluru      2.4  ...         No      0.0            No\n",
            "142180  2017-06-12    Uluru      5.1  ...         No      0.0            No\n",
            "142181  2017-06-13    Uluru      2.5  ...         No      0.0            No\n",
            "142182  2017-06-14    Uluru      2.3  ...         No      0.0            No\n",
            "142183  2017-06-15    Uluru      2.6  ...         No      0.0            No\n",
            "142184  2017-06-16    Uluru      5.2  ...         No      0.0            No\n",
            "142185  2017-06-17    Uluru      6.4  ...         No      0.0            No\n",
            "142186  2017-06-18    Uluru      8.0  ...         No      0.0            No\n",
            "142187  2017-06-19    Uluru      7.4  ...         No      0.0            No\n",
            "142188  2017-06-20    Uluru      3.5  ...         No      0.0            No\n",
            "142189  2017-06-21    Uluru      2.8  ...         No      0.0            No\n",
            "142190  2017-06-22    Uluru      3.6  ...         No      0.0            No\n",
            "142191  2017-06-23    Uluru      5.4  ...         No      0.0            No\n",
            "142192  2017-06-24    Uluru      7.8  ...         No      0.0            No\n",
            "\n",
            "[142193 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCbf2UIogD85",
        "colab_type": "code",
        "outputId": "34ca9029-3eab-4040-ac95-fee8184f3ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>142188</th>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>3.5</td>\n",
              "      <td>21.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E</td>\n",
              "      <td>31.0</td>\n",
              "      <td>ESE</td>\n",
              "      <td>E</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1024.7</td>\n",
              "      <td>1021.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142189</th>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>2.8</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E</td>\n",
              "      <td>31.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1024.6</td>\n",
              "      <td>1020.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1</td>\n",
              "      <td>22.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142190</th>\n",
              "      <td>2017-06-22</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>3.6</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NNW</td>\n",
              "      <td>22.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1023.5</td>\n",
              "      <td>1019.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142191</th>\n",
              "      <td>2017-06-23</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>5.4</td>\n",
              "      <td>26.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>37.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>WNW</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>1016.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.5</td>\n",
              "      <td>26.1</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142192</th>\n",
              "      <td>2017-06-24</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>7.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "142188  2017-06-20    Uluru      3.5  ...         No      0.0            No\n",
              "142189  2017-06-21    Uluru      2.8  ...         No      0.0            No\n",
              "142190  2017-06-22    Uluru      3.6  ...         No      0.0            No\n",
              "142191  2017-06-23    Uluru      5.4  ...         No      0.0            No\n",
              "142192  2017-06-24    Uluru      7.8  ...         No      0.0            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knYYUroCkFXQ",
        "colab_type": "code",
        "outputId": "9043223b-c78d-4a53-8e75-f9f1e2ab626b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.2</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "0  2008-12-01   Albury     13.4  ...         No      0.0            No\n",
              "1  2008-12-02   Albury      7.4  ...         No      0.0            No\n",
              "2  2008-12-03   Albury     12.9  ...         No      0.0            No\n",
              "3  2008-12-04   Albury      9.2  ...         No      1.0            No\n",
              "4  2008-12-05   Albury     17.5  ...         No      0.2            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjXg9FUPmTjI",
        "colab_type": "code",
        "outputId": "8316f4d8-b0d5-4578-90f2-5ee1adf2493a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#Drop NAN in all attributes\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5939</th>\n",
              "      <td>2009-01-01</td>\n",
              "      <td>Cobar</td>\n",
              "      <td>17.9</td>\n",
              "      <td>35.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>SSW</td>\n",
              "      <td>48.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>SW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>1004.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>33.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5940</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>Cobar</td>\n",
              "      <td>18.4</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>13.0</td>\n",
              "      <td>S</td>\n",
              "      <td>37.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>SSE</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1012.9</td>\n",
              "      <td>1012.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.3</td>\n",
              "      <td>27.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5942</th>\n",
              "      <td>2009-01-04</td>\n",
              "      <td>Cobar</td>\n",
              "      <td>19.4</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>10.6</td>\n",
              "      <td>NNE</td>\n",
              "      <td>46.0</td>\n",
              "      <td>NNE</td>\n",
              "      <td>NNW</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1012.3</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28.7</td>\n",
              "      <td>34.9</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5943</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>Cobar</td>\n",
              "      <td>21.9</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.4</td>\n",
              "      <td>12.2</td>\n",
              "      <td>WNW</td>\n",
              "      <td>31.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1012.7</td>\n",
              "      <td>1009.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29.1</td>\n",
              "      <td>35.6</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5944</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>Cobar</td>\n",
              "      <td>24.2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>8.4</td>\n",
              "      <td>WNW</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>WNW</td>\n",
              "      <td>17.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1010.7</td>\n",
              "      <td>1007.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>37.6</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "5939  2009-01-01    Cobar     17.9  ...         No      0.0            No\n",
              "5940  2009-01-02    Cobar     18.4  ...         No      0.0            No\n",
              "5942  2009-01-04    Cobar     19.4  ...         No      0.0            No\n",
              "5943  2009-01-05    Cobar     21.9  ...         No      0.0            No\n",
              "5944  2009-01-06    Cobar     24.2  ...         No      0.0            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5TYB0ONgMSG",
        "colab_type": "code",
        "outputId": "2456864b-0d6c-4a7e-ae1f-1f0219ea8fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#Double check that we have removed the NaN\n",
        "df.sample(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>138737</th>\n",
              "      <td>2016-06-14</td>\n",
              "      <td>Darwin</td>\n",
              "      <td>22.8</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>10.6</td>\n",
              "      <td>ESE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>ESE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>30.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>1011.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26.1</td>\n",
              "      <td>31.6</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60093</th>\n",
              "      <td>2009-12-24</td>\n",
              "      <td>Sale</td>\n",
              "      <td>19.7</td>\n",
              "      <td>34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>61.0</td>\n",
              "      <td>N</td>\n",
              "      <td>W</td>\n",
              "      <td>43.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1000.4</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>33.4</td>\n",
              "      <td>26.8</td>\n",
              "      <td>No</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70175</th>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>Mildura</td>\n",
              "      <td>5.7</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>WSW</td>\n",
              "      <td>57.0</td>\n",
              "      <td>WSW</td>\n",
              "      <td>SW</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1020.2</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9022</th>\n",
              "      <td>2009-04-07</td>\n",
              "      <td>CoffsHarbour</td>\n",
              "      <td>17.9</td>\n",
              "      <td>23.6</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>SE</td>\n",
              "      <td>31.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1022.7</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32269</th>\n",
              "      <td>2015-12-09</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>21.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>S</td>\n",
              "      <td>61.0</td>\n",
              "      <td>NNE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1014.2</td>\n",
              "      <td>1012.1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>27.5</td>\n",
              "      <td>No</td>\n",
              "      <td>15.2</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date      Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "138737  2016-06-14        Darwin     22.8  ...         No      0.0            No\n",
              "60093   2009-12-24          Sale     19.7  ...         No      4.4           Yes\n",
              "70175   2014-09-17       Mildura      5.7  ...         No      0.0            No\n",
              "9022    2009-04-07  CoffsHarbour     17.9  ...        Yes     15.6           Yes\n",
              "32269   2015-12-09        Sydney     21.3  ...         No     15.2           Yes\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jwhf9DDiCOl",
        "colab_type": "code",
        "outputId": "1d5d28a1-82b0-4f8f-8624-ab57477c1d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
              "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
              "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
              "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
              "       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZUArxgxiOkV",
        "colab_type": "code",
        "outputId": "7629b7ff-337d-4d60-914e-46e3aceb49ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date              object\n",
              "Location          object\n",
              "MinTemp          float64\n",
              "MaxTemp          float64\n",
              "Rainfall         float64\n",
              "Evaporation      float64\n",
              "Sunshine         float64\n",
              "WindGustDir       object\n",
              "WindGustSpeed    float64\n",
              "WindDir9am        object\n",
              "WindDir3pm        object\n",
              "WindSpeed9am     float64\n",
              "WindSpeed3pm     float64\n",
              "Humidity9am      float64\n",
              "Humidity3pm      float64\n",
              "Pressure9am      float64\n",
              "Pressure3pm      float64\n",
              "Cloud9am         float64\n",
              "Cloud3pm         float64\n",
              "Temp9am          float64\n",
              "Temp3pm          float64\n",
              "RainToday         object\n",
              "RISK_MM          float64\n",
              "RainTomorrow      object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BtY7DUD0zIBJ",
        "colab": {}
      },
      "source": [
        "#Changing Date attributes to be read as a date\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "60a092a1-8033-4531-cbda-95cb9e3f1a78",
        "id": "Sn5onWBxzH-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(\"Maximum date :: \", df[\"Date\"].max() )\n",
        "print(\"Minimum date :: \", df[\"Date\"].min())\n",
        "print(\"Count lines :: \", df[\"Date\"].count())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum date ::  2017-06-25 00:00:00\n",
            "Minimum date ::  2007-11-01 00:00:00\n",
            "Count lines ::  56420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFx52zf2j4Yv",
        "colab_type": "code",
        "outputId": "9c40d2c0-eb9f-4722-fc82-50dfa417bd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#  Plot of maximum temperature\n",
        "df['MaxTemp'].rolling(365).mean().plot()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb27e7482e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQNTgB_zmyPS",
        "colab_type": "code",
        "outputId": "6ab0cdd1-905f-47b6-cc3d-be5a3309ca39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2007-11-01</th>\n",
              "      <td>Canberra</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>30.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>NW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>23.6</td>\n",
              "      <td>No</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-11-02</th>\n",
              "      <td>Canberra</td>\n",
              "      <td>14.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>9.7</td>\n",
              "      <td>ENE</td>\n",
              "      <td>39.0</td>\n",
              "      <td>E</td>\n",
              "      <td>W</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1012.4</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>25.7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-11-03</th>\n",
              "      <td>Canberra</td>\n",
              "      <td>13.7</td>\n",
              "      <td>23.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>85.0</td>\n",
              "      <td>N</td>\n",
              "      <td>NNE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1009.5</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.4</td>\n",
              "      <td>20.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>39.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-11-04</th>\n",
              "      <td>Canberra</td>\n",
              "      <td>13.3</td>\n",
              "      <td>15.5</td>\n",
              "      <td>39.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>9.1</td>\n",
              "      <td>NW</td>\n",
              "      <td>54.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>W</td>\n",
              "      <td>30.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1005.5</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>14.1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-11-05</th>\n",
              "      <td>Canberra</td>\n",
              "      <td>7.6</td>\n",
              "      <td>16.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>10.6</td>\n",
              "      <td>SSE</td>\n",
              "      <td>50.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1018.3</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Location  MinTemp  MaxTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "Date                                    ...                                  \n",
              "2007-11-01  Canberra      8.0     24.3  ...         No      3.6           Yes\n",
              "2007-11-02  Canberra     14.0     26.9  ...        Yes      3.6           Yes\n",
              "2007-11-03  Canberra     13.7     23.4  ...        Yes     39.8           Yes\n",
              "2007-11-04  Canberra     13.3     15.5  ...        Yes      2.8           Yes\n",
              "2007-11-05  Canberra      7.6     16.1  ...        Yes      0.0            No\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uughw5hSq-Se",
        "colab_type": "code",
        "outputId": "e8643e00-ad20-4054-f6a2-7cff009d250f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2956
        }
      },
      "source": [
        "# Create data on specific location that we want to analyse which is Sydney.\n",
        "_SydneyData = df[df[\"Location\"] == \"Sydney\"]\n",
        "_SydneyData"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-10-20</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.9</td>\n",
              "      <td>20.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>ENE</td>\n",
              "      <td>37.0</td>\n",
              "      <td>W</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>1025.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>19.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-21</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>13.3</td>\n",
              "      <td>21.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>11.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>41.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1025.9</td>\n",
              "      <td>1022.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-22</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>15.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NNE</td>\n",
              "      <td>41.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1021.4</td>\n",
              "      <td>1017.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-26</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.9</td>\n",
              "      <td>26.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3.8</td>\n",
              "      <td>12.1</td>\n",
              "      <td>NE</td>\n",
              "      <td>33.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>22.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-27</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>14.8</td>\n",
              "      <td>23.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>SSE</td>\n",
              "      <td>54.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>SE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.6</td>\n",
              "      <td>No</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-29</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>14.5</td>\n",
              "      <td>22.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>ENE</td>\n",
              "      <td>31.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>ENE</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1020.7</td>\n",
              "      <td>1017.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>20.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-01</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>18.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>5.2</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>SSE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>S</td>\n",
              "      <td>SSE</td>\n",
              "      <td>22.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>1012.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>18.6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-03</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>SE</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ESE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1018.1</td>\n",
              "      <td>1016.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>20.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.4</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-04</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>14.4</td>\n",
              "      <td>18.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>ESE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>S</td>\n",
              "      <td>SE</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1022.3</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>17.6</td>\n",
              "      <td>No</td>\n",
              "      <td>8.4</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-05</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>13.4</td>\n",
              "      <td>19.2</td>\n",
              "      <td>8.4</td>\n",
              "      <td>8.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>SE</td>\n",
              "      <td>46.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>SSE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1023.9</td>\n",
              "      <td>1022.1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>17.8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-08</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>16.1</td>\n",
              "      <td>26.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>SW</td>\n",
              "      <td>74.0</td>\n",
              "      <td>E</td>\n",
              "      <td>NNE</td>\n",
              "      <td>7.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1017.2</td>\n",
              "      <td>1015.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>23.8</td>\n",
              "      <td>No</td>\n",
              "      <td>5.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-09</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>17.2</td>\n",
              "      <td>23.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>37.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>E</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>1024.2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.7</td>\n",
              "      <td>23.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-10</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>18.2</td>\n",
              "      <td>24.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>N</td>\n",
              "      <td>52.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>ENE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1021.8</td>\n",
              "      <td>1017.1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.9</td>\n",
              "      <td>23.5</td>\n",
              "      <td>No</td>\n",
              "      <td>8.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-11</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>19.7</td>\n",
              "      <td>27.2</td>\n",
              "      <td>8.6</td>\n",
              "      <td>7.2</td>\n",
              "      <td>9.3</td>\n",
              "      <td>E</td>\n",
              "      <td>30.0</td>\n",
              "      <td>ESE</td>\n",
              "      <td>E</td>\n",
              "      <td>7.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1014.9</td>\n",
              "      <td>1012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.1</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-16</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>17.4</td>\n",
              "      <td>23.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>ESE</td>\n",
              "      <td>35.0</td>\n",
              "      <td>S</td>\n",
              "      <td>SSE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1013.3</td>\n",
              "      <td>1011.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.4</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-17</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>17.1</td>\n",
              "      <td>22.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>6.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>SSE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>S</td>\n",
              "      <td>E</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1017.1</td>\n",
              "      <td>1015.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-18</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>16.8</td>\n",
              "      <td>23.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>8.8</td>\n",
              "      <td>NE</td>\n",
              "      <td>35.0</td>\n",
              "      <td>N</td>\n",
              "      <td>NE</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1015.2</td>\n",
              "      <td>1012.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>22.3</td>\n",
              "      <td>22.6</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-19</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>16.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>SSE</td>\n",
              "      <td>67.0</td>\n",
              "      <td>S</td>\n",
              "      <td>SSE</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1021.8</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.4</td>\n",
              "      <td>18.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-22</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>16.5</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.4</td>\n",
              "      <td>NE</td>\n",
              "      <td>44.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>E</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1026.0</td>\n",
              "      <td>1024.3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.3</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-24</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>17.5</td>\n",
              "      <td>24.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>NE</td>\n",
              "      <td>56.0</td>\n",
              "      <td>NNE</td>\n",
              "      <td>NE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1025.3</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.8</td>\n",
              "      <td>24.1</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-25</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>18.5</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>12.1</td>\n",
              "      <td>NE</td>\n",
              "      <td>44.0</td>\n",
              "      <td>E</td>\n",
              "      <td>NE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>1017.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>25.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-26</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>18.9</td>\n",
              "      <td>24.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NE</td>\n",
              "      <td>37.0</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>1015.3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>22.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-30</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>16.4</td>\n",
              "      <td>21.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>SSW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>S</td>\n",
              "      <td>SSE</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1016.4</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>20.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>27.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-01</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>17.2</td>\n",
              "      <td>20.1</td>\n",
              "      <td>27.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>E</td>\n",
              "      <td>43.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>E</td>\n",
              "      <td>30.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1016.4</td>\n",
              "      <td>1015.3</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>19.9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-02</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>18.5</td>\n",
              "      <td>24.3</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>ENE</td>\n",
              "      <td>44.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>1015.9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.1</td>\n",
              "      <td>22.7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.2</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-03</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>19.8</td>\n",
              "      <td>24.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>5.2</td>\n",
              "      <td>8.7</td>\n",
              "      <td>ENE</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NNE</td>\n",
              "      <td>E</td>\n",
              "      <td>17.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.7</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-06</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>20.4</td>\n",
              "      <td>25.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>11.4</td>\n",
              "      <td>ESE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>ESE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1014.2</td>\n",
              "      <td>1013.3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>25.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-07</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>21.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.2</td>\n",
              "      <td>ENE</td>\n",
              "      <td>43.0</td>\n",
              "      <td>E</td>\n",
              "      <td>ENE</td>\n",
              "      <td>19.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>23.5</td>\n",
              "      <td>25.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-08</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>20.8</td>\n",
              "      <td>26.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>12.2</td>\n",
              "      <td>NE</td>\n",
              "      <td>63.0</td>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "      <td>15.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1016.7</td>\n",
              "      <td>1012.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>24.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-09</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>22.0</td>\n",
              "      <td>30.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>N</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NE</td>\n",
              "      <td>SSE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1008.2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>23.4</td>\n",
              "      <td>28.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-27</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.6</td>\n",
              "      <td>20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>7.0</td>\n",
              "      <td>W</td>\n",
              "      <td>24.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>19.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1021.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>19.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-28</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.9</td>\n",
              "      <td>23.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>8.4</td>\n",
              "      <td>NNW</td>\n",
              "      <td>48.0</td>\n",
              "      <td>W</td>\n",
              "      <td>NW</td>\n",
              "      <td>13.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1013.2</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-29</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.4</td>\n",
              "      <td>18.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>9.4</td>\n",
              "      <td>W</td>\n",
              "      <td>56.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1017.8</td>\n",
              "      <td>1018.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-30</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>7.1</td>\n",
              "      <td>17.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>9.7</td>\n",
              "      <td>WSW</td>\n",
              "      <td>39.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1023.1</td>\n",
              "      <td>1020.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.7</td>\n",
              "      <td>16.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-31</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.7</td>\n",
              "      <td>16.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>7.8</td>\n",
              "      <td>SSW</td>\n",
              "      <td>52.0</td>\n",
              "      <td>SSW</td>\n",
              "      <td>SSW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1025.4</td>\n",
              "      <td>1026.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>15.9</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-01</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>9.7</td>\n",
              "      <td>WSW</td>\n",
              "      <td>43.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSW</td>\n",
              "      <td>28.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1032.8</td>\n",
              "      <td>1031.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>17.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-02</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>8.5</td>\n",
              "      <td>18.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>SSW</td>\n",
              "      <td>41.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSW</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1032.7</td>\n",
              "      <td>1030.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>16.4</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-03</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>10.7</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>S</td>\n",
              "      <td>41.0</td>\n",
              "      <td>W</td>\n",
              "      <td>S</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>1031.1</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>16.4</td>\n",
              "      <td>No</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-04</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>10.5</td>\n",
              "      <td>19.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>W</td>\n",
              "      <td>28.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1028.3</td>\n",
              "      <td>1024.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-05</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.4</td>\n",
              "      <td>19.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>9.4</td>\n",
              "      <td>W</td>\n",
              "      <td>28.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>19.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-06</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.1</td>\n",
              "      <td>17.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>WSW</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>S</td>\n",
              "      <td>19.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>1017.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>14.7</td>\n",
              "      <td>No</td>\n",
              "      <td>54.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-07</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>8.8</td>\n",
              "      <td>15.5</td>\n",
              "      <td>54.6</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SSW</td>\n",
              "      <td>56.0</td>\n",
              "      <td>SSW</td>\n",
              "      <td>S</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1020.2</td>\n",
              "      <td>1019.6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>14.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>61.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-08</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.4</td>\n",
              "      <td>18.1</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.3</td>\n",
              "      <td>SE</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>S</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1024.2</td>\n",
              "      <td>1023.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>16.9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.4</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-09</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>10.4</td>\n",
              "      <td>18.9</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>ESE</td>\n",
              "      <td>52.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSE</td>\n",
              "      <td>19.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1027.6</td>\n",
              "      <td>1026.7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>18.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-10</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.5</td>\n",
              "      <td>18.1</td>\n",
              "      <td>38.8</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>SSE</td>\n",
              "      <td>50.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>SSE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1031.9</td>\n",
              "      <td>1030.2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-11</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>12.5</td>\n",
              "      <td>17.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1029.2</td>\n",
              "      <td>1025.9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.2</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-12</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.5</td>\n",
              "      <td>SSE</td>\n",
              "      <td>26.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>SSE</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>19.1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-13</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.5</td>\n",
              "      <td>18.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>9.1</td>\n",
              "      <td>SSE</td>\n",
              "      <td>37.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1029.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>No</td>\n",
              "      <td>2.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-14</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.9</td>\n",
              "      <td>WNW</td>\n",
              "      <td>24.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1031.3</td>\n",
              "      <td>1028.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>17.4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.6</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-15</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>10.7</td>\n",
              "      <td>20.1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>6.4</td>\n",
              "      <td>W</td>\n",
              "      <td>22.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1027.9</td>\n",
              "      <td>1024.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>18.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-16</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.9</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>WNW</td>\n",
              "      <td>26.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1026.2</td>\n",
              "      <td>1023.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>17.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-17</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>13.2</td>\n",
              "      <td>19.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>SSW</td>\n",
              "      <td>26.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>SSW</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1024.3</td>\n",
              "      <td>1021.8</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>No</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-18</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>S</td>\n",
              "      <td>52.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>SSW</td>\n",
              "      <td>13.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>1025.7</td>\n",
              "      <td>1025.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.9</td>\n",
              "      <td>17.6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.4</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-19</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.2</td>\n",
              "      <td>18.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>SSW</td>\n",
              "      <td>37.0</td>\n",
              "      <td>W</td>\n",
              "      <td>S</td>\n",
              "      <td>17.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1030.4</td>\n",
              "      <td>1028.4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>17.2</td>\n",
              "      <td>No</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-20</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>11.3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>W</td>\n",
              "      <td>26.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1028.7</td>\n",
              "      <td>1025.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>19.7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-21</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>8.6</td>\n",
              "      <td>19.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>SSE</td>\n",
              "      <td>37.0</td>\n",
              "      <td>W</td>\n",
              "      <td>SSE</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1025.9</td>\n",
              "      <td>1025.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>17.9</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-22</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.3</td>\n",
              "      <td>19.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.2</td>\n",
              "      <td>W</td>\n",
              "      <td>30.0</td>\n",
              "      <td>W</td>\n",
              "      <td>ESE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1028.5</td>\n",
              "      <td>1024.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-23</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>9.4</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>W</td>\n",
              "      <td>24.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>N</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1020.8</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-24</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>10.1</td>\n",
              "      <td>19.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>9.3</td>\n",
              "      <td>W</td>\n",
              "      <td>43.0</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>17.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>1015.1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-25</th>\n",
              "      <td>Sydney</td>\n",
              "      <td>7.6</td>\n",
              "      <td>19.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>9.4</td>\n",
              "      <td>W</td>\n",
              "      <td>35.0</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1018.6</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>18.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1690 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Location  MinTemp  MaxTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "Date                                   ...                                  \n",
              "2010-10-20   Sydney     12.9     20.3  ...         No      0.0            No\n",
              "2010-10-21   Sydney     13.3     21.5  ...         No      0.0            No\n",
              "2010-10-22   Sydney     15.3     23.0  ...         No      0.0            No\n",
              "2010-10-26   Sydney     12.9     26.7  ...         No      0.0            No\n",
              "2010-10-27   Sydney     14.8     23.8  ...         No      1.8           Yes\n",
              "2010-10-29   Sydney     14.5     22.1  ...         No      0.0            No\n",
              "2010-11-01   Sydney     18.1     20.4  ...        Yes     32.6           Yes\n",
              "2010-11-03   Sydney     12.0     23.9  ...         No      0.4            No\n",
              "2010-11-04   Sydney     14.4     18.1  ...         No      8.4           Yes\n",
              "2010-11-05   Sydney     13.4     19.2  ...        Yes     26.0           Yes\n",
              "2010-11-08   Sydney     16.1     26.3  ...         No      5.6           Yes\n",
              "2010-11-09   Sydney     17.2     23.6  ...        Yes      0.0            No\n",
              "2010-11-10   Sydney     18.2     24.5  ...         No      8.6           Yes\n",
              "2010-11-11   Sydney     19.7     27.2  ...        Yes      0.0            No\n",
              "2010-11-16   Sydney     17.4     23.5  ...        Yes      0.4            No\n",
              "2010-11-17   Sydney     17.1     22.3  ...         No      1.0            No\n",
              "2010-11-18   Sydney     16.8     23.4  ...         No      0.0            No\n",
              "2010-11-19   Sydney     16.7     20.0  ...         No      0.0            No\n",
              "2010-11-22   Sydney     16.5     24.0  ...         No      0.0            No\n",
              "2010-11-24   Sydney     17.5     24.7  ...         No      0.0            No\n",
              "2010-11-25   Sydney     18.5     26.0  ...         No      0.0            No\n",
              "2010-11-26   Sydney     18.9     24.1  ...         No      0.0            No\n",
              "2010-11-30   Sydney     16.4     21.6  ...        Yes     27.6           Yes\n",
              "2010-12-01   Sydney     17.2     20.1  ...        Yes     21.0           Yes\n",
              "2010-12-02   Sydney     18.5     24.3  ...        Yes      0.2            No\n",
              "2010-12-03   Sydney     19.8     24.4  ...         No      0.0            No\n",
              "2010-12-06   Sydney     20.4     25.7  ...         No      0.0            No\n",
              "2010-12-07   Sydney     21.0     26.0  ...         No      0.0            No\n",
              "2010-12-08   Sydney     20.8     26.3  ...         No      0.0            No\n",
              "2010-12-09   Sydney     22.0     30.7  ...         No      0.0            No\n",
              "...             ...      ...      ...  ...        ...      ...           ...\n",
              "2017-05-27   Sydney     12.6     20.6  ...         No      0.0            No\n",
              "2017-05-28   Sydney     11.9     23.7  ...         No      0.0            No\n",
              "2017-05-29   Sydney     11.4     18.3  ...         No      0.0            No\n",
              "2017-05-30   Sydney      7.1     17.1  ...         No      0.0            No\n",
              "2017-05-31   Sydney      9.7     16.3  ...         No      0.0            No\n",
              "2017-06-01   Sydney      8.0     18.3  ...         No      0.0            No\n",
              "2017-06-02   Sydney      8.5     18.1  ...         No      0.0            No\n",
              "2017-06-03   Sydney     10.7     17.4  ...         No      1.4           Yes\n",
              "2017-06-04   Sydney     10.5     19.7  ...        Yes      0.0            No\n",
              "2017-06-05   Sydney      9.4     19.6  ...         No      0.0            No\n",
              "2017-06-06   Sydney      9.1     17.9  ...         No     54.6           Yes\n",
              "2017-06-07   Sydney      8.8     15.5  ...        Yes     61.0           Yes\n",
              "2017-06-08   Sydney     12.4     18.1  ...        Yes      3.4           Yes\n",
              "2017-06-09   Sydney     10.4     18.9  ...        Yes     38.8           Yes\n",
              "2017-06-10   Sydney     12.5     18.1  ...        Yes      2.8           Yes\n",
              "2017-06-11   Sydney     12.5     17.2  ...        Yes      1.2           Yes\n",
              "2017-06-12   Sydney     11.3     20.4  ...        Yes      0.0            No\n",
              "2017-06-13   Sydney      9.5     18.7  ...         No      2.6           Yes\n",
              "2017-06-14   Sydney     11.1     17.8  ...        Yes      0.6            No\n",
              "2017-06-15   Sydney     10.7     20.1  ...         No      0.0            No\n",
              "2017-06-16   Sydney     11.9     17.3  ...         No      0.0            No\n",
              "2017-06-17   Sydney     13.2     19.1  ...         No      1.8           Yes\n",
              "2017-06-18   Sydney     11.3     18.0  ...        Yes      0.4            No\n",
              "2017-06-19   Sydney     11.2     18.3  ...         No      4.4           Yes\n",
              "2017-06-20   Sydney     11.3     20.0  ...        Yes      0.0            No\n",
              "2017-06-21   Sydney      8.6     19.6  ...         No      0.0            No\n",
              "2017-06-22   Sydney      9.3     19.2  ...         No      0.0            No\n",
              "2017-06-23   Sydney      9.4     17.7  ...         No      0.0            No\n",
              "2017-06-24   Sydney     10.1     19.3  ...         No      0.0            No\n",
              "2017-06-25   Sydney      7.6     19.3  ...         No      0.0            No\n",
              "\n",
              "[1690 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8imHlirFp_",
        "colab_type": "code",
        "outputId": "4ff4b92e-e542-4a9d-a15c-d13c09c81e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "# how many data points do we have in Sydney data\n",
        "_SydneyData.count().sort_values()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Location         1690\n",
              "RainToday        1690\n",
              "Temp3pm          1690\n",
              "Temp9am          1690\n",
              "Cloud3pm         1690\n",
              "Cloud9am         1690\n",
              "Pressure3pm      1690\n",
              "Pressure9am      1690\n",
              "Humidity3pm      1690\n",
              "Humidity9am      1690\n",
              "RISK_MM          1690\n",
              "WindSpeed3pm     1690\n",
              "WindDir3pm       1690\n",
              "WindDir9am       1690\n",
              "WindGustSpeed    1690\n",
              "WindGustDir      1690\n",
              "Sunshine         1690\n",
              "Evaporation      1690\n",
              "Rainfall         1690\n",
              "MaxTemp          1690\n",
              "MinTemp          1690\n",
              "WindSpeed9am     1690\n",
              "RainTomorrow     1690\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWOKgsM8upW3",
        "colab_type": "code",
        "outputId": "eaa8889b-7a90-46eb-f410-f236f4117ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# We need to remove RISK_MM because we want to predict 'RainTomorrow' and RISK_MM can leak some info to our model\n",
        "_SydneyData = _SydneyData.drop(columns=['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM'],axis=1)\n",
        "_SydneyData.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1690, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBYuRtdFvqP2",
        "colab_type": "code",
        "outputId": "262f0d06-fc17-44bf-c199-de8ca11c0ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Delete any Na in Sydney data\n",
        "_SydneyData = _SydneyData.dropna(how='any')\n",
        "_SydneyData.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1690, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIGaOrspZOUG",
        "colab_type": "text"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVXh-Kigvwcp",
        "colab_type": "code",
        "outputId": "f876ca30-8940-4306-9afa-a23d049f18c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "#remove the outliers in our data - using Z-score to detect and remove the outliers.\n",
        "from scipy import stats\n",
        "z = np.abs(stats.zscore(_SydneyData._get_numeric_data()))\n",
        "print(z)\n",
        "_SydneyData= _SydneyData[(z < 3).all(axis=1)]\n",
        "print(_SydneyData.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.47135192 0.70379268 0.32002218 ... 1.34106279 0.24751534 0.49300913]\n",
            " [0.38291374 0.43569629 0.34433714 ... 0.88789402 0.10476444 0.14091928]\n",
            " [0.05927713 0.10057581 0.34433714 ... 0.23646393 0.18073736 0.07033464]\n",
            " ...\n",
            " [1.24518594 1.28466819 0.34433714 ... 0.16005874 1.61384538 1.07982556]\n",
            " [1.09041914 0.92720634 0.34433714 ... 0.14589721 1.1651997  0.68079039]\n",
            " [1.64315772 0.92720634 0.34433714 ... 0.10341264 1.77698927 0.7277357 ]]\n",
            "(1596, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIx8M0nZv-5Y",
        "colab_type": "code",
        "outputId": "39110a1d-4811-47e2-ad87-daa92727dcc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "#categorical cloumns changing Yes/No to binary \n",
        "# simply change yes/no to 1/0 for RainToday and RainTomorrow\n",
        "_SydneyData['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
        "_SydneyData['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
        "\n",
        "# See unique values and convert them to int using pd.getDummies()\n",
        "categorical_columns = ['WindGustDir', 'WindDir3pm', 'WindDir9am']\n",
        "for col in categorical_columns:\n",
        "    print(np.unique(df[col]))\n",
        "# transform the categorical columns\n",
        "_SydneyData = pd.get_dummies(_SydneyData, columns=categorical_columns)\n",
        "_SydneyData.iloc[4:9]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n",
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n",
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "      <th>WindGustDir_E</th>\n",
              "      <th>WindGustDir_ENE</th>\n",
              "      <th>WindGustDir_ESE</th>\n",
              "      <th>WindGustDir_N</th>\n",
              "      <th>WindGustDir_NE</th>\n",
              "      <th>WindGustDir_NNE</th>\n",
              "      <th>WindGustDir_NNW</th>\n",
              "      <th>WindGustDir_NW</th>\n",
              "      <th>WindGustDir_S</th>\n",
              "      <th>WindGustDir_SE</th>\n",
              "      <th>WindGustDir_SSE</th>\n",
              "      <th>WindGustDir_SSW</th>\n",
              "      <th>WindGustDir_SW</th>\n",
              "      <th>WindGustDir_W</th>\n",
              "      <th>WindGustDir_WNW</th>\n",
              "      <th>WindGustDir_WSW</th>\n",
              "      <th>WindDir3pm_E</th>\n",
              "      <th>WindDir3pm_ENE</th>\n",
              "      <th>WindDir3pm_ESE</th>\n",
              "      <th>WindDir3pm_N</th>\n",
              "      <th>WindDir3pm_NE</th>\n",
              "      <th>WindDir3pm_NNE</th>\n",
              "      <th>WindDir3pm_NNW</th>\n",
              "      <th>WindDir3pm_NW</th>\n",
              "      <th>WindDir3pm_S</th>\n",
              "      <th>WindDir3pm_SE</th>\n",
              "      <th>WindDir3pm_SSE</th>\n",
              "      <th>WindDir3pm_SSW</th>\n",
              "      <th>WindDir3pm_SW</th>\n",
              "      <th>WindDir3pm_W</th>\n",
              "      <th>WindDir3pm_WNW</th>\n",
              "      <th>WindDir3pm_WSW</th>\n",
              "      <th>WindDir9am_E</th>\n",
              "      <th>WindDir9am_ENE</th>\n",
              "      <th>WindDir9am_ESE</th>\n",
              "      <th>WindDir9am_N</th>\n",
              "      <th>WindDir9am_NE</th>\n",
              "      <th>WindDir9am_NNE</th>\n",
              "      <th>WindDir9am_NNW</th>\n",
              "      <th>WindDir9am_NW</th>\n",
              "      <th>WindDir9am_S</th>\n",
              "      <th>WindDir9am_SE</th>\n",
              "      <th>WindDir9am_SSE</th>\n",
              "      <th>WindDir9am_SSW</th>\n",
              "      <th>WindDir9am_SW</th>\n",
              "      <th>WindDir9am_W</th>\n",
              "      <th>WindDir9am_WNW</th>\n",
              "      <th>WindDir9am_WSW</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-10-27</th>\n",
              "      <td>14.8</td>\n",
              "      <td>23.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-29</th>\n",
              "      <td>14.5</td>\n",
              "      <td>22.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>31.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1020.7</td>\n",
              "      <td>1017.5</td>\n",
              "      <td>16.2</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-01</th>\n",
              "      <td>18.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>5.2</td>\n",
              "      <td>48.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1014.7</td>\n",
              "      <td>1012.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>18.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-03</th>\n",
              "      <td>12.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>44.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1018.1</td>\n",
              "      <td>1016.3</td>\n",
              "      <td>17.6</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-04</th>\n",
              "      <td>14.4</td>\n",
              "      <td>18.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>48.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1022.3</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>14.8</td>\n",
              "      <td>17.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            MinTemp  MaxTemp  ...  WindDir9am_WNW  WindDir9am_WSW\n",
              "Date                          ...                                \n",
              "2010-10-27     14.8     23.8  ...               0               0\n",
              "2010-10-29     14.5     22.1  ...               1               0\n",
              "2010-11-01     18.1     20.4  ...               0               0\n",
              "2010-11-03     12.0     23.9  ...               0               0\n",
              "2010-11-04     14.4     18.1  ...               0               0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whnHtkvkwOKq",
        "colab_type": "code",
        "outputId": "926cf0ee-d6d6-4934-9737-81a2c40f6f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "#standardize our data - using MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "scaler.fit(_SydneyData)\n",
        "_SydneyData = pd.DataFrame(scaler.transform(_SydneyData), index=_SydneyData.index, columns=_SydneyData.columns)\n",
        "_SydneyData.iloc[4:10]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "      <th>WindGustDir_E</th>\n",
              "      <th>WindGustDir_ENE</th>\n",
              "      <th>WindGustDir_ESE</th>\n",
              "      <th>WindGustDir_N</th>\n",
              "      <th>WindGustDir_NE</th>\n",
              "      <th>WindGustDir_NNE</th>\n",
              "      <th>WindGustDir_NNW</th>\n",
              "      <th>WindGustDir_NW</th>\n",
              "      <th>WindGustDir_S</th>\n",
              "      <th>WindGustDir_SE</th>\n",
              "      <th>WindGustDir_SSE</th>\n",
              "      <th>WindGustDir_SSW</th>\n",
              "      <th>WindGustDir_SW</th>\n",
              "      <th>WindGustDir_W</th>\n",
              "      <th>WindGustDir_WNW</th>\n",
              "      <th>WindGustDir_WSW</th>\n",
              "      <th>WindDir3pm_E</th>\n",
              "      <th>WindDir3pm_ENE</th>\n",
              "      <th>WindDir3pm_ESE</th>\n",
              "      <th>WindDir3pm_N</th>\n",
              "      <th>WindDir3pm_NE</th>\n",
              "      <th>WindDir3pm_NNE</th>\n",
              "      <th>WindDir3pm_NNW</th>\n",
              "      <th>WindDir3pm_NW</th>\n",
              "      <th>WindDir3pm_S</th>\n",
              "      <th>WindDir3pm_SE</th>\n",
              "      <th>WindDir3pm_SSE</th>\n",
              "      <th>WindDir3pm_SSW</th>\n",
              "      <th>WindDir3pm_SW</th>\n",
              "      <th>WindDir3pm_W</th>\n",
              "      <th>WindDir3pm_WNW</th>\n",
              "      <th>WindDir3pm_WSW</th>\n",
              "      <th>WindDir9am_E</th>\n",
              "      <th>WindDir9am_ENE</th>\n",
              "      <th>WindDir9am_ESE</th>\n",
              "      <th>WindDir9am_N</th>\n",
              "      <th>WindDir9am_NE</th>\n",
              "      <th>WindDir9am_NNE</th>\n",
              "      <th>WindDir9am_NNW</th>\n",
              "      <th>WindDir9am_NW</th>\n",
              "      <th>WindDir9am_S</th>\n",
              "      <th>WindDir9am_SE</th>\n",
              "      <th>WindDir9am_SSE</th>\n",
              "      <th>WindDir9am_SSW</th>\n",
              "      <th>WindDir9am_SW</th>\n",
              "      <th>WindDir9am_W</th>\n",
              "      <th>WindDir9am_WNW</th>\n",
              "      <th>WindDir9am_WSW</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-10-27</th>\n",
              "      <td>0.462264</td>\n",
              "      <td>0.485944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.696203</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.434889</td>\n",
              "      <td>0.475369</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.408511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-29</th>\n",
              "      <td>0.448113</td>\n",
              "      <td>0.417671</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.772152</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.550369</td>\n",
              "      <td>0.544335</td>\n",
              "      <td>0.390947</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-01</th>\n",
              "      <td>0.617925</td>\n",
              "      <td>0.349398</td>\n",
              "      <td>0.189781</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.721519</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.402948</td>\n",
              "      <td>0.411330</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.323404</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-03</th>\n",
              "      <td>0.330189</td>\n",
              "      <td>0.489960</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.556962</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.514778</td>\n",
              "      <td>0.448560</td>\n",
              "      <td>0.412766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-04</th>\n",
              "      <td>0.443396</td>\n",
              "      <td>0.257028</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.784810</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.589681</td>\n",
              "      <td>0.618227</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.280851</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-11-05</th>\n",
              "      <td>0.396226</td>\n",
              "      <td>0.301205</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>0.491525</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>0.628993</td>\n",
              "      <td>0.657635</td>\n",
              "      <td>0.349794</td>\n",
              "      <td>0.289362</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             MinTemp   MaxTemp  ...  WindDir9am_WNW  WindDir9am_WSW\n",
              "Date                            ...                                \n",
              "2010-10-27  0.462264  0.485944  ...             0.0             0.0\n",
              "2010-10-29  0.448113  0.417671  ...             1.0             0.0\n",
              "2010-11-01  0.617925  0.349398  ...             0.0             0.0\n",
              "2010-11-03  0.330189  0.489960  ...             0.0             0.0\n",
              "2010-11-04  0.443396  0.257028  ...             0.0             0.0\n",
              "2010-11-05  0.396226  0.301205  ...             0.0             0.0\n",
              "\n",
              "[6 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iguvW6oJ6HfD",
        "colab_type": "code",
        "outputId": "b84d256a-96f2-4490-bc6e-29bc6ae8a7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Top 5 feature selection in Sydney Data\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "_x = _SydneyData.loc[:, _SydneyData.columns != \"RainTomorrow\"]\n",
        "_y = _SydneyData[[\"RainTomorrow\"]]\n",
        "_selector = SelectKBest(chi2, k = 5)\n",
        "_selector.fit(_x, _y)\n",
        "_x_new = _selector.transform(_x)\n",
        "print(_x.columns[_selector.get_support(indices = True)])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Rainfall', 'RainToday', 'WindGustDir_S', 'WindDir3pm_S',\n",
            "       'WindDir3pm_SSW'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVdI2doR6Rdl",
        "colab_type": "code",
        "outputId": "989ca55f-4b6d-481d-bfd6-dada71c8d810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# _SydneyData = _SydneyData[[\"Cloud3pm\", \"RainToday\", \"WindDir3pm_SSW\", \"RainTomorrow\"]]\n",
        "# 3 features\n",
        "# _Data = _SydneyData[[\"Cloud3pm\", \"RainToday\", \"WindDir3pm_SSW\"]]\n",
        "# all features\n",
        "# _Data = _SydneyData.loc[:, _SydneyData.columns != \"RainTomorrow\"]\n",
        "# 5 features\n",
        "# _Data = _SydneyData[[\"Rainfall\", \"Sunshine\", \"Cloud3pm\", \"RainToday\", \"WindDir3pm_SSW\"]]\n",
        "\n",
        "_Data = _x_new\n",
        "_Label = _SydneyData[\"RainTomorrow\"]\n",
        "\n",
        "_Data.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1596, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxs3cWPJZxrE",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7nsTM9kxVIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the important features as assign them as X\n",
        "df = df[['Rainfall','RainToday','RainTomorrow']]\n",
        "X = df[['Rainfall']] # let's use only one feature Rainfall\n",
        "y = df[['RainTomorrow']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWoGtJTQxjN1",
        "colab_type": "code",
        "outputId": "2ec62b87-4293-43db-a4dd-c0598af5b931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#deicision tree suitable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "t0=time.time()\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
        "clf_dt = DecisionTreeClassifier(random_state=0)\n",
        "clf_dt.fit(X_train,y_train)\n",
        "y_pred = clf_dt.predict(X_test)\n",
        "score = accuracy_score(y_test,y_pred)\n",
        "print('Accuracy :',score)\n",
        "print('Time taken :' , time.time()-t0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7888691953208082\n",
            "Time taken : 0.12266778945922852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEeaaf312SWr",
        "colab_type": "text"
      },
      "source": [
        "Create neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPHf1p0c2Rfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split the dataset into three sets.\n",
        "#train - 80% valid - 10% test - 10%\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOBLtpkG2bLU",
        "colab_type": "code",
        "outputId": "3fbd7dbd-e4fc-419c-e9c2-63eb9af4512e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45136, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbwxWW_D1tRm",
        "colab_type": "code",
        "outputId": "7fd26c02-dc66-4bdb-e65d-2ec8a612b45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical, normalize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Activation, Input, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePp9no0o5tEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Activation, Input, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Q4tvBJ6BxB",
        "colab_type": "code",
        "outputId": "2e2aa597-6464-4526-bbc1-f56d2796602c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_Data = _x_new\n",
        "_Label = _SydneyData[\"RainTomorrow\"]\n",
        "\n",
        "_Data.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1596, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkygESSjRWE",
        "colab_type": "text"
      },
      "source": [
        "To increase the stability of a neural network, batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9UQcyrm6oLI",
        "colab_type": "code",
        "outputId": "560b8a10-0797-4db6-b983-e4811d5b6366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53616
        }
      },
      "source": [
        "_TrainData, _TestData, _TrainLabel, _TestLabel = train_test_split(_Data, _Label, test_size = 0.25)\n",
        "\n",
        "_i = Input(shape = (_Data.shape[1],))\n",
        "_x = Dense(64, kernel_regularizer = l2(0.005))(_i)\n",
        "_x = BatchNormalization()(_x)\n",
        "_x = Activation(\"relu\")(_x)\n",
        "_x = Dense(64, kernel_regularizer = l2(0.005))(_x)\n",
        "_x = BatchNormalization()(_x)\n",
        "_x = Activation(\"relu\")(_x)\n",
        "_o = Dense(1, activation = \"sigmoid\")(_x)\n",
        "\n",
        "_model = Model(_i, _o)\n",
        "_model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "_callback = EarlyStopping(monitor='val_loss', patience=500, verbose=1, mode='auto')\n",
        "_model.fit(_TrainData, _TrainLabel, validation_data = (_TestData, _TestLabel), batch_size = 32, epochs = 10000, callbacks = [_callback])\n",
        "_, _train_acc = _model.evaluate(_TrainData, _TrainLabel, verbose=0)\n",
        "_, _test_acc = _model.evaluate(_TestData, _TestLabel, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (_train_acc, _test_acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1197 samples, validate on 399 samples\n",
            "Epoch 1/10000\n",
            "1197/1197 [==============================] - 1s 680us/step - loss: 1.0222 - acc: 0.7068 - val_loss: 0.8609 - val_acc: 0.7694\n",
            "Epoch 2/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.8200 - acc: 0.7703 - val_loss: 0.7995 - val_acc: 0.7594\n",
            "Epoch 3/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.7635 - acc: 0.7694 - val_loss: 0.7426 - val_acc: 0.7845\n",
            "Epoch 4/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.7317 - acc: 0.7753 - val_loss: 0.7189 - val_acc: 0.7794\n",
            "Epoch 5/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.7078 - acc: 0.7845 - val_loss: 0.6940 - val_acc: 0.7920\n",
            "Epoch 6/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.6847 - acc: 0.7703 - val_loss: 0.6857 - val_acc: 0.7794\n",
            "Epoch 7/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.6656 - acc: 0.7703 - val_loss: 0.6615 - val_acc: 0.7669\n",
            "Epoch 8/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.6497 - acc: 0.7836 - val_loss: 0.6489 - val_acc: 0.7820\n",
            "Epoch 9/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.6342 - acc: 0.7778 - val_loss: 0.6344 - val_acc: 0.7769\n",
            "Epoch 10/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.6252 - acc: 0.7786 - val_loss: 0.6259 - val_acc: 0.7845\n",
            "Epoch 11/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.6185 - acc: 0.7836 - val_loss: 0.6189 - val_acc: 0.7769\n",
            "Epoch 12/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.6055 - acc: 0.7744 - val_loss: 0.6074 - val_acc: 0.8020\n",
            "Epoch 13/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.6015 - acc: 0.7728 - val_loss: 0.6066 - val_acc: 0.7619\n",
            "Epoch 14/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.5925 - acc: 0.7719 - val_loss: 0.5959 - val_acc: 0.7469\n",
            "Epoch 15/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5836 - acc: 0.7719 - val_loss: 0.5842 - val_acc: 0.7970\n",
            "Epoch 16/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.5804 - acc: 0.7786 - val_loss: 0.5822 - val_acc: 0.7870\n",
            "Epoch 17/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.5720 - acc: 0.7728 - val_loss: 0.5762 - val_acc: 0.7744\n",
            "Epoch 18/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.5639 - acc: 0.7694 - val_loss: 0.5753 - val_acc: 0.7619\n",
            "Epoch 19/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.5620 - acc: 0.7786 - val_loss: 0.5678 - val_acc: 0.7619\n",
            "Epoch 20/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.5545 - acc: 0.7803 - val_loss: 0.5622 - val_acc: 0.7544\n",
            "Epoch 21/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.5517 - acc: 0.7786 - val_loss: 0.5695 - val_acc: 0.7794\n",
            "Epoch 22/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.5536 - acc: 0.7694 - val_loss: 0.5535 - val_acc: 0.7769\n",
            "Epoch 23/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.5432 - acc: 0.7794 - val_loss: 0.5501 - val_acc: 0.7694\n",
            "Epoch 24/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.5442 - acc: 0.7811 - val_loss: 0.5422 - val_acc: 0.7945\n",
            "Epoch 25/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5401 - acc: 0.7669 - val_loss: 0.5432 - val_acc: 0.7895\n",
            "Epoch 26/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.5329 - acc: 0.7845 - val_loss: 0.5358 - val_acc: 0.7920\n",
            "Epoch 27/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.5346 - acc: 0.7811 - val_loss: 0.5343 - val_acc: 0.7920\n",
            "Epoch 28/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.5299 - acc: 0.7836 - val_loss: 0.5329 - val_acc: 0.8020\n",
            "Epoch 29/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5241 - acc: 0.7694 - val_loss: 0.5284 - val_acc: 0.7744\n",
            "Epoch 30/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.5277 - acc: 0.7803 - val_loss: 0.5262 - val_acc: 0.7870\n",
            "Epoch 31/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5227 - acc: 0.7786 - val_loss: 0.5214 - val_acc: 0.7995\n",
            "Epoch 32/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.5148 - acc: 0.7744 - val_loss: 0.5241 - val_acc: 0.7694\n",
            "Epoch 33/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.5177 - acc: 0.7728 - val_loss: 0.5226 - val_acc: 0.7820\n",
            "Epoch 34/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5098 - acc: 0.7820 - val_loss: 0.5312 - val_acc: 0.7694\n",
            "Epoch 35/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.5180 - acc: 0.7786 - val_loss: 0.5179 - val_acc: 0.7920\n",
            "Epoch 36/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.5126 - acc: 0.7719 - val_loss: 0.5159 - val_acc: 0.7970\n",
            "Epoch 37/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.5098 - acc: 0.7820 - val_loss: 0.5153 - val_acc: 0.7920\n",
            "Epoch 38/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.5081 - acc: 0.7744 - val_loss: 0.5146 - val_acc: 0.7744\n",
            "Epoch 39/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.5135 - acc: 0.7619 - val_loss: 0.5168 - val_acc: 0.7769\n",
            "Epoch 40/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.5067 - acc: 0.7870 - val_loss: 0.5095 - val_acc: 0.7920\n",
            "Epoch 41/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.5039 - acc: 0.7836 - val_loss: 0.5105 - val_acc: 0.7845\n",
            "Epoch 42/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.5043 - acc: 0.7719 - val_loss: 0.5108 - val_acc: 0.8020\n",
            "Epoch 43/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4992 - acc: 0.7803 - val_loss: 0.5177 - val_acc: 0.7393\n",
            "Epoch 44/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4975 - acc: 0.7794 - val_loss: 0.5059 - val_acc: 0.7895\n",
            "Epoch 45/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4987 - acc: 0.7853 - val_loss: 0.5016 - val_acc: 0.8045\n",
            "Epoch 46/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4948 - acc: 0.7794 - val_loss: 0.5068 - val_acc: 0.7920\n",
            "Epoch 47/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4946 - acc: 0.7761 - val_loss: 0.5082 - val_acc: 0.7769\n",
            "Epoch 48/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.5039 - acc: 0.7678 - val_loss: 0.5054 - val_acc: 0.7794\n",
            "Epoch 49/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4974 - acc: 0.7744 - val_loss: 0.5003 - val_acc: 0.7970\n",
            "Epoch 50/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4975 - acc: 0.7794 - val_loss: 0.4960 - val_acc: 0.7794\n",
            "Epoch 51/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4908 - acc: 0.7845 - val_loss: 0.4971 - val_acc: 0.7920\n",
            "Epoch 52/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4922 - acc: 0.7828 - val_loss: 0.5056 - val_acc: 0.7895\n",
            "Epoch 53/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4964 - acc: 0.7736 - val_loss: 0.5058 - val_acc: 0.7694\n",
            "Epoch 54/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4935 - acc: 0.7794 - val_loss: 0.5004 - val_acc: 0.7744\n",
            "Epoch 55/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4929 - acc: 0.7778 - val_loss: 0.5054 - val_acc: 0.7594\n",
            "Epoch 56/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4923 - acc: 0.7820 - val_loss: 0.4983 - val_acc: 0.7769\n",
            "Epoch 57/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4918 - acc: 0.7828 - val_loss: 0.4992 - val_acc: 0.7769\n",
            "Epoch 58/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4895 - acc: 0.7761 - val_loss: 0.5010 - val_acc: 0.7619\n",
            "Epoch 59/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4924 - acc: 0.7828 - val_loss: 0.4935 - val_acc: 0.7995\n",
            "Epoch 60/10000\n",
            "1197/1197 [==============================] - 0s 94us/step - loss: 0.4896 - acc: 0.7828 - val_loss: 0.4970 - val_acc: 0.7769\n",
            "Epoch 61/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4871 - acc: 0.7761 - val_loss: 0.4967 - val_acc: 0.7945\n",
            "Epoch 62/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4877 - acc: 0.7828 - val_loss: 0.4906 - val_acc: 0.7794\n",
            "Epoch 63/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4894 - acc: 0.7794 - val_loss: 0.4969 - val_acc: 0.7995\n",
            "Epoch 64/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4850 - acc: 0.7769 - val_loss: 0.5359 - val_acc: 0.7694\n",
            "Epoch 65/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4901 - acc: 0.7828 - val_loss: 0.4991 - val_acc: 0.7870\n",
            "Epoch 66/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4867 - acc: 0.7820 - val_loss: 0.4931 - val_acc: 0.8020\n",
            "Epoch 67/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4857 - acc: 0.7794 - val_loss: 0.4922 - val_acc: 0.7895\n",
            "Epoch 68/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4892 - acc: 0.7744 - val_loss: 0.4962 - val_acc: 0.7870\n",
            "Epoch 69/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4886 - acc: 0.7811 - val_loss: 0.4958 - val_acc: 0.7870\n",
            "Epoch 70/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4832 - acc: 0.7794 - val_loss: 0.4926 - val_acc: 0.7870\n",
            "Epoch 71/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4849 - acc: 0.7786 - val_loss: 0.4958 - val_acc: 0.7769\n",
            "Epoch 72/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4892 - acc: 0.7686 - val_loss: 0.4931 - val_acc: 0.7970\n",
            "Epoch 73/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4816 - acc: 0.7820 - val_loss: 0.4908 - val_acc: 0.7895\n",
            "Epoch 74/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4796 - acc: 0.7761 - val_loss: 0.4926 - val_acc: 0.7970\n",
            "Epoch 75/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4853 - acc: 0.7820 - val_loss: 0.4898 - val_acc: 0.7769\n",
            "Epoch 76/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4859 - acc: 0.7794 - val_loss: 0.4925 - val_acc: 0.7920\n",
            "Epoch 77/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4839 - acc: 0.7870 - val_loss: 0.4891 - val_acc: 0.7895\n",
            "Epoch 78/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4831 - acc: 0.7828 - val_loss: 0.4911 - val_acc: 0.7769\n",
            "Epoch 79/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7778 - val_loss: 0.4884 - val_acc: 0.7895\n",
            "Epoch 80/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4846 - acc: 0.7803 - val_loss: 0.4964 - val_acc: 0.7594\n",
            "Epoch 81/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4850 - acc: 0.7786 - val_loss: 0.4854 - val_acc: 0.7895\n",
            "Epoch 82/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4806 - acc: 0.7786 - val_loss: 0.5159 - val_acc: 0.7769\n",
            "Epoch 83/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4808 - acc: 0.7736 - val_loss: 0.4997 - val_acc: 0.7820\n",
            "Epoch 84/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4868 - acc: 0.7786 - val_loss: 0.4862 - val_acc: 0.7794\n",
            "Epoch 85/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4833 - acc: 0.7803 - val_loss: 0.4930 - val_acc: 0.7794\n",
            "Epoch 86/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4835 - acc: 0.7803 - val_loss: 0.4924 - val_acc: 0.7769\n",
            "Epoch 87/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4821 - acc: 0.7845 - val_loss: 0.4967 - val_acc: 0.7393\n",
            "Epoch 88/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4822 - acc: 0.7786 - val_loss: 0.4935 - val_acc: 0.7544\n",
            "Epoch 89/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4839 - acc: 0.7744 - val_loss: 0.4891 - val_acc: 0.7995\n",
            "Epoch 90/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4816 - acc: 0.7753 - val_loss: 0.4899 - val_acc: 0.8020\n",
            "Epoch 91/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4788 - acc: 0.7811 - val_loss: 0.4870 - val_acc: 0.7719\n",
            "Epoch 92/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4803 - acc: 0.7828 - val_loss: 0.4881 - val_acc: 0.7920\n",
            "Epoch 93/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4770 - acc: 0.7845 - val_loss: 0.4892 - val_acc: 0.7920\n",
            "Epoch 94/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4829 - acc: 0.7820 - val_loss: 0.4844 - val_acc: 0.8020\n",
            "Epoch 95/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4807 - acc: 0.7870 - val_loss: 0.4937 - val_acc: 0.7594\n",
            "Epoch 96/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4808 - acc: 0.7744 - val_loss: 0.4935 - val_acc: 0.7719\n",
            "Epoch 97/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4833 - acc: 0.7761 - val_loss: 0.4885 - val_acc: 0.7895\n",
            "Epoch 98/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4805 - acc: 0.7861 - val_loss: 0.4888 - val_acc: 0.7920\n",
            "Epoch 99/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4774 - acc: 0.7769 - val_loss: 0.4944 - val_acc: 0.7920\n",
            "Epoch 100/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4836 - acc: 0.7853 - val_loss: 0.4899 - val_acc: 0.7920\n",
            "Epoch 101/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4834 - acc: 0.7728 - val_loss: 0.4923 - val_acc: 0.7794\n",
            "Epoch 102/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4823 - acc: 0.7786 - val_loss: 0.4882 - val_acc: 0.7820\n",
            "Epoch 103/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7845 - val_loss: 0.4949 - val_acc: 0.7694\n",
            "Epoch 104/10000\n",
            "1197/1197 [==============================] - 0s 90us/step - loss: 0.4840 - acc: 0.7811 - val_loss: 0.4909 - val_acc: 0.7744\n",
            "Epoch 105/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4815 - acc: 0.7853 - val_loss: 0.4879 - val_acc: 0.7920\n",
            "Epoch 106/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4829 - acc: 0.7719 - val_loss: 0.4876 - val_acc: 0.7845\n",
            "Epoch 107/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4800 - acc: 0.7769 - val_loss: 0.4900 - val_acc: 0.8020\n",
            "Epoch 108/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4761 - acc: 0.7728 - val_loss: 0.5019 - val_acc: 0.7419\n",
            "Epoch 109/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4802 - acc: 0.7753 - val_loss: 0.4935 - val_acc: 0.7544\n",
            "Epoch 110/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4815 - acc: 0.7803 - val_loss: 0.4950 - val_acc: 0.7820\n",
            "Epoch 111/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4796 - acc: 0.7811 - val_loss: 0.4905 - val_acc: 0.7895\n",
            "Epoch 112/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4809 - acc: 0.7778 - val_loss: 0.4865 - val_acc: 0.7694\n",
            "Epoch 113/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4836 - acc: 0.7736 - val_loss: 0.4876 - val_acc: 0.7895\n",
            "Epoch 114/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4801 - acc: 0.7803 - val_loss: 0.4936 - val_acc: 0.7820\n",
            "Epoch 115/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4802 - acc: 0.7820 - val_loss: 0.4857 - val_acc: 0.7870\n",
            "Epoch 116/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4779 - acc: 0.7903 - val_loss: 0.4945 - val_acc: 0.7820\n",
            "Epoch 117/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.4773 - acc: 0.7794 - val_loss: 0.4893 - val_acc: 0.7845\n",
            "Epoch 118/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4769 - acc: 0.7820 - val_loss: 0.4981 - val_acc: 0.7419\n",
            "Epoch 119/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4802 - acc: 0.7828 - val_loss: 0.5088 - val_acc: 0.7393\n",
            "Epoch 120/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4818 - acc: 0.7744 - val_loss: 0.4895 - val_acc: 0.7744\n",
            "Epoch 121/10000\n",
            "1197/1197 [==============================] - 0s 68us/step - loss: 0.4875 - acc: 0.7719 - val_loss: 0.4871 - val_acc: 0.7845\n",
            "Epoch 122/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4865 - acc: 0.7886 - val_loss: 0.5718 - val_acc: 0.7393\n",
            "Epoch 123/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4792 - acc: 0.7803 - val_loss: 0.5168 - val_acc: 0.7393\n",
            "Epoch 124/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4769 - acc: 0.7803 - val_loss: 0.5172 - val_acc: 0.7393\n",
            "Epoch 125/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4822 - acc: 0.7820 - val_loss: 0.4834 - val_acc: 0.7794\n",
            "Epoch 126/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4772 - acc: 0.7828 - val_loss: 0.4843 - val_acc: 0.7794\n",
            "Epoch 127/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4808 - acc: 0.7769 - val_loss: 0.4892 - val_acc: 0.7794\n",
            "Epoch 128/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4796 - acc: 0.7836 - val_loss: 0.4909 - val_acc: 0.7845\n",
            "Epoch 129/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4789 - acc: 0.7728 - val_loss: 0.4901 - val_acc: 0.7895\n",
            "Epoch 130/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4833 - acc: 0.7711 - val_loss: 0.4933 - val_acc: 0.7794\n",
            "Epoch 131/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4808 - acc: 0.7828 - val_loss: 0.5087 - val_acc: 0.7393\n",
            "Epoch 132/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7794 - val_loss: 0.4865 - val_acc: 0.7769\n",
            "Epoch 133/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4779 - acc: 0.7794 - val_loss: 0.4905 - val_acc: 0.7845\n",
            "Epoch 134/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4799 - acc: 0.7736 - val_loss: 0.4964 - val_acc: 0.7820\n",
            "Epoch 135/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4774 - acc: 0.7861 - val_loss: 0.5027 - val_acc: 0.7870\n",
            "Epoch 136/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4766 - acc: 0.7820 - val_loss: 0.5348 - val_acc: 0.7794\n",
            "Epoch 137/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4804 - acc: 0.7686 - val_loss: 0.4951 - val_acc: 0.7920\n",
            "Epoch 138/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4760 - acc: 0.7836 - val_loss: 0.5123 - val_acc: 0.7594\n",
            "Epoch 139/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4798 - acc: 0.7828 - val_loss: 0.4931 - val_acc: 0.7895\n",
            "Epoch 140/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4809 - acc: 0.7761 - val_loss: 0.4859 - val_acc: 0.7895\n",
            "Epoch 141/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4815 - acc: 0.7794 - val_loss: 0.4897 - val_acc: 0.7995\n",
            "Epoch 142/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4809 - acc: 0.7719 - val_loss: 0.5947 - val_acc: 0.7393\n",
            "Epoch 143/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4770 - acc: 0.7786 - val_loss: 0.5187 - val_acc: 0.7393\n",
            "Epoch 144/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4837 - acc: 0.7803 - val_loss: 0.5053 - val_acc: 0.7393\n",
            "Epoch 145/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4789 - acc: 0.7803 - val_loss: 0.4930 - val_acc: 0.7820\n",
            "Epoch 146/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4791 - acc: 0.7845 - val_loss: 0.4958 - val_acc: 0.7895\n",
            "Epoch 147/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4771 - acc: 0.7828 - val_loss: 0.4942 - val_acc: 0.7820\n",
            "Epoch 148/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4777 - acc: 0.7769 - val_loss: 0.5022 - val_acc: 0.7820\n",
            "Epoch 149/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4761 - acc: 0.7886 - val_loss: 0.4886 - val_acc: 0.7995\n",
            "Epoch 150/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4807 - acc: 0.7753 - val_loss: 0.4892 - val_acc: 0.8020\n",
            "Epoch 151/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4812 - acc: 0.7811 - val_loss: 0.5307 - val_acc: 0.7393\n",
            "Epoch 152/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4801 - acc: 0.7778 - val_loss: 0.5035 - val_acc: 0.7794\n",
            "Epoch 153/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4799 - acc: 0.7878 - val_loss: 0.4867 - val_acc: 0.7995\n",
            "Epoch 154/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4796 - acc: 0.7761 - val_loss: 0.4856 - val_acc: 0.7794\n",
            "Epoch 155/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4748 - acc: 0.7861 - val_loss: 0.4928 - val_acc: 0.7870\n",
            "Epoch 156/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4821 - acc: 0.7794 - val_loss: 0.4880 - val_acc: 0.7870\n",
            "Epoch 157/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4745 - acc: 0.7903 - val_loss: 0.5956 - val_acc: 0.7393\n",
            "Epoch 158/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4785 - acc: 0.7778 - val_loss: 0.4895 - val_acc: 0.7845\n",
            "Epoch 159/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4739 - acc: 0.7761 - val_loss: 0.5024 - val_acc: 0.7820\n",
            "Epoch 160/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4769 - acc: 0.7803 - val_loss: 0.4921 - val_acc: 0.7719\n",
            "Epoch 161/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4799 - acc: 0.7728 - val_loss: 0.4861 - val_acc: 0.7820\n",
            "Epoch 162/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4798 - acc: 0.7769 - val_loss: 0.4833 - val_acc: 0.7744\n",
            "Epoch 163/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4800 - acc: 0.7753 - val_loss: 0.4874 - val_acc: 0.7895\n",
            "Epoch 164/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7769 - val_loss: 0.4969 - val_acc: 0.7419\n",
            "Epoch 165/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4819 - acc: 0.7661 - val_loss: 0.5199 - val_acc: 0.7769\n",
            "Epoch 166/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4892 - acc: 0.7786 - val_loss: 0.6063 - val_acc: 0.7393\n",
            "Epoch 167/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4794 - acc: 0.7845 - val_loss: 0.5100 - val_acc: 0.7393\n",
            "Epoch 168/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4799 - acc: 0.7786 - val_loss: 0.4955 - val_acc: 0.7368\n",
            "Epoch 169/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4776 - acc: 0.7778 - val_loss: 0.5549 - val_acc: 0.7769\n",
            "Epoch 170/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4806 - acc: 0.7794 - val_loss: 0.5718 - val_acc: 0.7769\n",
            "Epoch 171/10000\n",
            "1197/1197 [==============================] - 0s 92us/step - loss: 0.4815 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7820\n",
            "Epoch 172/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4796 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.7744\n",
            "Epoch 173/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4782 - acc: 0.7794 - val_loss: 0.4844 - val_acc: 0.7945\n",
            "Epoch 174/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4764 - acc: 0.7945 - val_loss: 0.6087 - val_acc: 0.7393\n",
            "Epoch 175/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4786 - acc: 0.7811 - val_loss: 0.4884 - val_acc: 0.7895\n",
            "Epoch 176/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4807 - acc: 0.7778 - val_loss: 0.5447 - val_acc: 0.7769\n",
            "Epoch 177/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4770 - acc: 0.7845 - val_loss: 0.4882 - val_acc: 0.7769\n",
            "Epoch 178/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4749 - acc: 0.7895 - val_loss: 0.5064 - val_acc: 0.7794\n",
            "Epoch 179/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4760 - acc: 0.7870 - val_loss: 0.5158 - val_acc: 0.7393\n",
            "Epoch 180/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4804 - acc: 0.7761 - val_loss: 0.4909 - val_acc: 0.7820\n",
            "Epoch 181/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4773 - acc: 0.7836 - val_loss: 0.5207 - val_acc: 0.7393\n",
            "Epoch 182/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4813 - acc: 0.7786 - val_loss: 0.4856 - val_acc: 0.7845\n",
            "Epoch 183/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4821 - acc: 0.7778 - val_loss: 0.4972 - val_acc: 0.7794\n",
            "Epoch 184/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4768 - acc: 0.7845 - val_loss: 0.4873 - val_acc: 0.7594\n",
            "Epoch 185/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4795 - acc: 0.7753 - val_loss: 0.4893 - val_acc: 0.7744\n",
            "Epoch 186/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4753 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7845\n",
            "Epoch 187/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4796 - acc: 0.7811 - val_loss: 0.4867 - val_acc: 0.7870\n",
            "Epoch 188/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4781 - acc: 0.7811 - val_loss: 0.4914 - val_acc: 0.7845\n",
            "Epoch 189/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4760 - acc: 0.7853 - val_loss: 0.4904 - val_acc: 0.7769\n",
            "Epoch 190/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4810 - acc: 0.7853 - val_loss: 0.5640 - val_acc: 0.7243\n",
            "Epoch 191/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4823 - acc: 0.7786 - val_loss: 0.4853 - val_acc: 0.7694\n",
            "Epoch 192/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4783 - acc: 0.7719 - val_loss: 0.4942 - val_acc: 0.7870\n",
            "Epoch 193/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4752 - acc: 0.7778 - val_loss: 0.4868 - val_acc: 0.7895\n",
            "Epoch 194/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4822 - acc: 0.7761 - val_loss: 0.5224 - val_acc: 0.7243\n",
            "Epoch 195/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4811 - acc: 0.7778 - val_loss: 0.4996 - val_acc: 0.7769\n",
            "Epoch 196/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4740 - acc: 0.7878 - val_loss: 0.5793 - val_acc: 0.7243\n",
            "Epoch 197/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4821 - acc: 0.7836 - val_loss: 0.4955 - val_acc: 0.7744\n",
            "Epoch 198/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4764 - acc: 0.7886 - val_loss: 0.4888 - val_acc: 0.7920\n",
            "Epoch 199/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4753 - acc: 0.7836 - val_loss: 0.4928 - val_acc: 0.7719\n",
            "Epoch 200/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4803 - acc: 0.7836 - val_loss: 0.4870 - val_acc: 0.7920\n",
            "Epoch 201/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4778 - acc: 0.7736 - val_loss: 0.5115 - val_acc: 0.7769\n",
            "Epoch 202/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4755 - acc: 0.7811 - val_loss: 0.5015 - val_acc: 0.7368\n",
            "Epoch 203/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4792 - acc: 0.7769 - val_loss: 0.5096 - val_acc: 0.7268\n",
            "Epoch 204/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4826 - acc: 0.7836 - val_loss: 0.4908 - val_acc: 0.7845\n",
            "Epoch 205/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4790 - acc: 0.7836 - val_loss: 0.4966 - val_acc: 0.7794\n",
            "Epoch 206/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4792 - acc: 0.7878 - val_loss: 0.4889 - val_acc: 0.7870\n",
            "Epoch 207/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4830 - acc: 0.7736 - val_loss: 0.4925 - val_acc: 0.7494\n",
            "Epoch 208/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4836 - acc: 0.7594 - val_loss: 0.5397 - val_acc: 0.7769\n",
            "Epoch 209/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4792 - acc: 0.7644 - val_loss: 0.4866 - val_acc: 0.7920\n",
            "Epoch 210/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4753 - acc: 0.7903 - val_loss: 0.4965 - val_acc: 0.7419\n",
            "Epoch 211/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4775 - acc: 0.7811 - val_loss: 0.4933 - val_acc: 0.7794\n",
            "Epoch 212/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4759 - acc: 0.7870 - val_loss: 0.4966 - val_acc: 0.7845\n",
            "Epoch 213/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4781 - acc: 0.7828 - val_loss: 0.4888 - val_acc: 0.7870\n",
            "Epoch 214/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4817 - acc: 0.7728 - val_loss: 0.4958 - val_acc: 0.7419\n",
            "Epoch 215/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4757 - acc: 0.7753 - val_loss: 0.5059 - val_acc: 0.7769\n",
            "Epoch 216/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4773 - acc: 0.7836 - val_loss: 0.5035 - val_acc: 0.7794\n",
            "Epoch 217/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4763 - acc: 0.7786 - val_loss: 0.5131 - val_acc: 0.7644\n",
            "Epoch 218/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4775 - acc: 0.7836 - val_loss: 0.4940 - val_acc: 0.7895\n",
            "Epoch 219/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4759 - acc: 0.7828 - val_loss: 0.4953 - val_acc: 0.7769\n",
            "Epoch 220/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4813 - acc: 0.7769 - val_loss: 0.4990 - val_acc: 0.7920\n",
            "Epoch 221/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4793 - acc: 0.7744 - val_loss: 0.4882 - val_acc: 0.7895\n",
            "Epoch 222/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4790 - acc: 0.7761 - val_loss: 0.4846 - val_acc: 0.7744\n",
            "Epoch 223/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4790 - acc: 0.7761 - val_loss: 0.4957 - val_acc: 0.7393\n",
            "Epoch 224/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4759 - acc: 0.7836 - val_loss: 0.5229 - val_acc: 0.7243\n",
            "Epoch 225/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4760 - acc: 0.7744 - val_loss: 0.4975 - val_acc: 0.7794\n",
            "Epoch 226/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4751 - acc: 0.7886 - val_loss: 0.5340 - val_acc: 0.7243\n",
            "Epoch 227/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4753 - acc: 0.7736 - val_loss: 0.4959 - val_acc: 0.7619\n",
            "Epoch 228/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4796 - acc: 0.7686 - val_loss: 0.5149 - val_acc: 0.7318\n",
            "Epoch 229/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4763 - acc: 0.7769 - val_loss: 0.5334 - val_acc: 0.7243\n",
            "Epoch 230/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4800 - acc: 0.7719 - val_loss: 0.5044 - val_acc: 0.7769\n",
            "Epoch 231/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4806 - acc: 0.7769 - val_loss: 0.4895 - val_acc: 0.7870\n",
            "Epoch 232/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4754 - acc: 0.7753 - val_loss: 0.5038 - val_acc: 0.7794\n",
            "Epoch 233/10000\n",
            "1197/1197 [==============================] - 0s 92us/step - loss: 0.4770 - acc: 0.7878 - val_loss: 0.4867 - val_acc: 0.7744\n",
            "Epoch 234/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4751 - acc: 0.7803 - val_loss: 0.5184 - val_acc: 0.7769\n",
            "Epoch 235/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4772 - acc: 0.7786 - val_loss: 0.4942 - val_acc: 0.7444\n",
            "Epoch 236/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4800 - acc: 0.7778 - val_loss: 0.5331 - val_acc: 0.7343\n",
            "Epoch 237/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4789 - acc: 0.7694 - val_loss: 0.5001 - val_acc: 0.7619\n",
            "Epoch 238/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4771 - acc: 0.7753 - val_loss: 0.5002 - val_acc: 0.7845\n",
            "Epoch 239/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4768 - acc: 0.7803 - val_loss: 0.5057 - val_acc: 0.7920\n",
            "Epoch 240/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4777 - acc: 0.7845 - val_loss: 0.5260 - val_acc: 0.7820\n",
            "Epoch 241/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4791 - acc: 0.7753 - val_loss: 0.4883 - val_acc: 0.7820\n",
            "Epoch 242/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4732 - acc: 0.7811 - val_loss: 0.4901 - val_acc: 0.7920\n",
            "Epoch 243/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4759 - acc: 0.7803 - val_loss: 0.4838 - val_acc: 0.8020\n",
            "Epoch 244/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4726 - acc: 0.7794 - val_loss: 0.4957 - val_acc: 0.7769\n",
            "Epoch 245/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4747 - acc: 0.7744 - val_loss: 0.4879 - val_acc: 0.7744\n",
            "Epoch 246/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4746 - acc: 0.7736 - val_loss: 0.5242 - val_acc: 0.7769\n",
            "Epoch 247/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4798 - acc: 0.7744 - val_loss: 0.5140 - val_acc: 0.7243\n",
            "Epoch 248/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4784 - acc: 0.7761 - val_loss: 0.4864 - val_acc: 0.7744\n",
            "Epoch 249/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4788 - acc: 0.7753 - val_loss: 0.5240 - val_acc: 0.7243\n",
            "Epoch 250/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4766 - acc: 0.7861 - val_loss: 0.5099 - val_acc: 0.7419\n",
            "Epoch 251/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4743 - acc: 0.7836 - val_loss: 0.5145 - val_acc: 0.7895\n",
            "Epoch 252/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4760 - acc: 0.7786 - val_loss: 0.4910 - val_acc: 0.7845\n",
            "Epoch 253/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4739 - acc: 0.7769 - val_loss: 0.4855 - val_acc: 0.7845\n",
            "Epoch 254/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4782 - acc: 0.7769 - val_loss: 0.5163 - val_acc: 0.7769\n",
            "Epoch 255/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4781 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7243\n",
            "Epoch 256/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4740 - acc: 0.7778 - val_loss: 0.5678 - val_acc: 0.7243\n",
            "Epoch 257/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4772 - acc: 0.7820 - val_loss: 0.4951 - val_acc: 0.7845\n",
            "Epoch 258/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4760 - acc: 0.7803 - val_loss: 0.5426 - val_acc: 0.7243\n",
            "Epoch 259/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4754 - acc: 0.7794 - val_loss: 0.4932 - val_acc: 0.7719\n",
            "Epoch 260/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4756 - acc: 0.7761 - val_loss: 0.4976 - val_acc: 0.7769\n",
            "Epoch 261/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4783 - acc: 0.7761 - val_loss: 0.5673 - val_acc: 0.7243\n",
            "Epoch 262/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4838 - acc: 0.7753 - val_loss: 0.5148 - val_acc: 0.7343\n",
            "Epoch 263/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4760 - acc: 0.7820 - val_loss: 0.4974 - val_acc: 0.7995\n",
            "Epoch 264/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4775 - acc: 0.7811 - val_loss: 0.4945 - val_acc: 0.7920\n",
            "Epoch 265/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4733 - acc: 0.7820 - val_loss: 0.4882 - val_acc: 0.7845\n",
            "Epoch 266/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4785 - acc: 0.7828 - val_loss: 0.4884 - val_acc: 0.7845\n",
            "Epoch 267/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4797 - acc: 0.7820 - val_loss: 0.5023 - val_acc: 0.7393\n",
            "Epoch 268/10000\n",
            "1197/1197 [==============================] - 0s 88us/step - loss: 0.4793 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7820\n",
            "Epoch 269/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4758 - acc: 0.7828 - val_loss: 0.5011 - val_acc: 0.7820\n",
            "Epoch 270/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4744 - acc: 0.7803 - val_loss: 0.5014 - val_acc: 0.7769\n",
            "Epoch 271/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4794 - acc: 0.7761 - val_loss: 0.5440 - val_acc: 0.7343\n",
            "Epoch 272/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4785 - acc: 0.7786 - val_loss: 0.4884 - val_acc: 0.7920\n",
            "Epoch 273/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4757 - acc: 0.7845 - val_loss: 0.4908 - val_acc: 0.7794\n",
            "Epoch 274/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4764 - acc: 0.7778 - val_loss: 0.5120 - val_acc: 0.7343\n",
            "Epoch 275/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4788 - acc: 0.7811 - val_loss: 0.5085 - val_acc: 0.7769\n",
            "Epoch 276/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4798 - acc: 0.7736 - val_loss: 0.4961 - val_acc: 0.7444\n",
            "Epoch 277/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4769 - acc: 0.7811 - val_loss: 0.5042 - val_acc: 0.7393\n",
            "Epoch 278/10000\n",
            "1197/1197 [==============================] - 0s 92us/step - loss: 0.4770 - acc: 0.7828 - val_loss: 0.5002 - val_acc: 0.7845\n",
            "Epoch 279/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4792 - acc: 0.7711 - val_loss: 0.4875 - val_acc: 0.7895\n",
            "Epoch 280/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4749 - acc: 0.7836 - val_loss: 0.5178 - val_acc: 0.7343\n",
            "Epoch 281/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4751 - acc: 0.7853 - val_loss: 0.5524 - val_acc: 0.7769\n",
            "Epoch 282/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4806 - acc: 0.7761 - val_loss: 0.5040 - val_acc: 0.7393\n",
            "Epoch 283/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4757 - acc: 0.7828 - val_loss: 0.4859 - val_acc: 0.7895\n",
            "Epoch 284/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4766 - acc: 0.7845 - val_loss: 0.5044 - val_acc: 0.7870\n",
            "Epoch 285/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4740 - acc: 0.7820 - val_loss: 0.4926 - val_acc: 0.7820\n",
            "Epoch 286/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4765 - acc: 0.7753 - val_loss: 0.4912 - val_acc: 0.7794\n",
            "Epoch 287/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4768 - acc: 0.7753 - val_loss: 0.4852 - val_acc: 0.7895\n",
            "Epoch 288/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7753 - val_loss: 0.5053 - val_acc: 0.7820\n",
            "Epoch 289/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4774 - acc: 0.7786 - val_loss: 0.5591 - val_acc: 0.7243\n",
            "Epoch 290/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4802 - acc: 0.7753 - val_loss: 0.4865 - val_acc: 0.7845\n",
            "Epoch 291/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4783 - acc: 0.7853 - val_loss: 0.5054 - val_acc: 0.7769\n",
            "Epoch 292/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4794 - acc: 0.7711 - val_loss: 0.4850 - val_acc: 0.7744\n",
            "Epoch 293/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4753 - acc: 0.7811 - val_loss: 0.4876 - val_acc: 0.7820\n",
            "Epoch 294/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4752 - acc: 0.7828 - val_loss: 0.5266 - val_acc: 0.7243\n",
            "Epoch 295/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7870\n",
            "Epoch 296/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4747 - acc: 0.7870 - val_loss: 0.4924 - val_acc: 0.7920\n",
            "Epoch 297/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4789 - acc: 0.7828 - val_loss: 0.4917 - val_acc: 0.7995\n",
            "Epoch 298/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4763 - acc: 0.7786 - val_loss: 0.4918 - val_acc: 0.7895\n",
            "Epoch 299/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4730 - acc: 0.7786 - val_loss: 0.5362 - val_acc: 0.7243\n",
            "Epoch 300/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4791 - acc: 0.7811 - val_loss: 0.4963 - val_acc: 0.7368\n",
            "Epoch 301/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4795 - acc: 0.7686 - val_loss: 0.5021 - val_acc: 0.7769\n",
            "Epoch 302/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4783 - acc: 0.7744 - val_loss: 0.4894 - val_acc: 0.7995\n",
            "Epoch 303/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4809 - acc: 0.7828 - val_loss: 0.5318 - val_acc: 0.7243\n",
            "Epoch 304/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4751 - acc: 0.7820 - val_loss: 0.5100 - val_acc: 0.7318\n",
            "Epoch 305/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4754 - acc: 0.7794 - val_loss: 0.4861 - val_acc: 0.7970\n",
            "Epoch 306/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4729 - acc: 0.7836 - val_loss: 0.4876 - val_acc: 0.7845\n",
            "Epoch 307/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4791 - acc: 0.7811 - val_loss: 0.5049 - val_acc: 0.7769\n",
            "Epoch 308/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4775 - acc: 0.7694 - val_loss: 0.4954 - val_acc: 0.7769\n",
            "Epoch 309/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4760 - acc: 0.7753 - val_loss: 0.4976 - val_acc: 0.7619\n",
            "Epoch 310/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4755 - acc: 0.7886 - val_loss: 0.4872 - val_acc: 0.7920\n",
            "Epoch 311/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7878 - val_loss: 0.4875 - val_acc: 0.7895\n",
            "Epoch 312/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4767 - acc: 0.7845 - val_loss: 0.5184 - val_acc: 0.7769\n",
            "Epoch 313/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4817 - acc: 0.7719 - val_loss: 0.5119 - val_acc: 0.7393\n",
            "Epoch 314/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4764 - acc: 0.7845 - val_loss: 0.5257 - val_acc: 0.7343\n",
            "Epoch 315/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4784 - acc: 0.7803 - val_loss: 0.5038 - val_acc: 0.7694\n",
            "Epoch 316/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4752 - acc: 0.7803 - val_loss: 0.4868 - val_acc: 0.7945\n",
            "Epoch 317/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4771 - acc: 0.7794 - val_loss: 0.4896 - val_acc: 0.7845\n",
            "Epoch 318/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4782 - acc: 0.7769 - val_loss: 0.4847 - val_acc: 0.7945\n",
            "Epoch 319/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4808 - acc: 0.7711 - val_loss: 0.4888 - val_acc: 0.7845\n",
            "Epoch 320/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4750 - acc: 0.7820 - val_loss: 0.4891 - val_acc: 0.7845\n",
            "Epoch 321/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4789 - acc: 0.7811 - val_loss: 0.5282 - val_acc: 0.7243\n",
            "Epoch 322/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4738 - acc: 0.7736 - val_loss: 0.4943 - val_acc: 0.7594\n",
            "Epoch 323/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4781 - acc: 0.7736 - val_loss: 0.5017 - val_acc: 0.7769\n",
            "Epoch 324/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4780 - acc: 0.7769 - val_loss: 0.5014 - val_acc: 0.7769\n",
            "Epoch 325/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4740 - acc: 0.7769 - val_loss: 0.4963 - val_acc: 0.7820\n",
            "Epoch 326/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4759 - acc: 0.7878 - val_loss: 0.5151 - val_acc: 0.7669\n",
            "Epoch 327/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4778 - acc: 0.7794 - val_loss: 0.5338 - val_acc: 0.7243\n",
            "Epoch 328/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4797 - acc: 0.7686 - val_loss: 0.4994 - val_acc: 0.7494\n",
            "Epoch 329/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.7836 - val_loss: 0.4960 - val_acc: 0.7544\n",
            "Epoch 330/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4774 - acc: 0.7786 - val_loss: 0.5275 - val_acc: 0.7243\n",
            "Epoch 331/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4783 - acc: 0.7786 - val_loss: 0.4872 - val_acc: 0.7744\n",
            "Epoch 332/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4768 - acc: 0.7828 - val_loss: 0.4862 - val_acc: 0.7694\n",
            "Epoch 333/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4763 - acc: 0.7761 - val_loss: 0.4872 - val_acc: 0.7769\n",
            "Epoch 334/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4737 - acc: 0.7736 - val_loss: 0.4859 - val_acc: 0.7870\n",
            "Epoch 335/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4766 - acc: 0.7820 - val_loss: 0.4888 - val_acc: 0.7945\n",
            "Epoch 336/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7878 - val_loss: 0.4871 - val_acc: 0.7920\n",
            "Epoch 337/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4784 - acc: 0.7769 - val_loss: 0.4891 - val_acc: 0.7845\n",
            "Epoch 338/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4752 - acc: 0.7928 - val_loss: 0.5511 - val_acc: 0.7243\n",
            "Epoch 339/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4768 - acc: 0.7828 - val_loss: 0.5002 - val_acc: 0.7744\n",
            "Epoch 340/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7861 - val_loss: 0.4966 - val_acc: 0.7769\n",
            "Epoch 341/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4772 - acc: 0.7786 - val_loss: 0.4960 - val_acc: 0.7794\n",
            "Epoch 342/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4776 - acc: 0.7820 - val_loss: 0.4865 - val_acc: 0.7970\n",
            "Epoch 343/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4758 - acc: 0.7786 - val_loss: 0.4848 - val_acc: 0.7719\n",
            "Epoch 344/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4714 - acc: 0.7853 - val_loss: 0.5227 - val_acc: 0.7243\n",
            "Epoch 345/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4757 - acc: 0.7744 - val_loss: 0.4900 - val_acc: 0.7744\n",
            "Epoch 346/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4752 - acc: 0.7786 - val_loss: 0.4867 - val_acc: 0.7794\n",
            "Epoch 347/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4712 - acc: 0.7861 - val_loss: 0.5055 - val_acc: 0.7343\n",
            "Epoch 348/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4766 - acc: 0.7778 - val_loss: 0.4879 - val_acc: 0.7744\n",
            "Epoch 349/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4766 - acc: 0.7761 - val_loss: 0.5145 - val_acc: 0.7544\n",
            "Epoch 350/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4776 - acc: 0.7820 - val_loss: 0.5250 - val_acc: 0.7343\n",
            "Epoch 351/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4743 - acc: 0.7820 - val_loss: 0.4901 - val_acc: 0.7845\n",
            "Epoch 352/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4787 - acc: 0.7769 - val_loss: 0.4971 - val_acc: 0.7393\n",
            "Epoch 353/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4751 - acc: 0.7761 - val_loss: 0.5166 - val_acc: 0.7268\n",
            "Epoch 354/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4774 - acc: 0.7736 - val_loss: 0.5075 - val_acc: 0.7769\n",
            "Epoch 355/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4781 - acc: 0.7786 - val_loss: 0.4957 - val_acc: 0.7895\n",
            "Epoch 356/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4762 - acc: 0.7811 - val_loss: 0.4957 - val_acc: 0.7769\n",
            "Epoch 357/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4772 - acc: 0.7736 - val_loss: 0.5387 - val_acc: 0.7769\n",
            "Epoch 358/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4771 - acc: 0.7744 - val_loss: 0.5210 - val_acc: 0.7243\n",
            "Epoch 359/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4745 - acc: 0.7811 - val_loss: 0.5080 - val_acc: 0.7293\n",
            "Epoch 360/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4706 - acc: 0.7811 - val_loss: 0.4927 - val_acc: 0.7845\n",
            "Epoch 361/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4749 - acc: 0.7769 - val_loss: 0.4867 - val_acc: 0.7895\n",
            "Epoch 362/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4793 - acc: 0.7744 - val_loss: 0.5446 - val_acc: 0.7243\n",
            "Epoch 363/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4733 - acc: 0.7803 - val_loss: 0.4842 - val_acc: 0.7794\n",
            "Epoch 364/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4772 - acc: 0.7778 - val_loss: 0.5047 - val_acc: 0.7494\n",
            "Epoch 365/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4752 - acc: 0.7803 - val_loss: 0.4907 - val_acc: 0.7820\n",
            "Epoch 366/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.7769 - val_loss: 0.5025 - val_acc: 0.7719\n",
            "Epoch 367/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4801 - acc: 0.7803 - val_loss: 0.5081 - val_acc: 0.7769\n",
            "Epoch 368/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4781 - acc: 0.7861 - val_loss: 0.4904 - val_acc: 0.7845\n",
            "Epoch 369/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4821 - acc: 0.7744 - val_loss: 0.5251 - val_acc: 0.7343\n",
            "Epoch 370/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4763 - acc: 0.7803 - val_loss: 0.4872 - val_acc: 0.7845\n",
            "Epoch 371/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4770 - acc: 0.7703 - val_loss: 0.5099 - val_acc: 0.7719\n",
            "Epoch 372/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4747 - acc: 0.7711 - val_loss: 0.4906 - val_acc: 0.7845\n",
            "Epoch 373/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4759 - acc: 0.7786 - val_loss: 0.4981 - val_acc: 0.7794\n",
            "Epoch 374/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4774 - acc: 0.7845 - val_loss: 0.4897 - val_acc: 0.7895\n",
            "Epoch 375/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4729 - acc: 0.7870 - val_loss: 0.5274 - val_acc: 0.7243\n",
            "Epoch 376/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4731 - acc: 0.7895 - val_loss: 0.5055 - val_acc: 0.7368\n",
            "Epoch 377/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4763 - acc: 0.7828 - val_loss: 0.4855 - val_acc: 0.7895\n",
            "Epoch 378/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4759 - acc: 0.7728 - val_loss: 0.5144 - val_acc: 0.7769\n",
            "Epoch 379/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4787 - acc: 0.7769 - val_loss: 0.5249 - val_acc: 0.7769\n",
            "Epoch 380/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4745 - acc: 0.7778 - val_loss: 0.4954 - val_acc: 0.7719\n",
            "Epoch 381/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4752 - acc: 0.7803 - val_loss: 0.4899 - val_acc: 0.7895\n",
            "Epoch 382/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4755 - acc: 0.7803 - val_loss: 0.5154 - val_acc: 0.7293\n",
            "Epoch 383/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4772 - acc: 0.7769 - val_loss: 0.5120 - val_acc: 0.7719\n",
            "Epoch 384/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4783 - acc: 0.7794 - val_loss: 0.4962 - val_acc: 0.7870\n",
            "Epoch 385/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4767 - acc: 0.7794 - val_loss: 0.5005 - val_acc: 0.7870\n",
            "Epoch 386/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7861 - val_loss: 0.4880 - val_acc: 0.7744\n",
            "Epoch 387/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4756 - acc: 0.7861 - val_loss: 0.4889 - val_acc: 0.7895\n",
            "Epoch 388/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4775 - acc: 0.7836 - val_loss: 0.5541 - val_acc: 0.7243\n",
            "Epoch 389/10000\n",
            "1197/1197 [==============================] - 0s 90us/step - loss: 0.4749 - acc: 0.7786 - val_loss: 0.4993 - val_acc: 0.7794\n",
            "Epoch 390/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4750 - acc: 0.7811 - val_loss: 0.4939 - val_acc: 0.7794\n",
            "Epoch 391/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4714 - acc: 0.7845 - val_loss: 0.5136 - val_acc: 0.7393\n",
            "Epoch 392/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4770 - acc: 0.7744 - val_loss: 0.4972 - val_acc: 0.7794\n",
            "Epoch 393/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7878 - val_loss: 0.4970 - val_acc: 0.7419\n",
            "Epoch 394/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4782 - acc: 0.7845 - val_loss: 0.4988 - val_acc: 0.7769\n",
            "Epoch 395/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4740 - acc: 0.7870 - val_loss: 0.5075 - val_acc: 0.7343\n",
            "Epoch 396/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4737 - acc: 0.7753 - val_loss: 0.4853 - val_acc: 0.7769\n",
            "Epoch 397/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4750 - acc: 0.7794 - val_loss: 0.4937 - val_acc: 0.7794\n",
            "Epoch 398/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4788 - acc: 0.7769 - val_loss: 0.4968 - val_acc: 0.7820\n",
            "Epoch 399/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4766 - acc: 0.7669 - val_loss: 0.4838 - val_acc: 0.7719\n",
            "Epoch 400/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.7736 - val_loss: 0.4888 - val_acc: 0.7870\n",
            "Epoch 401/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7828 - val_loss: 0.4877 - val_acc: 0.7845\n",
            "Epoch 402/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4754 - acc: 0.7744 - val_loss: 0.5057 - val_acc: 0.7619\n",
            "Epoch 403/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4757 - acc: 0.7811 - val_loss: 0.5289 - val_acc: 0.7945\n",
            "Epoch 404/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4764 - acc: 0.7778 - val_loss: 0.5465 - val_acc: 0.7719\n",
            "Epoch 405/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4765 - acc: 0.7820 - val_loss: 0.5640 - val_acc: 0.7293\n",
            "Epoch 406/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7836 - val_loss: 0.5004 - val_acc: 0.7744\n",
            "Epoch 407/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4762 - acc: 0.7786 - val_loss: 0.4862 - val_acc: 0.7694\n",
            "Epoch 408/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4763 - acc: 0.7761 - val_loss: 0.4855 - val_acc: 0.7719\n",
            "Epoch 409/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4767 - acc: 0.7736 - val_loss: 0.4851 - val_acc: 0.7820\n",
            "Epoch 410/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4787 - acc: 0.7878 - val_loss: 0.4936 - val_acc: 0.7794\n",
            "Epoch 411/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4741 - acc: 0.7861 - val_loss: 0.5018 - val_acc: 0.7895\n",
            "Epoch 412/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4743 - acc: 0.7845 - val_loss: 0.4956 - val_acc: 0.7845\n",
            "Epoch 413/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4720 - acc: 0.7803 - val_loss: 0.4908 - val_acc: 0.7845\n",
            "Epoch 414/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4750 - acc: 0.7769 - val_loss: 0.4882 - val_acc: 0.7920\n",
            "Epoch 415/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4782 - acc: 0.7778 - val_loss: 0.4848 - val_acc: 0.7845\n",
            "Epoch 416/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4742 - acc: 0.7811 - val_loss: 0.5025 - val_acc: 0.7368\n",
            "Epoch 417/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4779 - acc: 0.7703 - val_loss: 0.4934 - val_acc: 0.7820\n",
            "Epoch 418/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4732 - acc: 0.7895 - val_loss: 0.4878 - val_acc: 0.7970\n",
            "Epoch 419/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4749 - acc: 0.7753 - val_loss: 0.5023 - val_acc: 0.7794\n",
            "Epoch 420/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4738 - acc: 0.7811 - val_loss: 0.4993 - val_acc: 0.7945\n",
            "Epoch 421/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4763 - acc: 0.7744 - val_loss: 0.5578 - val_acc: 0.7393\n",
            "Epoch 422/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4747 - acc: 0.7786 - val_loss: 0.5779 - val_acc: 0.7393\n",
            "Epoch 423/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4740 - acc: 0.7769 - val_loss: 0.5928 - val_acc: 0.7393\n",
            "Epoch 424/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4742 - acc: 0.7820 - val_loss: 0.5225 - val_acc: 0.7970\n",
            "Epoch 425/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4735 - acc: 0.7753 - val_loss: 0.5011 - val_acc: 0.7820\n",
            "Epoch 426/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4759 - acc: 0.7820 - val_loss: 0.4871 - val_acc: 0.7895\n",
            "Epoch 427/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4762 - acc: 0.7870 - val_loss: 0.4889 - val_acc: 0.7995\n",
            "Epoch 428/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4767 - acc: 0.7794 - val_loss: 0.4868 - val_acc: 0.8020\n",
            "Epoch 429/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4729 - acc: 0.7836 - val_loss: 0.4962 - val_acc: 0.7794\n",
            "Epoch 430/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4747 - acc: 0.7803 - val_loss: 0.4878 - val_acc: 0.7845\n",
            "Epoch 431/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4787 - acc: 0.7761 - val_loss: 0.5285 - val_acc: 0.7769\n",
            "Epoch 432/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.7878 - val_loss: 0.5033 - val_acc: 0.7794\n",
            "Epoch 433/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4739 - acc: 0.7828 - val_loss: 0.4884 - val_acc: 0.7744\n",
            "Epoch 434/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4801 - acc: 0.7761 - val_loss: 0.5184 - val_acc: 0.7820\n",
            "Epoch 435/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4780 - acc: 0.7845 - val_loss: 0.5314 - val_acc: 0.7393\n",
            "Epoch 436/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4764 - acc: 0.7744 - val_loss: 0.5069 - val_acc: 0.7719\n",
            "Epoch 437/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7794 - val_loss: 0.5172 - val_acc: 0.7393\n",
            "Epoch 438/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4741 - acc: 0.7820 - val_loss: 0.4845 - val_acc: 0.7895\n",
            "Epoch 439/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4754 - acc: 0.7803 - val_loss: 0.5246 - val_acc: 0.7393\n",
            "Epoch 440/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4741 - acc: 0.7828 - val_loss: 0.4926 - val_acc: 0.7820\n",
            "Epoch 441/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4765 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7870\n",
            "Epoch 442/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4717 - acc: 0.7870 - val_loss: 0.5006 - val_acc: 0.7494\n",
            "Epoch 443/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7870 - val_loss: 0.5353 - val_acc: 0.7393\n",
            "Epoch 444/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4752 - acc: 0.7803 - val_loss: 0.4888 - val_acc: 0.7895\n",
            "Epoch 445/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7786 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 446/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4730 - acc: 0.7820 - val_loss: 0.4986 - val_acc: 0.7494\n",
            "Epoch 447/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4751 - acc: 0.7836 - val_loss: 0.4926 - val_acc: 0.7820\n",
            "Epoch 448/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4771 - acc: 0.7828 - val_loss: 0.5405 - val_acc: 0.7769\n",
            "Epoch 449/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4719 - acc: 0.7820 - val_loss: 0.4963 - val_acc: 0.7469\n",
            "Epoch 450/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7828 - val_loss: 0.4905 - val_acc: 0.7744\n",
            "Epoch 451/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4758 - acc: 0.7811 - val_loss: 0.5123 - val_acc: 0.7719\n",
            "Epoch 452/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4748 - acc: 0.7794 - val_loss: 0.4971 - val_acc: 0.7895\n",
            "Epoch 453/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4749 - acc: 0.7861 - val_loss: 0.5039 - val_acc: 0.7820\n",
            "Epoch 454/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4769 - acc: 0.7761 - val_loss: 0.5021 - val_acc: 0.7820\n",
            "Epoch 455/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4740 - acc: 0.7769 - val_loss: 0.5013 - val_acc: 0.7393\n",
            "Epoch 456/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4764 - acc: 0.7828 - val_loss: 0.4968 - val_acc: 0.7820\n",
            "Epoch 457/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4743 - acc: 0.7853 - val_loss: 0.4910 - val_acc: 0.7794\n",
            "Epoch 458/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4757 - acc: 0.7794 - val_loss: 0.4934 - val_acc: 0.7895\n",
            "Epoch 459/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4706 - acc: 0.7761 - val_loss: 0.5053 - val_acc: 0.7744\n",
            "Epoch 460/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4730 - acc: 0.7853 - val_loss: 0.4935 - val_acc: 0.7419\n",
            "Epoch 461/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4751 - acc: 0.7845 - val_loss: 0.4915 - val_acc: 0.7744\n",
            "Epoch 462/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4752 - acc: 0.7769 - val_loss: 0.4863 - val_acc: 0.7694\n",
            "Epoch 463/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.7803 - val_loss: 0.5034 - val_acc: 0.7619\n",
            "Epoch 464/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4763 - acc: 0.7828 - val_loss: 0.5663 - val_acc: 0.7343\n",
            "Epoch 465/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4755 - acc: 0.7778 - val_loss: 0.5384 - val_acc: 0.7268\n",
            "Epoch 466/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4733 - acc: 0.7811 - val_loss: 0.5133 - val_acc: 0.7243\n",
            "Epoch 467/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4784 - acc: 0.7761 - val_loss: 0.5020 - val_acc: 0.7419\n",
            "Epoch 468/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4764 - acc: 0.7878 - val_loss: 0.4956 - val_acc: 0.7494\n",
            "Epoch 469/10000\n",
            "1197/1197 [==============================] - 0s 88us/step - loss: 0.4775 - acc: 0.7703 - val_loss: 0.4873 - val_acc: 0.7845\n",
            "Epoch 470/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4735 - acc: 0.7853 - val_loss: 0.4915 - val_acc: 0.7794\n",
            "Epoch 471/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4762 - acc: 0.7769 - val_loss: 0.4878 - val_acc: 0.7920\n",
            "Epoch 472/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.7836 - val_loss: 0.4881 - val_acc: 0.7920\n",
            "Epoch 473/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4744 - acc: 0.7811 - val_loss: 0.4844 - val_acc: 0.7794\n",
            "Epoch 474/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4764 - acc: 0.7820 - val_loss: 0.4890 - val_acc: 0.7769\n",
            "Epoch 475/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4741 - acc: 0.7903 - val_loss: 0.5161 - val_acc: 0.7494\n",
            "Epoch 476/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4743 - acc: 0.7853 - val_loss: 0.4932 - val_acc: 0.7694\n",
            "Epoch 477/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4767 - acc: 0.7820 - val_loss: 0.4911 - val_acc: 0.7845\n",
            "Epoch 478/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4707 - acc: 0.7870 - val_loss: 0.4896 - val_acc: 0.7820\n",
            "Epoch 479/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4742 - acc: 0.7778 - val_loss: 0.4882 - val_acc: 0.7719\n",
            "Epoch 480/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4768 - acc: 0.7861 - val_loss: 0.4916 - val_acc: 0.7769\n",
            "Epoch 481/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4758 - acc: 0.7794 - val_loss: 0.4894 - val_acc: 0.7845\n",
            "Epoch 482/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4754 - acc: 0.7786 - val_loss: 0.5032 - val_acc: 0.7393\n",
            "Epoch 483/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4787 - acc: 0.7870 - val_loss: 0.4879 - val_acc: 0.7920\n",
            "Epoch 484/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4761 - acc: 0.7761 - val_loss: 0.5189 - val_acc: 0.7769\n",
            "Epoch 485/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4732 - acc: 0.7911 - val_loss: 0.4939 - val_acc: 0.7895\n",
            "Epoch 486/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4713 - acc: 0.7878 - val_loss: 0.4828 - val_acc: 0.7920\n",
            "Epoch 487/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4747 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7719\n",
            "Epoch 488/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4737 - acc: 0.7820 - val_loss: 0.4862 - val_acc: 0.7920\n",
            "Epoch 489/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4756 - acc: 0.7803 - val_loss: 0.4891 - val_acc: 0.7870\n",
            "Epoch 490/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4740 - acc: 0.7786 - val_loss: 0.4901 - val_acc: 0.7794\n",
            "Epoch 491/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4773 - acc: 0.7803 - val_loss: 0.4926 - val_acc: 0.7794\n",
            "Epoch 492/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.7753 - val_loss: 0.4900 - val_acc: 0.7895\n",
            "Epoch 493/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4736 - acc: 0.7811 - val_loss: 0.4988 - val_acc: 0.7594\n",
            "Epoch 494/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4726 - acc: 0.7836 - val_loss: 0.4989 - val_acc: 0.7920\n",
            "Epoch 495/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4709 - acc: 0.7811 - val_loss: 0.5037 - val_acc: 0.8020\n",
            "Epoch 496/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4747 - acc: 0.7820 - val_loss: 0.5260 - val_acc: 0.7719\n",
            "Epoch 497/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4847 - acc: 0.7778 - val_loss: 0.5093 - val_acc: 0.8020\n",
            "Epoch 498/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4766 - acc: 0.7836 - val_loss: 0.4908 - val_acc: 0.7644\n",
            "Epoch 499/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4762 - acc: 0.7711 - val_loss: 0.5071 - val_acc: 0.7769\n",
            "Epoch 500/10000\n",
            "1197/1197 [==============================] - 0s 109us/step - loss: 0.4751 - acc: 0.7761 - val_loss: 0.4886 - val_acc: 0.7895\n",
            "Epoch 501/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4745 - acc: 0.7853 - val_loss: 0.4968 - val_acc: 0.7870\n",
            "Epoch 502/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4753 - acc: 0.7778 - val_loss: 0.4931 - val_acc: 0.7870\n",
            "Epoch 503/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4746 - acc: 0.7820 - val_loss: 0.4925 - val_acc: 0.7794\n",
            "Epoch 504/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7786 - val_loss: 0.4967 - val_acc: 0.7694\n",
            "Epoch 505/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4754 - acc: 0.7769 - val_loss: 0.4912 - val_acc: 0.7845\n",
            "Epoch 506/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4712 - acc: 0.7861 - val_loss: 0.5036 - val_acc: 0.7368\n",
            "Epoch 507/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4731 - acc: 0.7853 - val_loss: 0.4890 - val_acc: 0.7995\n",
            "Epoch 508/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4738 - acc: 0.7861 - val_loss: 0.5013 - val_acc: 0.7794\n",
            "Epoch 509/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4767 - acc: 0.7744 - val_loss: 0.5165 - val_acc: 0.7769\n",
            "Epoch 510/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4733 - acc: 0.7811 - val_loss: 0.5088 - val_acc: 0.7719\n",
            "Epoch 511/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4755 - acc: 0.7769 - val_loss: 0.5045 - val_acc: 0.7719\n",
            "Epoch 512/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4755 - acc: 0.7811 - val_loss: 0.5089 - val_acc: 0.7694\n",
            "Epoch 513/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4737 - acc: 0.7828 - val_loss: 0.4980 - val_acc: 0.7694\n",
            "Epoch 514/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4735 - acc: 0.7845 - val_loss: 0.4938 - val_acc: 0.7794\n",
            "Epoch 515/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4749 - acc: 0.7828 - val_loss: 0.5080 - val_acc: 0.7368\n",
            "Epoch 516/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4736 - acc: 0.7803 - val_loss: 0.5011 - val_acc: 0.7719\n",
            "Epoch 517/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4734 - acc: 0.7769 - val_loss: 0.4860 - val_acc: 0.7719\n",
            "Epoch 518/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4757 - acc: 0.7828 - val_loss: 0.4886 - val_acc: 0.7870\n",
            "Epoch 519/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4770 - acc: 0.7753 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 520/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4760 - acc: 0.7886 - val_loss: 0.5044 - val_acc: 0.7243\n",
            "Epoch 521/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4749 - acc: 0.7786 - val_loss: 0.4871 - val_acc: 0.7920\n",
            "Epoch 522/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4765 - acc: 0.7753 - val_loss: 0.4933 - val_acc: 0.7494\n",
            "Epoch 523/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4759 - acc: 0.7778 - val_loss: 0.4854 - val_acc: 0.7769\n",
            "Epoch 524/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4735 - acc: 0.7870 - val_loss: 0.4864 - val_acc: 0.7895\n",
            "Epoch 525/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4756 - acc: 0.7803 - val_loss: 0.4889 - val_acc: 0.7970\n",
            "Epoch 526/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4746 - acc: 0.7786 - val_loss: 0.4881 - val_acc: 0.7920\n",
            "Epoch 527/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4757 - acc: 0.7736 - val_loss: 0.4971 - val_acc: 0.7845\n",
            "Epoch 528/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4743 - acc: 0.7794 - val_loss: 0.4938 - val_acc: 0.7544\n",
            "Epoch 529/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4736 - acc: 0.7794 - val_loss: 0.5425 - val_acc: 0.7243\n",
            "Epoch 530/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4779 - acc: 0.7769 - val_loss: 0.4949 - val_acc: 0.7845\n",
            "Epoch 531/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7853 - val_loss: 0.4937 - val_acc: 0.7870\n",
            "Epoch 532/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4730 - acc: 0.7861 - val_loss: 0.4846 - val_acc: 0.7820\n",
            "Epoch 533/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4764 - acc: 0.7794 - val_loss: 0.5248 - val_acc: 0.7845\n",
            "Epoch 534/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4747 - acc: 0.7703 - val_loss: 0.5005 - val_acc: 0.7769\n",
            "Epoch 535/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4684 - acc: 0.7861 - val_loss: 0.5038 - val_acc: 0.7669\n",
            "Epoch 536/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4729 - acc: 0.7794 - val_loss: 0.5178 - val_acc: 0.7820\n",
            "Epoch 537/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4733 - acc: 0.7853 - val_loss: 0.5052 - val_acc: 0.7343\n",
            "Epoch 538/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4760 - acc: 0.7786 - val_loss: 0.4881 - val_acc: 0.7970\n",
            "Epoch 539/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7861 - val_loss: 0.5152 - val_acc: 0.7845\n",
            "Epoch 540/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4752 - acc: 0.7820 - val_loss: 0.4953 - val_acc: 0.7895\n",
            "Epoch 541/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4767 - acc: 0.7778 - val_loss: 0.5041 - val_acc: 0.7769\n",
            "Epoch 542/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4756 - acc: 0.7769 - val_loss: 0.4845 - val_acc: 0.7719\n",
            "Epoch 543/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4746 - acc: 0.7836 - val_loss: 0.4930 - val_acc: 0.7794\n",
            "Epoch 544/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4744 - acc: 0.7861 - val_loss: 0.4881 - val_acc: 0.7845\n",
            "Epoch 545/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4735 - acc: 0.7803 - val_loss: 0.4857 - val_acc: 0.7794\n",
            "Epoch 546/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4757 - acc: 0.7836 - val_loss: 0.4923 - val_acc: 0.7920\n",
            "Epoch 547/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.5264 - val_acc: 0.7243\n",
            "Epoch 548/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4743 - acc: 0.7828 - val_loss: 0.5058 - val_acc: 0.7845\n",
            "Epoch 549/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4749 - acc: 0.7811 - val_loss: 0.4994 - val_acc: 0.7769\n",
            "Epoch 550/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4740 - acc: 0.7878 - val_loss: 0.4888 - val_acc: 0.7845\n",
            "Epoch 551/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4734 - acc: 0.7803 - val_loss: 0.4938 - val_acc: 0.7343\n",
            "Epoch 552/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4752 - acc: 0.7845 - val_loss: 0.5189 - val_acc: 0.7870\n",
            "Epoch 553/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4740 - acc: 0.7836 - val_loss: 0.5025 - val_acc: 0.7945\n",
            "Epoch 554/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4765 - acc: 0.7811 - val_loss: 0.4966 - val_acc: 0.7870\n",
            "Epoch 555/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4750 - acc: 0.7711 - val_loss: 0.4937 - val_acc: 0.7769\n",
            "Epoch 556/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.7853 - val_loss: 0.4909 - val_acc: 0.7870\n",
            "Epoch 557/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4755 - acc: 0.7828 - val_loss: 0.4990 - val_acc: 0.7794\n",
            "Epoch 558/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4728 - acc: 0.7836 - val_loss: 0.5200 - val_acc: 0.7268\n",
            "Epoch 559/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4748 - acc: 0.7803 - val_loss: 0.5216 - val_acc: 0.7243\n",
            "Epoch 560/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4748 - acc: 0.7828 - val_loss: 0.4919 - val_acc: 0.7845\n",
            "Epoch 561/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4750 - acc: 0.7820 - val_loss: 0.4910 - val_acc: 0.7719\n",
            "Epoch 562/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4761 - acc: 0.7778 - val_loss: 0.5029 - val_acc: 0.7870\n",
            "Epoch 563/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4753 - acc: 0.7853 - val_loss: 0.4918 - val_acc: 0.7719\n",
            "Epoch 564/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4720 - acc: 0.7836 - val_loss: 0.5062 - val_acc: 0.7243\n",
            "Epoch 565/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4736 - acc: 0.7870 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 566/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7836 - val_loss: 0.4894 - val_acc: 0.7719\n",
            "Epoch 567/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4734 - acc: 0.7861 - val_loss: 0.5215 - val_acc: 0.7343\n",
            "Epoch 568/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4739 - acc: 0.7845 - val_loss: 0.5358 - val_acc: 0.7845\n",
            "Epoch 569/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4794 - acc: 0.7669 - val_loss: 0.5208 - val_acc: 0.7769\n",
            "Epoch 570/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4720 - acc: 0.7853 - val_loss: 0.4974 - val_acc: 0.7519\n",
            "Epoch 571/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4757 - acc: 0.7719 - val_loss: 0.4951 - val_acc: 0.7820\n",
            "Epoch 572/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4766 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7870\n",
            "Epoch 573/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4729 - acc: 0.7811 - val_loss: 0.4921 - val_acc: 0.7895\n",
            "Epoch 574/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4725 - acc: 0.7828 - val_loss: 0.4924 - val_acc: 0.7845\n",
            "Epoch 575/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4739 - acc: 0.7836 - val_loss: 0.4886 - val_acc: 0.7845\n",
            "Epoch 576/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4739 - acc: 0.7820 - val_loss: 0.4878 - val_acc: 0.7845\n",
            "Epoch 577/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4718 - acc: 0.7853 - val_loss: 0.4893 - val_acc: 0.7845\n",
            "Epoch 578/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7753 - val_loss: 0.5255 - val_acc: 0.7694\n",
            "Epoch 579/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4751 - acc: 0.7853 - val_loss: 0.4858 - val_acc: 0.7769\n",
            "Epoch 580/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4739 - acc: 0.7744 - val_loss: 0.4951 - val_acc: 0.7820\n",
            "Epoch 581/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4755 - acc: 0.7845 - val_loss: 0.5099 - val_acc: 0.7318\n",
            "Epoch 582/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4753 - acc: 0.7794 - val_loss: 0.4981 - val_acc: 0.7845\n",
            "Epoch 583/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4744 - acc: 0.7870 - val_loss: 0.4912 - val_acc: 0.7845\n",
            "Epoch 584/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4762 - acc: 0.7794 - val_loss: 0.5172 - val_acc: 0.7243\n",
            "Epoch 585/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4769 - acc: 0.7820 - val_loss: 0.4952 - val_acc: 0.7669\n",
            "Epoch 586/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4770 - acc: 0.7786 - val_loss: 0.4869 - val_acc: 0.7845\n",
            "Epoch 587/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4764 - acc: 0.7861 - val_loss: 0.5101 - val_acc: 0.7243\n",
            "Epoch 588/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4732 - acc: 0.7836 - val_loss: 0.4905 - val_acc: 0.7794\n",
            "Epoch 589/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4758 - acc: 0.7811 - val_loss: 0.5060 - val_acc: 0.7343\n",
            "Epoch 590/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4711 - acc: 0.7836 - val_loss: 0.4932 - val_acc: 0.7494\n",
            "Epoch 591/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4748 - acc: 0.7870 - val_loss: 0.5073 - val_acc: 0.7243\n",
            "Epoch 592/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4740 - acc: 0.7828 - val_loss: 0.4853 - val_acc: 0.7920\n",
            "Epoch 593/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4745 - acc: 0.7878 - val_loss: 0.4845 - val_acc: 0.7995\n",
            "Epoch 594/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4726 - acc: 0.7895 - val_loss: 0.5159 - val_acc: 0.7419\n",
            "Epoch 595/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4770 - acc: 0.7820 - val_loss: 0.5110 - val_acc: 0.7820\n",
            "Epoch 596/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4734 - acc: 0.7803 - val_loss: 0.4968 - val_acc: 0.7744\n",
            "Epoch 597/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4754 - acc: 0.7811 - val_loss: 0.5305 - val_acc: 0.7243\n",
            "Epoch 598/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4717 - acc: 0.7861 - val_loss: 0.5170 - val_acc: 0.7895\n",
            "Epoch 599/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7828 - val_loss: 0.5088 - val_acc: 0.7845\n",
            "Epoch 600/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4721 - acc: 0.7828 - val_loss: 0.5047 - val_acc: 0.7719\n",
            "Epoch 601/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4754 - acc: 0.7853 - val_loss: 0.5375 - val_acc: 0.7419\n",
            "Epoch 602/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4765 - acc: 0.7820 - val_loss: 0.5078 - val_acc: 0.7820\n",
            "Epoch 603/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4726 - acc: 0.7878 - val_loss: 0.5028 - val_acc: 0.7870\n",
            "Epoch 604/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4752 - acc: 0.7861 - val_loss: 0.4864 - val_acc: 0.7820\n",
            "Epoch 605/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4738 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7945\n",
            "Epoch 606/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4722 - acc: 0.7861 - val_loss: 0.4911 - val_acc: 0.7945\n",
            "Epoch 607/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4725 - acc: 0.7845 - val_loss: 0.4962 - val_acc: 0.7794\n",
            "Epoch 608/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.4901 - val_acc: 0.7920\n",
            "Epoch 609/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4713 - acc: 0.7828 - val_loss: 0.4888 - val_acc: 0.7744\n",
            "Epoch 610/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4725 - acc: 0.7836 - val_loss: 0.4856 - val_acc: 0.7970\n",
            "Epoch 611/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4760 - acc: 0.7736 - val_loss: 0.4936 - val_acc: 0.7820\n",
            "Epoch 612/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4746 - acc: 0.7870 - val_loss: 0.5067 - val_acc: 0.7419\n",
            "Epoch 613/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4761 - acc: 0.7803 - val_loss: 0.4936 - val_acc: 0.7719\n",
            "Epoch 614/10000\n",
            "1197/1197 [==============================] - 0s 88us/step - loss: 0.4747 - acc: 0.7803 - val_loss: 0.5006 - val_acc: 0.7744\n",
            "Epoch 615/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4762 - acc: 0.7794 - val_loss: 0.4940 - val_acc: 0.7895\n",
            "Epoch 616/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4708 - acc: 0.7836 - val_loss: 0.4919 - val_acc: 0.7769\n",
            "Epoch 617/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4736 - acc: 0.7794 - val_loss: 0.4863 - val_acc: 0.7895\n",
            "Epoch 618/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4747 - acc: 0.7820 - val_loss: 0.4900 - val_acc: 0.7895\n",
            "Epoch 619/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7845 - val_loss: 0.4868 - val_acc: 0.7794\n",
            "Epoch 620/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4762 - acc: 0.7778 - val_loss: 0.4874 - val_acc: 0.7744\n",
            "Epoch 621/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4700 - acc: 0.7820 - val_loss: 0.4942 - val_acc: 0.7870\n",
            "Epoch 622/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4741 - acc: 0.7803 - val_loss: 0.5342 - val_acc: 0.7243\n",
            "Epoch 623/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4722 - acc: 0.7861 - val_loss: 0.4925 - val_acc: 0.7870\n",
            "Epoch 624/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4774 - acc: 0.7803 - val_loss: 0.5313 - val_acc: 0.7243\n",
            "Epoch 625/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4760 - acc: 0.7794 - val_loss: 0.4919 - val_acc: 0.7845\n",
            "Epoch 626/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4725 - acc: 0.7828 - val_loss: 0.4837 - val_acc: 0.7870\n",
            "Epoch 627/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4739 - acc: 0.7870 - val_loss: 0.4844 - val_acc: 0.7895\n",
            "Epoch 628/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4734 - acc: 0.7853 - val_loss: 0.4913 - val_acc: 0.7820\n",
            "Epoch 629/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4742 - acc: 0.7828 - val_loss: 0.4972 - val_acc: 0.7694\n",
            "Epoch 630/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4695 - acc: 0.7861 - val_loss: 0.5190 - val_acc: 0.7218\n",
            "Epoch 631/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4770 - acc: 0.7828 - val_loss: 0.4840 - val_acc: 0.7870\n",
            "Epoch 632/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4735 - acc: 0.7878 - val_loss: 0.4937 - val_acc: 0.7694\n",
            "Epoch 633/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4770 - acc: 0.7761 - val_loss: 0.4960 - val_acc: 0.7268\n",
            "Epoch 634/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4774 - acc: 0.7753 - val_loss: 0.5011 - val_acc: 0.7845\n",
            "Epoch 635/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7836 - val_loss: 0.5028 - val_acc: 0.7845\n",
            "Epoch 636/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4721 - acc: 0.7886 - val_loss: 0.5036 - val_acc: 0.7845\n",
            "Epoch 637/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4755 - acc: 0.7794 - val_loss: 0.5173 - val_acc: 0.7820\n",
            "Epoch 638/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4698 - acc: 0.7895 - val_loss: 0.5087 - val_acc: 0.7870\n",
            "Epoch 639/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4705 - acc: 0.7811 - val_loss: 0.5239 - val_acc: 0.7719\n",
            "Epoch 640/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7803 - val_loss: 0.5432 - val_acc: 0.7243\n",
            "Epoch 641/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4758 - acc: 0.7786 - val_loss: 0.5000 - val_acc: 0.7895\n",
            "Epoch 642/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4728 - acc: 0.7878 - val_loss: 0.4866 - val_acc: 0.7820\n",
            "Epoch 643/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4744 - acc: 0.7786 - val_loss: 0.4967 - val_acc: 0.7569\n",
            "Epoch 644/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4709 - acc: 0.7853 - val_loss: 0.4889 - val_acc: 0.7870\n",
            "Epoch 645/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4729 - acc: 0.7836 - val_loss: 0.4846 - val_acc: 0.7895\n",
            "Epoch 646/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4714 - acc: 0.7861 - val_loss: 0.4845 - val_acc: 0.7794\n",
            "Epoch 647/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4750 - acc: 0.7803 - val_loss: 0.5102 - val_acc: 0.7820\n",
            "Epoch 648/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4732 - acc: 0.7803 - val_loss: 0.4990 - val_acc: 0.7719\n",
            "Epoch 649/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4713 - acc: 0.7937 - val_loss: 0.4938 - val_acc: 0.7845\n",
            "Epoch 650/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4730 - acc: 0.7820 - val_loss: 0.5017 - val_acc: 0.7419\n",
            "Epoch 651/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4733 - acc: 0.7853 - val_loss: 0.5206 - val_acc: 0.7243\n",
            "Epoch 652/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4719 - acc: 0.7778 - val_loss: 0.4893 - val_acc: 0.7895\n",
            "Epoch 653/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.7828 - val_loss: 0.4984 - val_acc: 0.7368\n",
            "Epoch 654/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4739 - acc: 0.7820 - val_loss: 0.4858 - val_acc: 0.7870\n",
            "Epoch 655/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4756 - acc: 0.7828 - val_loss: 0.4861 - val_acc: 0.7870\n",
            "Epoch 656/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4721 - acc: 0.7845 - val_loss: 0.5039 - val_acc: 0.7744\n",
            "Epoch 657/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4743 - acc: 0.7878 - val_loss: 0.4984 - val_acc: 0.7820\n",
            "Epoch 658/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.7811 - val_loss: 0.5057 - val_acc: 0.7243\n",
            "Epoch 659/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4724 - acc: 0.7811 - val_loss: 0.4903 - val_acc: 0.7870\n",
            "Epoch 660/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.4861 - val_acc: 0.7719\n",
            "Epoch 661/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.4910 - val_acc: 0.7870\n",
            "Epoch 662/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4756 - acc: 0.7903 - val_loss: 0.4874 - val_acc: 0.7744\n",
            "Epoch 663/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4736 - acc: 0.7811 - val_loss: 0.4841 - val_acc: 0.7694\n",
            "Epoch 664/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4739 - acc: 0.7828 - val_loss: 0.4879 - val_acc: 0.7769\n",
            "Epoch 665/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4720 - acc: 0.7778 - val_loss: 0.4961 - val_acc: 0.7744\n",
            "Epoch 666/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4741 - acc: 0.7769 - val_loss: 0.5144 - val_acc: 0.7794\n",
            "Epoch 667/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4732 - acc: 0.7828 - val_loss: 0.5033 - val_acc: 0.7744\n",
            "Epoch 668/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4750 - acc: 0.7820 - val_loss: 0.5054 - val_acc: 0.7744\n",
            "Epoch 669/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4731 - acc: 0.7853 - val_loss: 0.5037 - val_acc: 0.7870\n",
            "Epoch 670/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4716 - acc: 0.7886 - val_loss: 0.4935 - val_acc: 0.7870\n",
            "Epoch 671/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7778 - val_loss: 0.4875 - val_acc: 0.7920\n",
            "Epoch 672/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4744 - acc: 0.7794 - val_loss: 0.4956 - val_acc: 0.7769\n",
            "Epoch 673/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4748 - acc: 0.7853 - val_loss: 0.4994 - val_acc: 0.7519\n",
            "Epoch 674/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4734 - acc: 0.7861 - val_loss: 0.4940 - val_acc: 0.7769\n",
            "Epoch 675/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4747 - acc: 0.7803 - val_loss: 0.5014 - val_acc: 0.7870\n",
            "Epoch 676/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4734 - acc: 0.7845 - val_loss: 0.4878 - val_acc: 0.7794\n",
            "Epoch 677/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4717 - acc: 0.7803 - val_loss: 0.4908 - val_acc: 0.7895\n",
            "Epoch 678/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4747 - acc: 0.7836 - val_loss: 0.5236 - val_acc: 0.7895\n",
            "Epoch 679/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4700 - acc: 0.7811 - val_loss: 0.5880 - val_acc: 0.7243\n",
            "Epoch 680/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4721 - acc: 0.7820 - val_loss: 0.5047 - val_acc: 0.7820\n",
            "Epoch 681/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4727 - acc: 0.7811 - val_loss: 0.4981 - val_acc: 0.7820\n",
            "Epoch 682/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4776 - acc: 0.7769 - val_loss: 0.5282 - val_acc: 0.7769\n",
            "Epoch 683/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4736 - acc: 0.7886 - val_loss: 0.5126 - val_acc: 0.7694\n",
            "Epoch 684/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4720 - acc: 0.7895 - val_loss: 0.5014 - val_acc: 0.7318\n",
            "Epoch 685/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.4894 - val_acc: 0.7820\n",
            "Epoch 686/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4743 - acc: 0.7803 - val_loss: 0.5091 - val_acc: 0.7794\n",
            "Epoch 687/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4773 - acc: 0.7794 - val_loss: 0.4848 - val_acc: 0.7694\n",
            "Epoch 688/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4762 - acc: 0.7794 - val_loss: 0.4996 - val_acc: 0.7268\n",
            "Epoch 689/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4751 - acc: 0.7828 - val_loss: 0.4930 - val_acc: 0.7644\n",
            "Epoch 690/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4720 - acc: 0.7861 - val_loss: 0.5072 - val_acc: 0.7318\n",
            "Epoch 691/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7769 - val_loss: 0.4951 - val_acc: 0.7845\n",
            "Epoch 692/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4717 - acc: 0.7769 - val_loss: 0.5074 - val_acc: 0.7343\n",
            "Epoch 693/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4744 - acc: 0.7820 - val_loss: 0.4952 - val_acc: 0.7845\n",
            "Epoch 694/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4739 - acc: 0.7744 - val_loss: 0.5078 - val_acc: 0.7845\n",
            "Epoch 695/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4726 - acc: 0.7853 - val_loss: 0.5137 - val_acc: 0.7744\n",
            "Epoch 696/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4719 - acc: 0.7861 - val_loss: 0.4960 - val_acc: 0.7845\n",
            "Epoch 697/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4716 - acc: 0.7803 - val_loss: 0.5051 - val_acc: 0.7719\n",
            "Epoch 698/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4751 - acc: 0.7778 - val_loss: 0.5181 - val_acc: 0.7870\n",
            "Epoch 699/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.7845 - val_loss: 0.4980 - val_acc: 0.7744\n",
            "Epoch 700/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4757 - acc: 0.7769 - val_loss: 0.5078 - val_acc: 0.7744\n",
            "Epoch 701/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7811 - val_loss: 0.4968 - val_acc: 0.7920\n",
            "Epoch 702/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4750 - acc: 0.7794 - val_loss: 0.4960 - val_acc: 0.7895\n",
            "Epoch 703/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4720 - acc: 0.7811 - val_loss: 0.4982 - val_acc: 0.7895\n",
            "Epoch 704/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4741 - acc: 0.7811 - val_loss: 0.5014 - val_acc: 0.7870\n",
            "Epoch 705/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7870 - val_loss: 0.4893 - val_acc: 0.7895\n",
            "Epoch 706/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4737 - acc: 0.7820 - val_loss: 0.5117 - val_acc: 0.7318\n",
            "Epoch 707/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7786 - val_loss: 0.4909 - val_acc: 0.7820\n",
            "Epoch 708/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4743 - acc: 0.7853 - val_loss: 0.4918 - val_acc: 0.7845\n",
            "Epoch 709/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4735 - acc: 0.7803 - val_loss: 0.4874 - val_acc: 0.7769\n",
            "Epoch 710/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4767 - acc: 0.7753 - val_loss: 0.5059 - val_acc: 0.7218\n",
            "Epoch 711/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4721 - acc: 0.7853 - val_loss: 0.4926 - val_acc: 0.7744\n",
            "Epoch 712/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7861 - val_loss: 0.4956 - val_acc: 0.7318\n",
            "Epoch 713/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4714 - acc: 0.7870 - val_loss: 0.4857 - val_acc: 0.7694\n",
            "Epoch 714/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4723 - acc: 0.7853 - val_loss: 0.4874 - val_acc: 0.7845\n",
            "Epoch 715/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4739 - acc: 0.7794 - val_loss: 0.5013 - val_acc: 0.7769\n",
            "Epoch 716/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4714 - acc: 0.7878 - val_loss: 0.4907 - val_acc: 0.7694\n",
            "Epoch 717/10000\n",
            "1197/1197 [==============================] - 0s 95us/step - loss: 0.4738 - acc: 0.7794 - val_loss: 0.5105 - val_acc: 0.7318\n",
            "Epoch 718/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.7769 - val_loss: 0.4984 - val_acc: 0.7669\n",
            "Epoch 719/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4732 - acc: 0.7920 - val_loss: 0.4847 - val_acc: 0.7744\n",
            "Epoch 720/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4708 - acc: 0.7886 - val_loss: 0.5119 - val_acc: 0.7519\n",
            "Epoch 721/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7836 - val_loss: 0.5365 - val_acc: 0.7744\n",
            "Epoch 722/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4732 - acc: 0.7845 - val_loss: 0.5311 - val_acc: 0.7845\n",
            "Epoch 723/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4705 - acc: 0.7803 - val_loss: 0.5436 - val_acc: 0.7393\n",
            "Epoch 724/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4709 - acc: 0.7786 - val_loss: 0.5005 - val_acc: 0.7744\n",
            "Epoch 725/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4771 - acc: 0.7669 - val_loss: 0.5490 - val_acc: 0.7820\n",
            "Epoch 726/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4758 - acc: 0.7853 - val_loss: 0.5343 - val_acc: 0.7769\n",
            "Epoch 727/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4746 - acc: 0.7845 - val_loss: 0.4851 - val_acc: 0.7744\n",
            "Epoch 728/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4722 - acc: 0.7886 - val_loss: 0.4978 - val_acc: 0.7669\n",
            "Epoch 729/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4747 - acc: 0.7811 - val_loss: 0.5044 - val_acc: 0.7870\n",
            "Epoch 730/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4752 - acc: 0.7870 - val_loss: 0.4883 - val_acc: 0.7845\n",
            "Epoch 731/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4756 - acc: 0.7769 - val_loss: 0.4897 - val_acc: 0.7895\n",
            "Epoch 732/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.7845\n",
            "Epoch 733/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4706 - acc: 0.7853 - val_loss: 0.4870 - val_acc: 0.7970\n",
            "Epoch 734/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4736 - acc: 0.7811 - val_loss: 0.4867 - val_acc: 0.7920\n",
            "Epoch 735/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.7845 - val_loss: 0.4856 - val_acc: 0.7769\n",
            "Epoch 736/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4710 - acc: 0.7861 - val_loss: 0.5083 - val_acc: 0.7870\n",
            "Epoch 737/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4761 - acc: 0.7778 - val_loss: 0.5294 - val_acc: 0.7870\n",
            "Epoch 738/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4721 - acc: 0.7803 - val_loss: 0.4948 - val_acc: 0.7794\n",
            "Epoch 739/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4746 - acc: 0.7828 - val_loss: 0.5413 - val_acc: 0.7945\n",
            "Epoch 740/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4723 - acc: 0.7811 - val_loss: 0.5304 - val_acc: 0.7845\n",
            "Epoch 741/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4744 - acc: 0.7794 - val_loss: 0.4897 - val_acc: 0.7870\n",
            "Epoch 742/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4735 - acc: 0.7845 - val_loss: 0.4940 - val_acc: 0.7694\n",
            "Epoch 743/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7794 - val_loss: 0.4859 - val_acc: 0.7744\n",
            "Epoch 744/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4723 - acc: 0.7794 - val_loss: 0.4970 - val_acc: 0.7870\n",
            "Epoch 745/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4729 - acc: 0.7820 - val_loss: 0.4987 - val_acc: 0.7769\n",
            "Epoch 746/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4711 - acc: 0.7853 - val_loss: 0.5037 - val_acc: 0.7419\n",
            "Epoch 747/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4756 - acc: 0.7861 - val_loss: 0.4921 - val_acc: 0.7794\n",
            "Epoch 748/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4751 - acc: 0.7761 - val_loss: 0.5336 - val_acc: 0.7769\n",
            "Epoch 749/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4747 - acc: 0.7836 - val_loss: 0.5260 - val_acc: 0.7895\n",
            "Epoch 750/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4719 - acc: 0.7836 - val_loss: 0.5394 - val_acc: 0.7845\n",
            "Epoch 751/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4725 - acc: 0.7861 - val_loss: 0.5479 - val_acc: 0.7870\n",
            "Epoch 752/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4759 - acc: 0.7769 - val_loss: 0.5216 - val_acc: 0.7293\n",
            "Epoch 753/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4722 - acc: 0.7811 - val_loss: 0.5031 - val_acc: 0.7694\n",
            "Epoch 754/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4711 - acc: 0.7836 - val_loss: 0.4942 - val_acc: 0.7845\n",
            "Epoch 755/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4724 - acc: 0.7836 - val_loss: 0.5267 - val_acc: 0.7669\n",
            "Epoch 756/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4727 - acc: 0.7794 - val_loss: 0.5152 - val_acc: 0.7845\n",
            "Epoch 757/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4710 - acc: 0.7820 - val_loss: 0.4901 - val_acc: 0.7970\n",
            "Epoch 758/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4725 - acc: 0.7878 - val_loss: 0.4949 - val_acc: 0.7995\n",
            "Epoch 759/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7761 - val_loss: 0.4994 - val_acc: 0.7769\n",
            "Epoch 760/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4768 - acc: 0.7769 - val_loss: 0.5077 - val_acc: 0.7794\n",
            "Epoch 761/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4732 - acc: 0.7794 - val_loss: 0.4963 - val_acc: 0.7769\n",
            "Epoch 762/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4720 - acc: 0.7786 - val_loss: 0.4915 - val_acc: 0.7870\n",
            "Epoch 763/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4724 - acc: 0.7820 - val_loss: 0.4844 - val_acc: 0.7920\n",
            "Epoch 764/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4730 - acc: 0.7861 - val_loss: 0.4874 - val_acc: 0.7845\n",
            "Epoch 765/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4747 - acc: 0.7719 - val_loss: 0.4942 - val_acc: 0.7845\n",
            "Epoch 766/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4718 - acc: 0.7820 - val_loss: 0.5091 - val_acc: 0.7744\n",
            "Epoch 767/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4745 - acc: 0.7794 - val_loss: 0.5136 - val_acc: 0.7920\n",
            "Epoch 768/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4740 - acc: 0.7753 - val_loss: 0.4859 - val_acc: 0.7719\n",
            "Epoch 769/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.4850 - val_acc: 0.7820\n",
            "Epoch 770/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4706 - acc: 0.7853 - val_loss: 0.4895 - val_acc: 0.7820\n",
            "Epoch 771/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4740 - acc: 0.7803 - val_loss: 0.4897 - val_acc: 0.7945\n",
            "Epoch 772/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7778 - val_loss: 0.4930 - val_acc: 0.7895\n",
            "Epoch 773/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4696 - acc: 0.7911 - val_loss: 0.4879 - val_acc: 0.7895\n",
            "Epoch 774/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4733 - acc: 0.7811 - val_loss: 0.4882 - val_acc: 0.7945\n",
            "Epoch 775/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4716 - acc: 0.7803 - val_loss: 0.4854 - val_acc: 0.7820\n",
            "Epoch 776/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4752 - acc: 0.7811 - val_loss: 0.5220 - val_acc: 0.7544\n",
            "Epoch 777/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4726 - acc: 0.7820 - val_loss: 0.5122 - val_acc: 0.7794\n",
            "Epoch 778/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4729 - acc: 0.7870 - val_loss: 0.5299 - val_acc: 0.7444\n",
            "Epoch 779/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4741 - acc: 0.7769 - val_loss: 0.5003 - val_acc: 0.7744\n",
            "Epoch 780/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4736 - acc: 0.7794 - val_loss: 0.4916 - val_acc: 0.7694\n",
            "Epoch 781/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7836 - val_loss: 0.4989 - val_acc: 0.7870\n",
            "Epoch 782/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4733 - acc: 0.7786 - val_loss: 0.4846 - val_acc: 0.7995\n",
            "Epoch 783/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4719 - acc: 0.7870 - val_loss: 0.4859 - val_acc: 0.7895\n",
            "Epoch 784/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4722 - acc: 0.7853 - val_loss: 0.4856 - val_acc: 0.7769\n",
            "Epoch 785/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4732 - acc: 0.7845 - val_loss: 0.4957 - val_acc: 0.7845\n",
            "Epoch 786/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4771 - acc: 0.7870 - val_loss: 0.4839 - val_acc: 0.7895\n",
            "Epoch 787/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4729 - acc: 0.7803 - val_loss: 0.5014 - val_acc: 0.7769\n",
            "Epoch 788/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4733 - acc: 0.7903 - val_loss: 0.4884 - val_acc: 0.7845\n",
            "Epoch 789/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.4873 - val_acc: 0.7719\n",
            "Epoch 790/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4713 - acc: 0.7811 - val_loss: 0.5013 - val_acc: 0.7419\n",
            "Epoch 791/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4714 - acc: 0.7861 - val_loss: 0.4911 - val_acc: 0.7845\n",
            "Epoch 792/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4720 - acc: 0.7828 - val_loss: 0.4895 - val_acc: 0.7970\n",
            "Epoch 793/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4733 - acc: 0.7803 - val_loss: 0.5020 - val_acc: 0.7970\n",
            "Epoch 794/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4719 - acc: 0.7870 - val_loss: 0.4893 - val_acc: 0.7845\n",
            "Epoch 795/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4731 - acc: 0.7895 - val_loss: 0.4841 - val_acc: 0.7995\n",
            "Epoch 796/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4720 - acc: 0.7803 - val_loss: 0.4811 - val_acc: 0.7970\n",
            "Epoch 797/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4720 - acc: 0.7878 - val_loss: 0.4996 - val_acc: 0.7393\n",
            "Epoch 798/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4738 - acc: 0.7728 - val_loss: 0.4869 - val_acc: 0.7870\n",
            "Epoch 799/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4732 - acc: 0.7886 - val_loss: 0.4833 - val_acc: 0.7769\n",
            "Epoch 800/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4751 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7794\n",
            "Epoch 801/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4762 - acc: 0.7820 - val_loss: 0.4897 - val_acc: 0.7895\n",
            "Epoch 802/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.4913 - val_acc: 0.7870\n",
            "Epoch 803/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4781 - acc: 0.7786 - val_loss: 0.5043 - val_acc: 0.7293\n",
            "Epoch 804/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4748 - acc: 0.7853 - val_loss: 0.4979 - val_acc: 0.7343\n",
            "Epoch 805/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4725 - acc: 0.7820 - val_loss: 0.4867 - val_acc: 0.7995\n",
            "Epoch 806/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4737 - acc: 0.7836 - val_loss: 0.4842 - val_acc: 0.7794\n",
            "Epoch 807/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4746 - acc: 0.7786 - val_loss: 0.4903 - val_acc: 0.7945\n",
            "Epoch 808/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4767 - acc: 0.7761 - val_loss: 0.4887 - val_acc: 0.7870\n",
            "Epoch 809/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4698 - acc: 0.7870 - val_loss: 0.5077 - val_acc: 0.7719\n",
            "Epoch 810/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4747 - acc: 0.7794 - val_loss: 0.4886 - val_acc: 0.7870\n",
            "Epoch 811/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4735 - acc: 0.7794 - val_loss: 0.4842 - val_acc: 0.7970\n",
            "Epoch 812/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4729 - acc: 0.7878 - val_loss: 0.4842 - val_acc: 0.7970\n",
            "Epoch 813/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4736 - acc: 0.7786 - val_loss: 0.4966 - val_acc: 0.7920\n",
            "Epoch 814/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7845 - val_loss: 0.4923 - val_acc: 0.7769\n",
            "Epoch 815/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4723 - acc: 0.7853 - val_loss: 0.5014 - val_acc: 0.7945\n",
            "Epoch 816/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4733 - acc: 0.7820 - val_loss: 0.4838 - val_acc: 0.7694\n",
            "Epoch 817/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4719 - acc: 0.7861 - val_loss: 0.4961 - val_acc: 0.7519\n",
            "Epoch 818/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4742 - acc: 0.7811 - val_loss: 0.4881 - val_acc: 0.7920\n",
            "Epoch 819/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4708 - acc: 0.7853 - val_loss: 0.4964 - val_acc: 0.7895\n",
            "Epoch 820/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4732 - acc: 0.7828 - val_loss: 0.4882 - val_acc: 0.7895\n",
            "Epoch 821/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4689 - acc: 0.7853 - val_loss: 0.4838 - val_acc: 0.8020\n",
            "Epoch 822/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4733 - acc: 0.7828 - val_loss: 0.4910 - val_acc: 0.7895\n",
            "Epoch 823/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4707 - acc: 0.7861 - val_loss: 0.5019 - val_acc: 0.7895\n",
            "Epoch 824/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7928 - val_loss: 0.4905 - val_acc: 0.7920\n",
            "Epoch 825/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4732 - acc: 0.7761 - val_loss: 0.4848 - val_acc: 0.7794\n",
            "Epoch 826/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4713 - acc: 0.7903 - val_loss: 0.4935 - val_acc: 0.7794\n",
            "Epoch 827/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4709 - acc: 0.7820 - val_loss: 0.4956 - val_acc: 0.7845\n",
            "Epoch 828/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4737 - acc: 0.7845 - val_loss: 0.4993 - val_acc: 0.7895\n",
            "Epoch 829/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4738 - acc: 0.7820 - val_loss: 0.5018 - val_acc: 0.7870\n",
            "Epoch 830/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4700 - acc: 0.7895 - val_loss: 0.5109 - val_acc: 0.7519\n",
            "Epoch 831/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7820 - val_loss: 0.4962 - val_acc: 0.7769\n",
            "Epoch 832/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4735 - acc: 0.7870 - val_loss: 0.5108 - val_acc: 0.7870\n",
            "Epoch 833/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4747 - acc: 0.7786 - val_loss: 0.4920 - val_acc: 0.7744\n",
            "Epoch 834/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4758 - acc: 0.7803 - val_loss: 0.4953 - val_acc: 0.7719\n",
            "Epoch 835/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4745 - acc: 0.7778 - val_loss: 0.5199 - val_acc: 0.7243\n",
            "Epoch 836/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7736 - val_loss: 0.4825 - val_acc: 0.7769\n",
            "Epoch 837/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4729 - acc: 0.7820 - val_loss: 0.4945 - val_acc: 0.7870\n",
            "Epoch 838/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4733 - acc: 0.7870 - val_loss: 0.4966 - val_acc: 0.7895\n",
            "Epoch 839/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4775 - acc: 0.7811 - val_loss: 0.5389 - val_acc: 0.7243\n",
            "Epoch 840/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4760 - acc: 0.7753 - val_loss: 0.4855 - val_acc: 0.7945\n",
            "Epoch 841/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4749 - acc: 0.7853 - val_loss: 0.4935 - val_acc: 0.7769\n",
            "Epoch 842/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4741 - acc: 0.7870 - val_loss: 0.4843 - val_acc: 0.7995\n",
            "Epoch 843/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4730 - acc: 0.7803 - val_loss: 0.4853 - val_acc: 0.7694\n",
            "Epoch 844/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4742 - acc: 0.7794 - val_loss: 0.4940 - val_acc: 0.7694\n",
            "Epoch 845/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4748 - acc: 0.7878 - val_loss: 0.4894 - val_acc: 0.7895\n",
            "Epoch 846/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4745 - acc: 0.7870 - val_loss: 0.4869 - val_acc: 0.7719\n",
            "Epoch 847/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4750 - acc: 0.7820 - val_loss: 0.4976 - val_acc: 0.7594\n",
            "Epoch 848/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4727 - acc: 0.7828 - val_loss: 0.5156 - val_acc: 0.7769\n",
            "Epoch 849/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4739 - acc: 0.7803 - val_loss: 0.5104 - val_acc: 0.7644\n",
            "Epoch 850/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.4928 - val_acc: 0.7920\n",
            "Epoch 851/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4704 - acc: 0.7811 - val_loss: 0.5151 - val_acc: 0.7243\n",
            "Epoch 852/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4730 - acc: 0.7803 - val_loss: 0.5020 - val_acc: 0.7794\n",
            "Epoch 853/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4733 - acc: 0.7861 - val_loss: 0.4857 - val_acc: 0.7970\n",
            "Epoch 854/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7803 - val_loss: 0.4893 - val_acc: 0.7845\n",
            "Epoch 855/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4731 - acc: 0.7836 - val_loss: 0.4866 - val_acc: 0.7870\n",
            "Epoch 856/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4731 - acc: 0.7861 - val_loss: 0.5007 - val_acc: 0.7719\n",
            "Epoch 857/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4728 - acc: 0.7845 - val_loss: 0.5002 - val_acc: 0.7920\n",
            "Epoch 858/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4747 - acc: 0.7870 - val_loss: 0.4889 - val_acc: 0.7769\n",
            "Epoch 859/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4733 - acc: 0.7870 - val_loss: 0.4952 - val_acc: 0.7318\n",
            "Epoch 860/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4730 - acc: 0.7870 - val_loss: 0.4865 - val_acc: 0.7970\n",
            "Epoch 861/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4717 - acc: 0.7794 - val_loss: 0.5067 - val_acc: 0.7870\n",
            "Epoch 862/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4724 - acc: 0.7769 - val_loss: 0.5164 - val_acc: 0.7794\n",
            "Epoch 863/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4739 - acc: 0.7853 - val_loss: 0.5154 - val_acc: 0.7845\n",
            "Epoch 864/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4733 - acc: 0.7811 - val_loss: 0.5256 - val_acc: 0.7995\n",
            "Epoch 865/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4754 - acc: 0.7786 - val_loss: 0.5344 - val_acc: 0.7920\n",
            "Epoch 866/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4745 - acc: 0.7870 - val_loss: 0.5428 - val_acc: 0.7970\n",
            "Epoch 867/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4713 - acc: 0.7828 - val_loss: 0.5060 - val_acc: 0.7970\n",
            "Epoch 868/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7794 - val_loss: 0.5048 - val_acc: 0.7820\n",
            "Epoch 869/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4723 - acc: 0.7803 - val_loss: 0.5005 - val_acc: 0.7845\n",
            "Epoch 870/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4744 - acc: 0.7786 - val_loss: 0.4844 - val_acc: 0.7820\n",
            "Epoch 871/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4737 - acc: 0.7895 - val_loss: 0.4869 - val_acc: 0.7845\n",
            "Epoch 872/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4721 - acc: 0.7861 - val_loss: 0.4843 - val_acc: 0.7945\n",
            "Epoch 873/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4739 - acc: 0.7786 - val_loss: 0.4866 - val_acc: 0.7895\n",
            "Epoch 874/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4741 - acc: 0.7820 - val_loss: 0.4871 - val_acc: 0.7744\n",
            "Epoch 875/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4750 - acc: 0.7786 - val_loss: 0.4945 - val_acc: 0.7669\n",
            "Epoch 876/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4731 - acc: 0.7811 - val_loss: 0.4946 - val_acc: 0.7870\n",
            "Epoch 877/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4708 - acc: 0.7878 - val_loss: 0.4868 - val_acc: 0.7694\n",
            "Epoch 878/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4733 - acc: 0.7820 - val_loss: 0.4839 - val_acc: 0.7769\n",
            "Epoch 879/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4755 - acc: 0.7794 - val_loss: 0.4998 - val_acc: 0.7719\n",
            "Epoch 880/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4754 - acc: 0.7845 - val_loss: 0.4880 - val_acc: 0.7744\n",
            "Epoch 881/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7811 - val_loss: 0.4883 - val_acc: 0.7870\n",
            "Epoch 882/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4729 - acc: 0.7895 - val_loss: 0.5026 - val_acc: 0.7343\n",
            "Epoch 883/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4737 - acc: 0.7769 - val_loss: 0.5022 - val_acc: 0.7744\n",
            "Epoch 884/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7820 - val_loss: 0.4912 - val_acc: 0.7769\n",
            "Epoch 885/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4724 - acc: 0.7811 - val_loss: 0.4908 - val_acc: 0.7895\n",
            "Epoch 886/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4752 - acc: 0.7828 - val_loss: 0.4899 - val_acc: 0.7845\n",
            "Epoch 887/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.4866 - val_acc: 0.7920\n",
            "Epoch 888/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4735 - acc: 0.7769 - val_loss: 0.4830 - val_acc: 0.7769\n",
            "Epoch 889/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4725 - acc: 0.7853 - val_loss: 0.5113 - val_acc: 0.7845\n",
            "Epoch 890/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4714 - acc: 0.7870 - val_loss: 0.4982 - val_acc: 0.7895\n",
            "Epoch 891/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4720 - acc: 0.7803 - val_loss: 0.5363 - val_acc: 0.7920\n",
            "Epoch 892/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4719 - acc: 0.7761 - val_loss: 0.5704 - val_acc: 0.7845\n",
            "Epoch 893/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7820 - val_loss: 0.5156 - val_acc: 0.7995\n",
            "Epoch 894/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7828 - val_loss: 0.5009 - val_acc: 0.7694\n",
            "Epoch 895/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4724 - acc: 0.7794 - val_loss: 0.5267 - val_acc: 0.7669\n",
            "Epoch 896/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4726 - acc: 0.7878 - val_loss: 0.5212 - val_acc: 0.7920\n",
            "Epoch 897/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4734 - acc: 0.7820 - val_loss: 0.5211 - val_acc: 0.7945\n",
            "Epoch 898/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4709 - acc: 0.7861 - val_loss: 0.5527 - val_acc: 0.7820\n",
            "Epoch 899/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4723 - acc: 0.7820 - val_loss: 0.5095 - val_acc: 0.7895\n",
            "Epoch 900/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4735 - acc: 0.7753 - val_loss: 0.4907 - val_acc: 0.7845\n",
            "Epoch 901/10000\n",
            "1197/1197 [==============================] - 0s 93us/step - loss: 0.4737 - acc: 0.7845 - val_loss: 0.4974 - val_acc: 0.7945\n",
            "Epoch 902/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4720 - acc: 0.7853 - val_loss: 0.4916 - val_acc: 0.7845\n",
            "Epoch 903/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4721 - acc: 0.7820 - val_loss: 0.4880 - val_acc: 0.7744\n",
            "Epoch 904/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4745 - acc: 0.7811 - val_loss: 0.4906 - val_acc: 0.7719\n",
            "Epoch 905/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4734 - acc: 0.7836 - val_loss: 0.4951 - val_acc: 0.7845\n",
            "Epoch 906/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4719 - acc: 0.7845 - val_loss: 0.4995 - val_acc: 0.7769\n",
            "Epoch 907/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4727 - acc: 0.7786 - val_loss: 0.4854 - val_acc: 0.7945\n",
            "Epoch 908/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4735 - acc: 0.7811 - val_loss: 0.5119 - val_acc: 0.7218\n",
            "Epoch 909/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4718 - acc: 0.7836 - val_loss: 0.4930 - val_acc: 0.7845\n",
            "Epoch 910/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4723 - acc: 0.7811 - val_loss: 0.5047 - val_acc: 0.7293\n",
            "Epoch 911/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4722 - acc: 0.7820 - val_loss: 0.4948 - val_acc: 0.7870\n",
            "Epoch 912/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4724 - acc: 0.7870 - val_loss: 0.5629 - val_acc: 0.7895\n",
            "Epoch 913/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4715 - acc: 0.7870 - val_loss: 0.5691 - val_acc: 0.7719\n",
            "Epoch 914/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4718 - acc: 0.7794 - val_loss: 0.5571 - val_acc: 0.7945\n",
            "Epoch 915/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4739 - acc: 0.7870 - val_loss: 0.5123 - val_acc: 0.7845\n",
            "Epoch 916/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4752 - acc: 0.7811 - val_loss: 0.5336 - val_acc: 0.7995\n",
            "Epoch 917/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7803 - val_loss: 0.4940 - val_acc: 0.7794\n",
            "Epoch 918/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4733 - acc: 0.7861 - val_loss: 0.5254 - val_acc: 0.7845\n",
            "Epoch 919/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7870 - val_loss: 0.5443 - val_acc: 0.7920\n",
            "Epoch 920/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4730 - acc: 0.7786 - val_loss: 0.5566 - val_acc: 0.7995\n",
            "Epoch 921/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4725 - acc: 0.7886 - val_loss: 0.4955 - val_acc: 0.7794\n",
            "Epoch 922/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4716 - acc: 0.7786 - val_loss: 0.4878 - val_acc: 0.7694\n",
            "Epoch 923/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4762 - acc: 0.7903 - val_loss: 0.4840 - val_acc: 0.7820\n",
            "Epoch 924/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4770 - acc: 0.7778 - val_loss: 0.4889 - val_acc: 0.7845\n",
            "Epoch 925/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4753 - acc: 0.7778 - val_loss: 0.4871 - val_acc: 0.7920\n",
            "Epoch 926/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.5006 - val_acc: 0.7293\n",
            "Epoch 927/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4740 - acc: 0.7794 - val_loss: 0.4859 - val_acc: 0.7845\n",
            "Epoch 928/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4718 - acc: 0.7861 - val_loss: 0.5068 - val_acc: 0.7268\n",
            "Epoch 929/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4737 - acc: 0.7845 - val_loss: 0.4859 - val_acc: 0.7794\n",
            "Epoch 930/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4743 - acc: 0.7845 - val_loss: 0.4858 - val_acc: 0.7845\n",
            "Epoch 931/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4742 - acc: 0.7769 - val_loss: 0.4855 - val_acc: 0.7970\n",
            "Epoch 932/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4721 - acc: 0.7845 - val_loss: 0.4991 - val_acc: 0.7920\n",
            "Epoch 933/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4696 - acc: 0.7853 - val_loss: 0.5078 - val_acc: 0.7995\n",
            "Epoch 934/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4697 - acc: 0.7778 - val_loss: 0.4962 - val_acc: 0.7845\n",
            "Epoch 935/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4765 - acc: 0.7753 - val_loss: 0.4926 - val_acc: 0.7995\n",
            "Epoch 936/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4721 - acc: 0.7870 - val_loss: 0.4866 - val_acc: 0.7845\n",
            "Epoch 937/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4703 - acc: 0.7753 - val_loss: 0.5011 - val_acc: 0.7920\n",
            "Epoch 938/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4734 - acc: 0.7820 - val_loss: 0.4943 - val_acc: 0.7870\n",
            "Epoch 939/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7803 - val_loss: 0.4925 - val_acc: 0.7995\n",
            "Epoch 940/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4718 - acc: 0.7836 - val_loss: 0.4866 - val_acc: 0.7970\n",
            "Epoch 941/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4726 - acc: 0.7761 - val_loss: 0.5075 - val_acc: 0.7945\n",
            "Epoch 942/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4719 - acc: 0.7820 - val_loss: 0.4810 - val_acc: 0.8020\n",
            "Epoch 943/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4744 - acc: 0.7853 - val_loss: 0.5108 - val_acc: 0.7268\n",
            "Epoch 944/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4724 - acc: 0.7853 - val_loss: 0.4920 - val_acc: 0.7794\n",
            "Epoch 945/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4719 - acc: 0.7895 - val_loss: 0.4861 - val_acc: 0.7995\n",
            "Epoch 946/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4705 - acc: 0.7886 - val_loss: 0.4948 - val_acc: 0.7895\n",
            "Epoch 947/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4724 - acc: 0.7803 - val_loss: 0.4917 - val_acc: 0.7870\n",
            "Epoch 948/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4745 - acc: 0.7811 - val_loss: 0.4982 - val_acc: 0.7769\n",
            "Epoch 949/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4726 - acc: 0.7870 - val_loss: 0.4943 - val_acc: 0.7970\n",
            "Epoch 950/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4730 - acc: 0.7845 - val_loss: 0.4936 - val_acc: 0.7794\n",
            "Epoch 951/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4710 - acc: 0.7820 - val_loss: 0.4978 - val_acc: 0.7343\n",
            "Epoch 952/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4715 - acc: 0.7811 - val_loss: 0.4952 - val_acc: 0.7820\n",
            "Epoch 953/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4726 - acc: 0.7886 - val_loss: 0.4901 - val_acc: 0.7820\n",
            "Epoch 954/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4736 - acc: 0.7886 - val_loss: 0.4919 - val_acc: 0.7920\n",
            "Epoch 955/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4710 - acc: 0.7911 - val_loss: 0.4910 - val_acc: 0.7794\n",
            "Epoch 956/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4723 - acc: 0.7836 - val_loss: 0.5189 - val_acc: 0.7895\n",
            "Epoch 957/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4754 - acc: 0.7794 - val_loss: 0.5118 - val_acc: 0.7544\n",
            "Epoch 958/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4721 - acc: 0.7803 - val_loss: 0.5075 - val_acc: 0.7794\n",
            "Epoch 959/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4686 - acc: 0.7845 - val_loss: 0.5026 - val_acc: 0.7845\n",
            "Epoch 960/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4742 - acc: 0.7753 - val_loss: 0.5039 - val_acc: 0.7895\n",
            "Epoch 961/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4731 - acc: 0.7786 - val_loss: 0.4840 - val_acc: 0.7895\n",
            "Epoch 962/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7836 - val_loss: 0.4898 - val_acc: 0.7845\n",
            "Epoch 963/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4715 - acc: 0.7836 - val_loss: 0.4871 - val_acc: 0.8020\n",
            "Epoch 964/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.5041 - val_acc: 0.7995\n",
            "Epoch 965/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4711 - acc: 0.7836 - val_loss: 0.5172 - val_acc: 0.7970\n",
            "Epoch 966/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4736 - acc: 0.7836 - val_loss: 0.5423 - val_acc: 0.7970\n",
            "Epoch 967/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4737 - acc: 0.7853 - val_loss: 0.5174 - val_acc: 0.7845\n",
            "Epoch 968/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4711 - acc: 0.7836 - val_loss: 0.5120 - val_acc: 0.7920\n",
            "Epoch 969/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4726 - acc: 0.7853 - val_loss: 0.5359 - val_acc: 0.7920\n",
            "Epoch 970/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4735 - acc: 0.7878 - val_loss: 0.5224 - val_acc: 0.7820\n",
            "Epoch 971/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4738 - acc: 0.7803 - val_loss: 0.5064 - val_acc: 0.7970\n",
            "Epoch 972/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4761 - acc: 0.7794 - val_loss: 0.4927 - val_acc: 0.7895\n",
            "Epoch 973/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4709 - acc: 0.7836 - val_loss: 0.5306 - val_acc: 0.7970\n",
            "Epoch 974/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4719 - acc: 0.7920 - val_loss: 0.5256 - val_acc: 0.7970\n",
            "Epoch 975/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4712 - acc: 0.7769 - val_loss: 0.5208 - val_acc: 0.7744\n",
            "Epoch 976/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4733 - acc: 0.7845 - val_loss: 0.5162 - val_acc: 0.7769\n",
            "Epoch 977/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.5233 - val_acc: 0.7794\n",
            "Epoch 978/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4724 - acc: 0.7820 - val_loss: 0.5154 - val_acc: 0.7895\n",
            "Epoch 979/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4712 - acc: 0.7820 - val_loss: 0.4968 - val_acc: 0.7870\n",
            "Epoch 980/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4697 - acc: 0.7786 - val_loss: 0.5013 - val_acc: 0.7895\n",
            "Epoch 981/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7803 - val_loss: 0.5001 - val_acc: 0.7569\n",
            "Epoch 982/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.7878 - val_loss: 0.5017 - val_acc: 0.7318\n",
            "Epoch 983/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7828 - val_loss: 0.5090 - val_acc: 0.7794\n",
            "Epoch 984/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4725 - acc: 0.7870 - val_loss: 0.4946 - val_acc: 0.7744\n",
            "Epoch 985/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4711 - acc: 0.7803 - val_loss: 0.5015 - val_acc: 0.7845\n",
            "Epoch 986/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4714 - acc: 0.7820 - val_loss: 0.5017 - val_acc: 0.7995\n",
            "Epoch 987/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4729 - acc: 0.7803 - val_loss: 0.4863 - val_acc: 0.7870\n",
            "Epoch 988/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4735 - acc: 0.7778 - val_loss: 0.4885 - val_acc: 0.7995\n",
            "Epoch 989/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4700 - acc: 0.7895 - val_loss: 0.5201 - val_acc: 0.7870\n",
            "Epoch 990/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4729 - acc: 0.7861 - val_loss: 0.5257 - val_acc: 0.7945\n",
            "Epoch 991/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4727 - acc: 0.7853 - val_loss: 0.4848 - val_acc: 0.7970\n",
            "Epoch 992/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4724 - acc: 0.7820 - val_loss: 0.4907 - val_acc: 0.7845\n",
            "Epoch 993/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4715 - acc: 0.7853 - val_loss: 0.5125 - val_acc: 0.7845\n",
            "Epoch 994/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4725 - acc: 0.7878 - val_loss: 0.5085 - val_acc: 0.7243\n",
            "Epoch 995/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7786 - val_loss: 0.4823 - val_acc: 0.7694\n",
            "Epoch 996/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4716 - acc: 0.7870 - val_loss: 0.4863 - val_acc: 0.7920\n",
            "Epoch 997/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4723 - acc: 0.7820 - val_loss: 0.5062 - val_acc: 0.7845\n",
            "Epoch 998/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4720 - acc: 0.7836 - val_loss: 0.4916 - val_acc: 0.7945\n",
            "Epoch 999/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4722 - acc: 0.7878 - val_loss: 0.4987 - val_acc: 0.7769\n",
            "Epoch 1000/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4723 - acc: 0.7853 - val_loss: 0.4885 - val_acc: 0.8020\n",
            "Epoch 1001/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4738 - acc: 0.7845 - val_loss: 0.4873 - val_acc: 0.7970\n",
            "Epoch 1002/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4729 - acc: 0.7836 - val_loss: 0.4859 - val_acc: 0.7744\n",
            "Epoch 1003/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4693 - acc: 0.7853 - val_loss: 0.4968 - val_acc: 0.7970\n",
            "Epoch 1004/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4721 - acc: 0.7845 - val_loss: 0.4980 - val_acc: 0.7995\n",
            "Epoch 1005/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4715 - acc: 0.7853 - val_loss: 0.4892 - val_acc: 0.7845\n",
            "Epoch 1006/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4724 - acc: 0.7794 - val_loss: 0.4802 - val_acc: 0.7845\n",
            "Epoch 1007/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4707 - acc: 0.7836 - val_loss: 0.4916 - val_acc: 0.7895\n",
            "Epoch 1008/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4712 - acc: 0.7861 - val_loss: 0.4969 - val_acc: 0.7895\n",
            "Epoch 1009/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7744 - val_loss: 0.5578 - val_acc: 0.7769\n",
            "Epoch 1010/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4740 - acc: 0.7836 - val_loss: 0.5842 - val_acc: 0.7719\n",
            "Epoch 1011/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4764 - acc: 0.7828 - val_loss: 0.5061 - val_acc: 0.7820\n",
            "Epoch 1012/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4761 - acc: 0.7769 - val_loss: 0.4822 - val_acc: 0.7920\n",
            "Epoch 1013/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4717 - acc: 0.7786 - val_loss: 0.4844 - val_acc: 0.7970\n",
            "Epoch 1014/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.7811 - val_loss: 0.4955 - val_acc: 0.7995\n",
            "Epoch 1015/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4708 - acc: 0.7861 - val_loss: 0.5049 - val_acc: 0.7970\n",
            "Epoch 1016/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4714 - acc: 0.7870 - val_loss: 0.5004 - val_acc: 0.8020\n",
            "Epoch 1017/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4744 - acc: 0.7878 - val_loss: 0.4888 - val_acc: 0.7845\n",
            "Epoch 1018/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4743 - acc: 0.7836 - val_loss: 0.4879 - val_acc: 0.7970\n",
            "Epoch 1019/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4746 - acc: 0.7853 - val_loss: 0.4867 - val_acc: 0.7845\n",
            "Epoch 1020/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4744 - acc: 0.7870 - val_loss: 0.4960 - val_acc: 0.7845\n",
            "Epoch 1021/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4712 - acc: 0.7853 - val_loss: 0.5017 - val_acc: 0.7995\n",
            "Epoch 1022/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4721 - acc: 0.7870 - val_loss: 0.4978 - val_acc: 0.7895\n",
            "Epoch 1023/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4718 - acc: 0.7853 - val_loss: 0.4926 - val_acc: 0.7669\n",
            "Epoch 1024/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4740 - acc: 0.7828 - val_loss: 0.5049 - val_acc: 0.7920\n",
            "Epoch 1025/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4740 - acc: 0.7820 - val_loss: 0.4867 - val_acc: 0.7769\n",
            "Epoch 1026/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4750 - acc: 0.7920 - val_loss: 0.4858 - val_acc: 0.7769\n",
            "Epoch 1027/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4715 - acc: 0.7853 - val_loss: 0.4928 - val_acc: 0.7769\n",
            "Epoch 1028/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4716 - acc: 0.7845 - val_loss: 0.4873 - val_acc: 0.7895\n",
            "Epoch 1029/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4718 - acc: 0.7811 - val_loss: 0.4865 - val_acc: 0.7845\n",
            "Epoch 1030/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4712 - acc: 0.7811 - val_loss: 0.4914 - val_acc: 0.7845\n",
            "Epoch 1031/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7744 - val_loss: 0.5053 - val_acc: 0.7343\n",
            "Epoch 1032/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4715 - acc: 0.7811 - val_loss: 0.5021 - val_acc: 0.7494\n",
            "Epoch 1033/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4702 - acc: 0.7886 - val_loss: 0.4890 - val_acc: 0.7845\n",
            "Epoch 1034/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4717 - acc: 0.7878 - val_loss: 0.4852 - val_acc: 0.7920\n",
            "Epoch 1035/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4734 - acc: 0.7786 - val_loss: 0.4830 - val_acc: 0.7744\n",
            "Epoch 1036/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4729 - acc: 0.7845 - val_loss: 0.4884 - val_acc: 0.7870\n",
            "Epoch 1037/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4728 - acc: 0.7903 - val_loss: 0.4895 - val_acc: 0.7970\n",
            "Epoch 1038/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4700 - acc: 0.7853 - val_loss: 0.4858 - val_acc: 0.7820\n",
            "Epoch 1039/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4717 - acc: 0.7786 - val_loss: 0.5058 - val_acc: 0.7719\n",
            "Epoch 1040/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4711 - acc: 0.7861 - val_loss: 0.4950 - val_acc: 0.7694\n",
            "Epoch 1041/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4744 - acc: 0.7711 - val_loss: 0.4847 - val_acc: 0.7719\n",
            "Epoch 1042/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4733 - acc: 0.7886 - val_loss: 0.4848 - val_acc: 0.7769\n",
            "Epoch 1043/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4719 - acc: 0.7895 - val_loss: 0.4851 - val_acc: 0.7870\n",
            "Epoch 1044/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4706 - acc: 0.7937 - val_loss: 0.4926 - val_acc: 0.7870\n",
            "Epoch 1045/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4747 - acc: 0.7861 - val_loss: 0.5105 - val_acc: 0.7870\n",
            "Epoch 1046/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4718 - acc: 0.7928 - val_loss: 0.4835 - val_acc: 0.7920\n",
            "Epoch 1047/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4709 - acc: 0.7870 - val_loss: 0.4973 - val_acc: 0.7845\n",
            "Epoch 1048/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4751 - acc: 0.7811 - val_loss: 0.4962 - val_acc: 0.7820\n",
            "Epoch 1049/10000\n",
            "1197/1197 [==============================] - 0s 92us/step - loss: 0.4712 - acc: 0.7845 - val_loss: 0.5007 - val_acc: 0.7895\n",
            "Epoch 1050/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4729 - acc: 0.7903 - val_loss: 0.4870 - val_acc: 0.7895\n",
            "Epoch 1051/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4726 - acc: 0.7861 - val_loss: 0.4944 - val_acc: 0.7895\n",
            "Epoch 1052/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4718 - acc: 0.7878 - val_loss: 0.4939 - val_acc: 0.7820\n",
            "Epoch 1053/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4748 - acc: 0.7794 - val_loss: 0.4913 - val_acc: 0.7870\n",
            "Epoch 1054/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4730 - acc: 0.7778 - val_loss: 0.4847 - val_acc: 0.7870\n",
            "Epoch 1055/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4701 - acc: 0.7903 - val_loss: 0.4884 - val_acc: 0.7870\n",
            "Epoch 1056/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4716 - acc: 0.7853 - val_loss: 0.4941 - val_acc: 0.7820\n",
            "Epoch 1057/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4709 - acc: 0.7886 - val_loss: 0.4878 - val_acc: 0.7870\n",
            "Epoch 1058/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4732 - acc: 0.7853 - val_loss: 0.4859 - val_acc: 0.7870\n",
            "Epoch 1059/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4717 - acc: 0.7811 - val_loss: 0.5016 - val_acc: 0.7945\n",
            "Epoch 1060/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4732 - acc: 0.7828 - val_loss: 0.4887 - val_acc: 0.7719\n",
            "Epoch 1061/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4707 - acc: 0.7870 - val_loss: 0.4948 - val_acc: 0.7845\n",
            "Epoch 1062/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4716 - acc: 0.7836 - val_loss: 0.4846 - val_acc: 0.7895\n",
            "Epoch 1063/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4709 - acc: 0.7878 - val_loss: 0.5157 - val_acc: 0.7318\n",
            "Epoch 1064/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4707 - acc: 0.7870 - val_loss: 0.5257 - val_acc: 0.7343\n",
            "Epoch 1065/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4718 - acc: 0.7878 - val_loss: 0.4879 - val_acc: 0.7995\n",
            "Epoch 1066/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4751 - acc: 0.7861 - val_loss: 0.4880 - val_acc: 0.7870\n",
            "Epoch 1067/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.4840 - val_acc: 0.7920\n",
            "Epoch 1068/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4694 - acc: 0.7878 - val_loss: 0.4925 - val_acc: 0.7870\n",
            "Epoch 1069/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4702 - acc: 0.7878 - val_loss: 0.4991 - val_acc: 0.7744\n",
            "Epoch 1070/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4724 - acc: 0.7811 - val_loss: 0.4876 - val_acc: 0.7845\n",
            "Epoch 1071/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4731 - acc: 0.7828 - val_loss: 0.4901 - val_acc: 0.7870\n",
            "Epoch 1072/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4730 - acc: 0.7853 - val_loss: 0.4834 - val_acc: 0.7845\n",
            "Epoch 1073/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.7845 - val_loss: 0.4882 - val_acc: 0.8020\n",
            "Epoch 1074/10000\n",
            "1197/1197 [==============================] - 0s 88us/step - loss: 0.4726 - acc: 0.7920 - val_loss: 0.4886 - val_acc: 0.7845\n",
            "Epoch 1075/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4713 - acc: 0.7895 - val_loss: 0.4883 - val_acc: 0.7845\n",
            "Epoch 1076/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4713 - acc: 0.7803 - val_loss: 0.4954 - val_acc: 0.7870\n",
            "Epoch 1077/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4726 - acc: 0.7878 - val_loss: 0.5014 - val_acc: 0.7845\n",
            "Epoch 1078/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4716 - acc: 0.7794 - val_loss: 0.5109 - val_acc: 0.7694\n",
            "Epoch 1079/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4728 - acc: 0.7845 - val_loss: 0.5335 - val_acc: 0.7845\n",
            "Epoch 1080/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4700 - acc: 0.7911 - val_loss: 0.5228 - val_acc: 0.7694\n",
            "Epoch 1081/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4705 - acc: 0.7828 - val_loss: 0.5196 - val_acc: 0.7920\n",
            "Epoch 1082/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4711 - acc: 0.7803 - val_loss: 0.4860 - val_acc: 0.7744\n",
            "Epoch 1083/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4710 - acc: 0.7886 - val_loss: 0.4857 - val_acc: 0.7895\n",
            "Epoch 1084/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4739 - acc: 0.7811 - val_loss: 0.5076 - val_acc: 0.7845\n",
            "Epoch 1085/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4750 - acc: 0.7820 - val_loss: 0.5030 - val_acc: 0.7744\n",
            "Epoch 1086/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7769 - val_loss: 0.4840 - val_acc: 0.7794\n",
            "Epoch 1087/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4704 - acc: 0.7828 - val_loss: 0.4846 - val_acc: 0.7820\n",
            "Epoch 1088/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7861 - val_loss: 0.4922 - val_acc: 0.7820\n",
            "Epoch 1089/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4719 - acc: 0.7878 - val_loss: 0.4849 - val_acc: 0.7769\n",
            "Epoch 1090/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4717 - acc: 0.7853 - val_loss: 0.4832 - val_acc: 0.7719\n",
            "Epoch 1091/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4732 - acc: 0.7870 - val_loss: 0.4836 - val_acc: 0.7895\n",
            "Epoch 1092/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4733 - acc: 0.7753 - val_loss: 0.4804 - val_acc: 0.7895\n",
            "Epoch 1093/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4724 - acc: 0.7753 - val_loss: 0.4889 - val_acc: 0.7895\n",
            "Epoch 1094/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4767 - acc: 0.7803 - val_loss: 0.4977 - val_acc: 0.7619\n",
            "Epoch 1095/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4753 - acc: 0.7903 - val_loss: 0.5021 - val_acc: 0.7419\n",
            "Epoch 1096/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4695 - acc: 0.7836 - val_loss: 0.5085 - val_acc: 0.7895\n",
            "Epoch 1097/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4744 - acc: 0.7861 - val_loss: 0.5167 - val_acc: 0.7769\n",
            "Epoch 1098/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4734 - acc: 0.7845 - val_loss: 0.5182 - val_acc: 0.7845\n",
            "Epoch 1099/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4691 - acc: 0.7895 - val_loss: 0.5000 - val_acc: 0.7644\n",
            "Epoch 1100/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4702 - acc: 0.7828 - val_loss: 0.4857 - val_acc: 0.7820\n",
            "Epoch 1101/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.7870 - val_loss: 0.4857 - val_acc: 0.7895\n",
            "Epoch 1102/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.5113 - val_acc: 0.7845\n",
            "Epoch 1103/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4738 - acc: 0.7786 - val_loss: 0.5073 - val_acc: 0.7895\n",
            "Epoch 1104/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4720 - acc: 0.7861 - val_loss: 0.5118 - val_acc: 0.7945\n",
            "Epoch 1105/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.5211 - val_acc: 0.7845\n",
            "Epoch 1106/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4708 - acc: 0.7744 - val_loss: 0.5156 - val_acc: 0.7920\n",
            "Epoch 1107/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4714 - acc: 0.7878 - val_loss: 0.5132 - val_acc: 0.7995\n",
            "Epoch 1108/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4734 - acc: 0.7920 - val_loss: 0.5026 - val_acc: 0.7769\n",
            "Epoch 1109/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4740 - acc: 0.7769 - val_loss: 0.5051 - val_acc: 0.7970\n",
            "Epoch 1110/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4693 - acc: 0.7811 - val_loss: 0.4899 - val_acc: 0.7794\n",
            "Epoch 1111/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4720 - acc: 0.7903 - val_loss: 0.4853 - val_acc: 0.7870\n",
            "Epoch 1112/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4671 - acc: 0.7895 - val_loss: 0.4881 - val_acc: 0.7820\n",
            "Epoch 1113/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4740 - acc: 0.7811 - val_loss: 0.4812 - val_acc: 0.7845\n",
            "Epoch 1114/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4722 - acc: 0.7761 - val_loss: 0.5378 - val_acc: 0.7920\n",
            "Epoch 1115/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4691 - acc: 0.7878 - val_loss: 0.5238 - val_acc: 0.7870\n",
            "Epoch 1116/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4713 - acc: 0.7870 - val_loss: 0.4868 - val_acc: 0.7920\n",
            "Epoch 1117/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.7878 - val_loss: 0.4899 - val_acc: 0.7870\n",
            "Epoch 1118/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4726 - acc: 0.7753 - val_loss: 0.4884 - val_acc: 0.7870\n",
            "Epoch 1119/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.4883 - val_acc: 0.7845\n",
            "Epoch 1120/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4703 - acc: 0.7928 - val_loss: 0.4919 - val_acc: 0.7820\n",
            "Epoch 1121/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4741 - acc: 0.7853 - val_loss: 0.4868 - val_acc: 0.7845\n",
            "Epoch 1122/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4713 - acc: 0.7828 - val_loss: 0.5026 - val_acc: 0.7870\n",
            "Epoch 1123/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7878 - val_loss: 0.4949 - val_acc: 0.7820\n",
            "Epoch 1124/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4734 - acc: 0.7820 - val_loss: 0.4879 - val_acc: 0.7845\n",
            "Epoch 1125/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4736 - acc: 0.7820 - val_loss: 0.5049 - val_acc: 0.7644\n",
            "Epoch 1126/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4738 - acc: 0.7769 - val_loss: 0.4911 - val_acc: 0.7845\n",
            "Epoch 1127/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7836 - val_loss: 0.4930 - val_acc: 0.7820\n",
            "Epoch 1128/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4729 - acc: 0.7811 - val_loss: 0.4846 - val_acc: 0.7870\n",
            "Epoch 1129/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4733 - acc: 0.7836 - val_loss: 0.4917 - val_acc: 0.7895\n",
            "Epoch 1130/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4715 - acc: 0.7836 - val_loss: 0.5208 - val_acc: 0.7870\n",
            "Epoch 1131/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4718 - acc: 0.7845 - val_loss: 0.5199 - val_acc: 0.7769\n",
            "Epoch 1132/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4732 - acc: 0.7811 - val_loss: 0.4865 - val_acc: 0.7995\n",
            "Epoch 1133/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7861 - val_loss: 0.4887 - val_acc: 0.7895\n",
            "Epoch 1134/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4727 - acc: 0.7845 - val_loss: 0.4845 - val_acc: 0.7794\n",
            "Epoch 1135/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4745 - acc: 0.7794 - val_loss: 0.4912 - val_acc: 0.7895\n",
            "Epoch 1136/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.5106 - val_acc: 0.7794\n",
            "Epoch 1137/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4722 - acc: 0.7836 - val_loss: 0.5182 - val_acc: 0.7845\n",
            "Epoch 1138/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4726 - acc: 0.7861 - val_loss: 0.5157 - val_acc: 0.7719\n",
            "Epoch 1139/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4733 - acc: 0.7845 - val_loss: 0.5060 - val_acc: 0.7845\n",
            "Epoch 1140/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4733 - acc: 0.7761 - val_loss: 0.4854 - val_acc: 0.7945\n",
            "Epoch 1141/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4703 - acc: 0.7870 - val_loss: 0.4849 - val_acc: 0.7845\n",
            "Epoch 1142/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4707 - acc: 0.7803 - val_loss: 0.4858 - val_acc: 0.7744\n",
            "Epoch 1143/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4721 - acc: 0.7853 - val_loss: 0.4836 - val_acc: 0.7895\n",
            "Epoch 1144/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4695 - acc: 0.7903 - val_loss: 0.4889 - val_acc: 0.7845\n",
            "Epoch 1145/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4688 - acc: 0.7845 - val_loss: 0.4919 - val_acc: 0.7820\n",
            "Epoch 1146/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4759 - acc: 0.7794 - val_loss: 0.5052 - val_acc: 0.7845\n",
            "Epoch 1147/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4742 - acc: 0.7853 - val_loss: 0.4920 - val_acc: 0.7744\n",
            "Epoch 1148/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.4712 - acc: 0.7703 - val_loss: 0.5024 - val_acc: 0.7845\n",
            "Epoch 1149/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4727 - acc: 0.7811 - val_loss: 0.4845 - val_acc: 0.7644\n",
            "Epoch 1150/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4729 - acc: 0.7820 - val_loss: 0.4847 - val_acc: 0.7694\n",
            "Epoch 1151/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4717 - acc: 0.7870 - val_loss: 0.5013 - val_acc: 0.7845\n",
            "Epoch 1152/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4697 - acc: 0.7853 - val_loss: 0.4988 - val_acc: 0.7845\n",
            "Epoch 1153/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4698 - acc: 0.7895 - val_loss: 0.4940 - val_acc: 0.7794\n",
            "Epoch 1154/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4737 - acc: 0.7828 - val_loss: 0.4866 - val_acc: 0.7895\n",
            "Epoch 1155/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4714 - acc: 0.7886 - val_loss: 0.4895 - val_acc: 0.7845\n",
            "Epoch 1156/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4683 - acc: 0.7836 - val_loss: 0.4932 - val_acc: 0.7619\n",
            "Epoch 1157/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4708 - acc: 0.7886 - val_loss: 0.4907 - val_acc: 0.7820\n",
            "Epoch 1158/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4754 - acc: 0.7652 - val_loss: 0.4851 - val_acc: 0.7794\n",
            "Epoch 1159/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4730 - acc: 0.7820 - val_loss: 0.4928 - val_acc: 0.7769\n",
            "Epoch 1160/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4688 - acc: 0.7886 - val_loss: 0.4866 - val_acc: 0.7820\n",
            "Epoch 1161/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4720 - acc: 0.7853 - val_loss: 0.4856 - val_acc: 0.7845\n",
            "Epoch 1162/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4691 - acc: 0.7870 - val_loss: 0.5080 - val_acc: 0.7870\n",
            "Epoch 1163/10000\n",
            "1197/1197 [==============================] - 0s 95us/step - loss: 0.4722 - acc: 0.7820 - val_loss: 0.5045 - val_acc: 0.7769\n",
            "Epoch 1164/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4719 - acc: 0.7853 - val_loss: 0.4833 - val_acc: 0.7995\n",
            "Epoch 1165/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4705 - acc: 0.7820 - val_loss: 0.5088 - val_acc: 0.7945\n",
            "Epoch 1166/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4712 - acc: 0.7845 - val_loss: 0.4942 - val_acc: 0.7694\n",
            "Epoch 1167/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4714 - acc: 0.7794 - val_loss: 0.4939 - val_acc: 0.7870\n",
            "Epoch 1168/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4717 - acc: 0.7845 - val_loss: 0.4885 - val_acc: 0.7820\n",
            "Epoch 1169/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4711 - acc: 0.7836 - val_loss: 0.4857 - val_acc: 0.7945\n",
            "Epoch 1170/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4745 - acc: 0.7719 - val_loss: 0.4919 - val_acc: 0.7769\n",
            "Epoch 1171/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4734 - acc: 0.7853 - val_loss: 0.4906 - val_acc: 0.7920\n",
            "Epoch 1172/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4710 - acc: 0.7870 - val_loss: 0.4865 - val_acc: 0.7870\n",
            "Epoch 1173/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4751 - acc: 0.7861 - val_loss: 0.5064 - val_acc: 0.7845\n",
            "Epoch 1174/10000\n",
            "1197/1197 [==============================] - 0s 68us/step - loss: 0.4729 - acc: 0.7870 - val_loss: 0.5703 - val_acc: 0.7920\n",
            "Epoch 1175/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4727 - acc: 0.7811 - val_loss: 0.5623 - val_acc: 0.7820\n",
            "Epoch 1176/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4716 - acc: 0.7836 - val_loss: 0.5359 - val_acc: 0.7820\n",
            "Epoch 1177/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4700 - acc: 0.7962 - val_loss: 0.4967 - val_acc: 0.7970\n",
            "Epoch 1178/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4741 - acc: 0.7803 - val_loss: 0.4955 - val_acc: 0.7870\n",
            "Epoch 1179/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4711 - acc: 0.7886 - val_loss: 0.4949 - val_acc: 0.7970\n",
            "Epoch 1180/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4748 - acc: 0.7803 - val_loss: 0.4838 - val_acc: 0.7794\n",
            "Epoch 1181/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4716 - acc: 0.7886 - val_loss: 0.5038 - val_acc: 0.7995\n",
            "Epoch 1182/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4703 - acc: 0.7820 - val_loss: 0.5089 - val_acc: 0.7870\n",
            "Epoch 1183/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4718 - acc: 0.7836 - val_loss: 0.4971 - val_acc: 0.7995\n",
            "Epoch 1184/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4714 - acc: 0.7861 - val_loss: 0.4904 - val_acc: 0.7895\n",
            "Epoch 1185/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4737 - acc: 0.7861 - val_loss: 0.4827 - val_acc: 0.7744\n",
            "Epoch 1186/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4713 - acc: 0.7878 - val_loss: 0.4846 - val_acc: 0.7895\n",
            "Epoch 1187/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4718 - acc: 0.7811 - val_loss: 0.4883 - val_acc: 0.7870\n",
            "Epoch 1188/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4709 - acc: 0.7878 - val_loss: 0.4846 - val_acc: 0.7920\n",
            "Epoch 1189/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.4712 - acc: 0.7895 - val_loss: 0.4852 - val_acc: 0.7870\n",
            "Epoch 1190/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4687 - acc: 0.7895 - val_loss: 0.5103 - val_acc: 0.7769\n",
            "Epoch 1191/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4724 - acc: 0.7761 - val_loss: 0.4845 - val_acc: 0.7895\n",
            "Epoch 1192/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4721 - acc: 0.7836 - val_loss: 0.4942 - val_acc: 0.7895\n",
            "Epoch 1193/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4710 - acc: 0.7853 - val_loss: 0.4855 - val_acc: 0.7845\n",
            "Epoch 1194/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4686 - acc: 0.7886 - val_loss: 0.4903 - val_acc: 0.7845\n",
            "Epoch 1195/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4736 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.7845\n",
            "Epoch 1196/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7836 - val_loss: 0.5147 - val_acc: 0.7845\n",
            "Epoch 1197/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4728 - acc: 0.7794 - val_loss: 0.5364 - val_acc: 0.7744\n",
            "Epoch 1198/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4707 - acc: 0.7845 - val_loss: 0.5200 - val_acc: 0.7845\n",
            "Epoch 1199/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4706 - acc: 0.7845 - val_loss: 0.4842 - val_acc: 0.7870\n",
            "Epoch 1200/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4688 - acc: 0.7928 - val_loss: 0.4925 - val_acc: 0.7870\n",
            "Epoch 1201/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.7794 - val_loss: 0.4838 - val_acc: 0.7744\n",
            "Epoch 1202/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.4909 - val_acc: 0.7744\n",
            "Epoch 1203/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4744 - acc: 0.7803 - val_loss: 0.4854 - val_acc: 0.7744\n",
            "Epoch 1204/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4715 - acc: 0.7845 - val_loss: 0.4906 - val_acc: 0.7694\n",
            "Epoch 1205/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4711 - acc: 0.7928 - val_loss: 0.4964 - val_acc: 0.7744\n",
            "Epoch 1206/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4708 - acc: 0.7870 - val_loss: 0.4948 - val_acc: 0.7769\n",
            "Epoch 1207/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4731 - acc: 0.7870 - val_loss: 0.5203 - val_acc: 0.7694\n",
            "Epoch 1208/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4701 - acc: 0.7853 - val_loss: 0.5046 - val_acc: 0.7845\n",
            "Epoch 1209/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4725 - acc: 0.7886 - val_loss: 0.4989 - val_acc: 0.7870\n",
            "Epoch 1210/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4700 - acc: 0.7861 - val_loss: 0.4915 - val_acc: 0.7820\n",
            "Epoch 1211/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.7861 - val_loss: 0.4873 - val_acc: 0.7794\n",
            "Epoch 1212/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4695 - acc: 0.7828 - val_loss: 0.4924 - val_acc: 0.7945\n",
            "Epoch 1213/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4714 - acc: 0.7853 - val_loss: 0.4864 - val_acc: 0.7845\n",
            "Epoch 1214/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4690 - acc: 0.7962 - val_loss: 0.4869 - val_acc: 0.7769\n",
            "Epoch 1215/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4730 - acc: 0.7811 - val_loss: 0.4899 - val_acc: 0.7769\n",
            "Epoch 1216/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4695 - acc: 0.7861 - val_loss: 0.4858 - val_acc: 0.7995\n",
            "Epoch 1217/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4710 - acc: 0.7970 - val_loss: 0.5165 - val_acc: 0.7920\n",
            "Epoch 1218/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4732 - acc: 0.7820 - val_loss: 0.5309 - val_acc: 0.7769\n",
            "Epoch 1219/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4738 - acc: 0.7828 - val_loss: 0.5273 - val_acc: 0.7845\n",
            "Epoch 1220/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.7836 - val_loss: 0.4823 - val_acc: 0.7744\n",
            "Epoch 1221/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4751 - acc: 0.7911 - val_loss: 0.4856 - val_acc: 0.7744\n",
            "Epoch 1222/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4744 - acc: 0.7820 - val_loss: 0.5048 - val_acc: 0.7794\n",
            "Epoch 1223/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4718 - acc: 0.7861 - val_loss: 0.4891 - val_acc: 0.7769\n",
            "Epoch 1224/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4699 - acc: 0.7861 - val_loss: 0.4867 - val_acc: 0.7920\n",
            "Epoch 1225/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4724 - acc: 0.7811 - val_loss: 0.4841 - val_acc: 0.7895\n",
            "Epoch 1226/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4738 - acc: 0.7861 - val_loss: 0.4857 - val_acc: 0.7945\n",
            "Epoch 1227/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4721 - acc: 0.7911 - val_loss: 0.4809 - val_acc: 0.7744\n",
            "Epoch 1228/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4695 - acc: 0.7895 - val_loss: 0.4859 - val_acc: 0.7870\n",
            "Epoch 1229/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4696 - acc: 0.7794 - val_loss: 0.4867 - val_acc: 0.7945\n",
            "Epoch 1230/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4705 - acc: 0.7878 - val_loss: 0.4841 - val_acc: 0.7744\n",
            "Epoch 1231/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7820 - val_loss: 0.4882 - val_acc: 0.7719\n",
            "Epoch 1232/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4735 - acc: 0.7811 - val_loss: 0.4879 - val_acc: 0.7820\n",
            "Epoch 1233/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4720 - acc: 0.7803 - val_loss: 0.4988 - val_acc: 0.7920\n",
            "Epoch 1234/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4724 - acc: 0.7845 - val_loss: 0.4867 - val_acc: 0.7694\n",
            "Epoch 1235/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4751 - acc: 0.7845 - val_loss: 0.4838 - val_acc: 0.7945\n",
            "Epoch 1236/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4747 - acc: 0.7895 - val_loss: 0.4824 - val_acc: 0.7870\n",
            "Epoch 1237/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4712 - acc: 0.7878 - val_loss: 0.4834 - val_acc: 0.7845\n",
            "Epoch 1238/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4718 - acc: 0.7886 - val_loss: 0.4877 - val_acc: 0.7794\n",
            "Epoch 1239/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.4721 - acc: 0.7828 - val_loss: 0.4936 - val_acc: 0.7794\n",
            "Epoch 1240/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4725 - acc: 0.7786 - val_loss: 0.5028 - val_acc: 0.7895\n",
            "Epoch 1241/10000\n",
            "1197/1197 [==============================] - 0s 69us/step - loss: 0.4722 - acc: 0.7794 - val_loss: 0.5158 - val_acc: 0.7995\n",
            "Epoch 1242/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4721 - acc: 0.7878 - val_loss: 0.4981 - val_acc: 0.7895\n",
            "Epoch 1243/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.7886 - val_loss: 0.5064 - val_acc: 0.7870\n",
            "Epoch 1244/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4710 - acc: 0.7886 - val_loss: 0.5040 - val_acc: 0.7895\n",
            "Epoch 1245/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4765 - acc: 0.7769 - val_loss: 0.4992 - val_acc: 0.7995\n",
            "Epoch 1246/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4718 - acc: 0.7778 - val_loss: 0.4972 - val_acc: 0.7845\n",
            "Epoch 1247/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4699 - acc: 0.7861 - val_loss: 0.4903 - val_acc: 0.7870\n",
            "Epoch 1248/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7878 - val_loss: 0.4977 - val_acc: 0.7845\n",
            "Epoch 1249/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4704 - acc: 0.7845 - val_loss: 0.5039 - val_acc: 0.7945\n",
            "Epoch 1250/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4725 - acc: 0.7828 - val_loss: 0.5090 - val_acc: 0.7845\n",
            "Epoch 1251/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4729 - acc: 0.7870 - val_loss: 0.4934 - val_acc: 0.7845\n",
            "Epoch 1252/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4724 - acc: 0.7853 - val_loss: 0.4996 - val_acc: 0.7945\n",
            "Epoch 1253/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4688 - acc: 0.7878 - val_loss: 0.4973 - val_acc: 0.7845\n",
            "Epoch 1254/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.7811 - val_loss: 0.4928 - val_acc: 0.7794\n",
            "Epoch 1255/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4706 - acc: 0.7870 - val_loss: 0.4940 - val_acc: 0.7895\n",
            "Epoch 1256/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4702 - acc: 0.7886 - val_loss: 0.4855 - val_acc: 0.7820\n",
            "Epoch 1257/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4717 - acc: 0.7870 - val_loss: 0.5005 - val_acc: 0.7970\n",
            "Epoch 1258/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4728 - acc: 0.7878 - val_loss: 0.5059 - val_acc: 0.7794\n",
            "Epoch 1259/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4692 - acc: 0.7853 - val_loss: 0.5450 - val_acc: 0.7619\n",
            "Epoch 1260/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4718 - acc: 0.7853 - val_loss: 0.5565 - val_acc: 0.7820\n",
            "Epoch 1261/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4722 - acc: 0.7870 - val_loss: 0.5264 - val_acc: 0.7794\n",
            "Epoch 1262/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4703 - acc: 0.7895 - val_loss: 0.5227 - val_acc: 0.7845\n",
            "Epoch 1263/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4700 - acc: 0.7845 - val_loss: 0.4856 - val_acc: 0.7895\n",
            "Epoch 1264/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4745 - acc: 0.7836 - val_loss: 0.4845 - val_acc: 0.7794\n",
            "Epoch 1265/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4733 - acc: 0.7845 - val_loss: 0.4883 - val_acc: 0.7945\n",
            "Epoch 1266/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4712 - acc: 0.7836 - val_loss: 0.4878 - val_acc: 0.7820\n",
            "Epoch 1267/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4705 - acc: 0.7786 - val_loss: 0.4890 - val_acc: 0.7845\n",
            "Epoch 1268/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4703 - acc: 0.7828 - val_loss: 0.4839 - val_acc: 0.7820\n",
            "Epoch 1269/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4739 - acc: 0.7769 - val_loss: 0.4932 - val_acc: 0.7694\n",
            "Epoch 1270/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4714 - acc: 0.7811 - val_loss: 0.4893 - val_acc: 0.7845\n",
            "Epoch 1271/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4694 - acc: 0.7886 - val_loss: 0.4933 - val_acc: 0.7794\n",
            "Epoch 1272/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.5279 - val_acc: 0.7694\n",
            "Epoch 1273/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4693 - acc: 0.7811 - val_loss: 0.5401 - val_acc: 0.7920\n",
            "Epoch 1274/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4718 - acc: 0.7769 - val_loss: 0.5264 - val_acc: 0.7744\n",
            "Epoch 1275/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4747 - acc: 0.7861 - val_loss: 0.5023 - val_acc: 0.8045\n",
            "Epoch 1276/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4726 - acc: 0.7845 - val_loss: 0.4915 - val_acc: 0.7995\n",
            "Epoch 1277/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4711 - acc: 0.7803 - val_loss: 0.4922 - val_acc: 0.7870\n",
            "Epoch 1278/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4730 - acc: 0.7845 - val_loss: 0.4890 - val_acc: 0.7895\n",
            "Epoch 1279/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4714 - acc: 0.7861 - val_loss: 0.4885 - val_acc: 0.7920\n",
            "Epoch 1280/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4716 - acc: 0.7903 - val_loss: 0.5294 - val_acc: 0.7895\n",
            "Epoch 1281/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4704 - acc: 0.7820 - val_loss: 0.5321 - val_acc: 0.7920\n",
            "Epoch 1282/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4710 - acc: 0.7845 - val_loss: 0.4978 - val_acc: 0.7820\n",
            "Epoch 1283/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4731 - acc: 0.7786 - val_loss: 0.5292 - val_acc: 0.7820\n",
            "Epoch 1284/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4710 - acc: 0.7828 - val_loss: 0.5033 - val_acc: 0.7794\n",
            "Epoch 1285/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4750 - acc: 0.7769 - val_loss: 0.5200 - val_acc: 0.7945\n",
            "Epoch 1286/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4709 - acc: 0.7920 - val_loss: 0.5081 - val_acc: 0.7895\n",
            "Epoch 1287/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4723 - acc: 0.7895 - val_loss: 0.4851 - val_acc: 0.7920\n",
            "Epoch 1288/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4712 - acc: 0.7911 - val_loss: 0.4886 - val_acc: 0.7769\n",
            "Epoch 1289/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4726 - acc: 0.7836 - val_loss: 0.4883 - val_acc: 0.7845\n",
            "Epoch 1290/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4741 - acc: 0.7820 - val_loss: 0.4844 - val_acc: 0.7895\n",
            "Epoch 1291/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4729 - acc: 0.7878 - val_loss: 0.5057 - val_acc: 0.7870\n",
            "Epoch 1292/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7820 - val_loss: 0.5048 - val_acc: 0.7995\n",
            "Epoch 1293/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4725 - acc: 0.7836 - val_loss: 0.4841 - val_acc: 0.7920\n",
            "Epoch 1294/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4721 - acc: 0.7861 - val_loss: 0.4920 - val_acc: 0.7820\n",
            "Epoch 1295/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4711 - acc: 0.7870 - val_loss: 0.5098 - val_acc: 0.7870\n",
            "Epoch 1296/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4708 - acc: 0.7861 - val_loss: 0.5310 - val_acc: 0.7794\n",
            "Epoch 1297/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4714 - acc: 0.7861 - val_loss: 0.4978 - val_acc: 0.7619\n",
            "Epoch 1298/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4711 - acc: 0.7920 - val_loss: 0.4894 - val_acc: 0.7870\n",
            "Epoch 1299/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4732 - acc: 0.7836 - val_loss: 0.5086 - val_acc: 0.7794\n",
            "Epoch 1300/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4718 - acc: 0.7861 - val_loss: 0.5178 - val_acc: 0.7820\n",
            "Epoch 1301/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4729 - acc: 0.7845 - val_loss: 0.5222 - val_acc: 0.7920\n",
            "Epoch 1302/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4708 - acc: 0.7895 - val_loss: 0.5149 - val_acc: 0.7945\n",
            "Epoch 1303/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7870 - val_loss: 0.5202 - val_acc: 0.7870\n",
            "Epoch 1304/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4697 - acc: 0.7878 - val_loss: 0.5051 - val_acc: 0.7920\n",
            "Epoch 1305/10000\n",
            "1197/1197 [==============================] - 0s 93us/step - loss: 0.4712 - acc: 0.7895 - val_loss: 0.5057 - val_acc: 0.7845\n",
            "Epoch 1306/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4707 - acc: 0.7886 - val_loss: 0.4939 - val_acc: 0.7870\n",
            "Epoch 1307/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4696 - acc: 0.7861 - val_loss: 0.5016 - val_acc: 0.7895\n",
            "Epoch 1308/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4701 - acc: 0.7920 - val_loss: 0.4929 - val_acc: 0.7920\n",
            "Epoch 1309/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4719 - acc: 0.7895 - val_loss: 0.5003 - val_acc: 0.7945\n",
            "Epoch 1310/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4709 - acc: 0.7736 - val_loss: 0.4927 - val_acc: 0.7895\n",
            "Epoch 1311/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4755 - acc: 0.7820 - val_loss: 0.5013 - val_acc: 0.7920\n",
            "Epoch 1312/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4719 - acc: 0.7811 - val_loss: 0.4923 - val_acc: 0.7870\n",
            "Epoch 1313/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4749 - acc: 0.7861 - val_loss: 0.4887 - val_acc: 0.7845\n",
            "Epoch 1314/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4742 - acc: 0.7861 - val_loss: 0.4902 - val_acc: 0.7895\n",
            "Epoch 1315/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4726 - acc: 0.7928 - val_loss: 0.4926 - val_acc: 0.7895\n",
            "Epoch 1316/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4707 - acc: 0.7836 - val_loss: 0.4947 - val_acc: 0.7945\n",
            "Epoch 1317/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4740 - acc: 0.7803 - val_loss: 0.4972 - val_acc: 0.7895\n",
            "Epoch 1318/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4713 - acc: 0.7836 - val_loss: 0.5105 - val_acc: 0.7845\n",
            "Epoch 1319/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4734 - acc: 0.7853 - val_loss: 0.4967 - val_acc: 0.7769\n",
            "Epoch 1320/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.4903 - val_acc: 0.7920\n",
            "Epoch 1321/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4696 - acc: 0.7845 - val_loss: 0.4889 - val_acc: 0.7895\n",
            "Epoch 1322/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4736 - acc: 0.7828 - val_loss: 0.4916 - val_acc: 0.7845\n",
            "Epoch 1323/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4709 - acc: 0.7794 - val_loss: 0.5093 - val_acc: 0.7945\n",
            "Epoch 1324/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4703 - acc: 0.7920 - val_loss: 0.5087 - val_acc: 0.7845\n",
            "Epoch 1325/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4691 - acc: 0.7903 - val_loss: 0.5047 - val_acc: 0.7920\n",
            "Epoch 1326/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4718 - acc: 0.7853 - val_loss: 0.5036 - val_acc: 0.7845\n",
            "Epoch 1327/10000\n",
            "1197/1197 [==============================] - 0s 89us/step - loss: 0.4704 - acc: 0.7861 - val_loss: 0.5002 - val_acc: 0.7970\n",
            "Epoch 1328/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4673 - acc: 0.7845 - val_loss: 0.4993 - val_acc: 0.7845\n",
            "Epoch 1329/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4710 - acc: 0.7845 - val_loss: 0.4864 - val_acc: 0.7970\n",
            "Epoch 1330/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4758 - acc: 0.7811 - val_loss: 0.4905 - val_acc: 0.7845\n",
            "Epoch 1331/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4719 - acc: 0.7845 - val_loss: 0.5032 - val_acc: 0.7845\n",
            "Epoch 1332/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4725 - acc: 0.7820 - val_loss: 0.5034 - val_acc: 0.7870\n",
            "Epoch 1333/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4711 - acc: 0.7853 - val_loss: 0.5050 - val_acc: 0.7920\n",
            "Epoch 1334/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4749 - acc: 0.7836 - val_loss: 0.4879 - val_acc: 0.7845\n",
            "Epoch 1335/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4748 - acc: 0.7794 - val_loss: 0.4869 - val_acc: 0.7794\n",
            "Epoch 1336/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4724 - acc: 0.7828 - val_loss: 0.4841 - val_acc: 0.7820\n",
            "Epoch 1337/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4718 - acc: 0.7886 - val_loss: 0.4885 - val_acc: 0.7744\n",
            "Epoch 1338/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.7820 - val_loss: 0.4920 - val_acc: 0.7970\n",
            "Epoch 1339/10000\n",
            "1197/1197 [==============================] - 0s 89us/step - loss: 0.4739 - acc: 0.7794 - val_loss: 0.4997 - val_acc: 0.7769\n",
            "Epoch 1340/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4720 - acc: 0.7895 - val_loss: 0.5188 - val_acc: 0.7895\n",
            "Epoch 1341/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4693 - acc: 0.7870 - val_loss: 0.5210 - val_acc: 0.7945\n",
            "Epoch 1342/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4738 - acc: 0.7853 - val_loss: 0.5033 - val_acc: 0.7870\n",
            "Epoch 1343/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4698 - acc: 0.7861 - val_loss: 0.5047 - val_acc: 0.7895\n",
            "Epoch 1344/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4705 - acc: 0.7945 - val_loss: 0.5048 - val_acc: 0.7820\n",
            "Epoch 1345/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4711 - acc: 0.7911 - val_loss: 0.4982 - val_acc: 0.7870\n",
            "Epoch 1346/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4715 - acc: 0.7853 - val_loss: 0.4890 - val_acc: 0.7719\n",
            "Epoch 1347/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4737 - acc: 0.7861 - val_loss: 0.5159 - val_acc: 0.7895\n",
            "Epoch 1348/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4734 - acc: 0.7878 - val_loss: 0.5213 - val_acc: 0.7744\n",
            "Epoch 1349/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4720 - acc: 0.7836 - val_loss: 0.4848 - val_acc: 0.7845\n",
            "Epoch 1350/10000\n",
            "1197/1197 [==============================] - 0s 85us/step - loss: 0.4711 - acc: 0.7886 - val_loss: 0.4901 - val_acc: 0.7820\n",
            "Epoch 1351/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4713 - acc: 0.7911 - val_loss: 0.4879 - val_acc: 0.7845\n",
            "Epoch 1352/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4718 - acc: 0.7845 - val_loss: 0.4871 - val_acc: 0.7945\n",
            "Epoch 1353/10000\n",
            "1197/1197 [==============================] - 0s 91us/step - loss: 0.4710 - acc: 0.7811 - val_loss: 0.4898 - val_acc: 0.7870\n",
            "Epoch 1354/10000\n",
            "1197/1197 [==============================] - 0s 94us/step - loss: 0.4761 - acc: 0.7761 - val_loss: 0.4853 - val_acc: 0.7845\n",
            "Epoch 1355/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4716 - acc: 0.7853 - val_loss: 0.4877 - val_acc: 0.7995\n",
            "Epoch 1356/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4715 - acc: 0.7878 - val_loss: 0.5193 - val_acc: 0.7794\n",
            "Epoch 1357/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4723 - acc: 0.7803 - val_loss: 0.5103 - val_acc: 0.7870\n",
            "Epoch 1358/10000\n",
            "1197/1197 [==============================] - 0s 89us/step - loss: 0.4703 - acc: 0.7845 - val_loss: 0.4847 - val_acc: 0.7794\n",
            "Epoch 1359/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4707 - acc: 0.7920 - val_loss: 0.5022 - val_acc: 0.7920\n",
            "Epoch 1360/10000\n",
            "1197/1197 [==============================] - 0s 88us/step - loss: 0.4718 - acc: 0.7803 - val_loss: 0.4860 - val_acc: 0.7845\n",
            "Epoch 1361/10000\n",
            "1197/1197 [==============================] - 0s 83us/step - loss: 0.4712 - acc: 0.7853 - val_loss: 0.5004 - val_acc: 0.7820\n",
            "Epoch 1362/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4719 - acc: 0.7870 - val_loss: 0.4838 - val_acc: 0.7845\n",
            "Epoch 1363/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4709 - acc: 0.7970 - val_loss: 0.4849 - val_acc: 0.7820\n",
            "Epoch 1364/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4711 - acc: 0.7861 - val_loss: 0.4986 - val_acc: 0.7694\n",
            "Epoch 1365/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4729 - acc: 0.7845 - val_loss: 0.5149 - val_acc: 0.7845\n",
            "Epoch 1366/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4746 - acc: 0.7861 - val_loss: 0.5019 - val_acc: 0.7845\n",
            "Epoch 1367/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4725 - acc: 0.7803 - val_loss: 0.4863 - val_acc: 0.7845\n",
            "Epoch 1368/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4715 - acc: 0.7811 - val_loss: 0.4855 - val_acc: 0.7820\n",
            "Epoch 1369/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4706 - acc: 0.7820 - val_loss: 0.4962 - val_acc: 0.7845\n",
            "Epoch 1370/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4694 - acc: 0.7870 - val_loss: 0.4875 - val_acc: 0.7794\n",
            "Epoch 1371/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4713 - acc: 0.7903 - val_loss: 0.5089 - val_acc: 0.7794\n",
            "Epoch 1372/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4724 - acc: 0.7845 - val_loss: 0.5056 - val_acc: 0.7769\n",
            "Epoch 1373/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4730 - acc: 0.7803 - val_loss: 0.4901 - val_acc: 0.7870\n",
            "Epoch 1374/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4707 - acc: 0.7953 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 1375/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4691 - acc: 0.7861 - val_loss: 0.5007 - val_acc: 0.7870\n",
            "Epoch 1376/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4688 - acc: 0.7878 - val_loss: 0.5130 - val_acc: 0.7895\n",
            "Epoch 1377/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4715 - acc: 0.7853 - val_loss: 0.4948 - val_acc: 0.7845\n",
            "Epoch 1378/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4733 - acc: 0.7761 - val_loss: 0.5126 - val_acc: 0.7820\n",
            "Epoch 1379/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4714 - acc: 0.7895 - val_loss: 0.5050 - val_acc: 0.7744\n",
            "Epoch 1380/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.4914 - val_acc: 0.7870\n",
            "Epoch 1381/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4715 - acc: 0.7744 - val_loss: 0.4974 - val_acc: 0.7945\n",
            "Epoch 1382/10000\n",
            "1197/1197 [==============================] - 0s 89us/step - loss: 0.4719 - acc: 0.7861 - val_loss: 0.5105 - val_acc: 0.7719\n",
            "Epoch 1383/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4712 - acc: 0.7845 - val_loss: 0.5008 - val_acc: 0.7744\n",
            "Epoch 1384/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4717 - acc: 0.7786 - val_loss: 0.4942 - val_acc: 0.7845\n",
            "Epoch 1385/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4705 - acc: 0.7836 - val_loss: 0.4920 - val_acc: 0.7845\n",
            "Epoch 1386/10000\n",
            "1197/1197 [==============================] - 0s 81us/step - loss: 0.4714 - acc: 0.7903 - val_loss: 0.4887 - val_acc: 0.7744\n",
            "Epoch 1387/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4729 - acc: 0.7886 - val_loss: 0.4858 - val_acc: 0.7820\n",
            "Epoch 1388/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4745 - acc: 0.7853 - val_loss: 0.4825 - val_acc: 0.7870\n",
            "Epoch 1389/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.7836 - val_loss: 0.4853 - val_acc: 0.7719\n",
            "Epoch 1390/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4724 - acc: 0.7861 - val_loss: 0.4966 - val_acc: 0.7945\n",
            "Epoch 1391/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4696 - acc: 0.7878 - val_loss: 0.4939 - val_acc: 0.7945\n",
            "Epoch 1392/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4744 - acc: 0.7836 - val_loss: 0.4939 - val_acc: 0.7845\n",
            "Epoch 1393/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4717 - acc: 0.7845 - val_loss: 0.4876 - val_acc: 0.7870\n",
            "Epoch 1394/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4746 - acc: 0.7786 - val_loss: 0.4922 - val_acc: 0.7769\n",
            "Epoch 1395/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4712 - acc: 0.7895 - val_loss: 0.4872 - val_acc: 0.7845\n",
            "Epoch 1396/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4713 - acc: 0.7820 - val_loss: 0.4881 - val_acc: 0.7870\n",
            "Epoch 1397/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4718 - acc: 0.7803 - val_loss: 0.4885 - val_acc: 0.7870\n",
            "Epoch 1398/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4703 - acc: 0.7845 - val_loss: 0.4869 - val_acc: 0.7820\n",
            "Epoch 1399/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4728 - acc: 0.7911 - val_loss: 0.4838 - val_acc: 0.7769\n",
            "Epoch 1400/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4733 - acc: 0.7828 - val_loss: 0.4857 - val_acc: 0.7920\n",
            "Epoch 1401/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4714 - acc: 0.7870 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 1402/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4732 - acc: 0.7836 - val_loss: 0.4908 - val_acc: 0.7845\n",
            "Epoch 1403/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4703 - acc: 0.7828 - val_loss: 0.4865 - val_acc: 0.7820\n",
            "Epoch 1404/10000\n",
            "1197/1197 [==============================] - 0s 82us/step - loss: 0.4705 - acc: 0.7836 - val_loss: 0.4990 - val_acc: 0.7920\n",
            "Epoch 1405/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4728 - acc: 0.7794 - val_loss: 0.5076 - val_acc: 0.7870\n",
            "Epoch 1406/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4694 - acc: 0.7870 - val_loss: 0.5036 - val_acc: 0.7694\n",
            "Epoch 1407/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4670 - acc: 0.7945 - val_loss: 0.4904 - val_acc: 0.7719\n",
            "Epoch 1408/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4721 - acc: 0.7878 - val_loss: 0.4878 - val_acc: 0.7920\n",
            "Epoch 1409/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4703 - acc: 0.7878 - val_loss: 0.4995 - val_acc: 0.7820\n",
            "Epoch 1410/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4731 - acc: 0.7828 - val_loss: 0.5149 - val_acc: 0.7970\n",
            "Epoch 1411/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4689 - acc: 0.7820 - val_loss: 0.5014 - val_acc: 0.7769\n",
            "Epoch 1412/10000\n",
            "1197/1197 [==============================] - 0s 68us/step - loss: 0.4700 - acc: 0.7878 - val_loss: 0.4891 - val_acc: 0.7794\n",
            "Epoch 1413/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4695 - acc: 0.7853 - val_loss: 0.4905 - val_acc: 0.7794\n",
            "Epoch 1414/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4721 - acc: 0.7928 - val_loss: 0.4916 - val_acc: 0.7769\n",
            "Epoch 1415/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4745 - acc: 0.7853 - val_loss: 0.4867 - val_acc: 0.7719\n",
            "Epoch 1416/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4691 - acc: 0.7895 - val_loss: 0.4852 - val_acc: 0.7945\n",
            "Epoch 1417/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4749 - acc: 0.7794 - val_loss: 0.4885 - val_acc: 0.7794\n",
            "Epoch 1418/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4694 - acc: 0.7878 - val_loss: 0.5178 - val_acc: 0.7920\n",
            "Epoch 1419/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4721 - acc: 0.7903 - val_loss: 0.4952 - val_acc: 0.7719\n",
            "Epoch 1420/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4741 - acc: 0.7803 - val_loss: 0.4852 - val_acc: 0.7820\n",
            "Epoch 1421/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4690 - acc: 0.7903 - val_loss: 0.4866 - val_acc: 0.7820\n",
            "Epoch 1422/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4729 - acc: 0.7861 - val_loss: 0.4905 - val_acc: 0.7820\n",
            "Epoch 1423/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4748 - acc: 0.7845 - val_loss: 0.4906 - val_acc: 0.7895\n",
            "Epoch 1424/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4716 - acc: 0.7870 - val_loss: 0.4937 - val_acc: 0.7870\n",
            "Epoch 1425/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4722 - acc: 0.7870 - val_loss: 0.4931 - val_acc: 0.7769\n",
            "Epoch 1426/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4713 - acc: 0.7803 - val_loss: 0.4889 - val_acc: 0.7845\n",
            "Epoch 1427/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4722 - acc: 0.7836 - val_loss: 0.4902 - val_acc: 0.7820\n",
            "Epoch 1428/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4708 - acc: 0.7778 - val_loss: 0.4934 - val_acc: 0.7870\n",
            "Epoch 1429/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4705 - acc: 0.7845 - val_loss: 0.4975 - val_acc: 0.7870\n",
            "Epoch 1430/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4693 - acc: 0.7878 - val_loss: 0.4937 - val_acc: 0.7820\n",
            "Epoch 1431/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4682 - acc: 0.7886 - val_loss: 0.4922 - val_acc: 0.7920\n",
            "Epoch 1432/10000\n",
            "1197/1197 [==============================] - 0s 86us/step - loss: 0.4696 - acc: 0.7886 - val_loss: 0.4920 - val_acc: 0.7845\n",
            "Epoch 1433/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4708 - acc: 0.7911 - val_loss: 0.4911 - val_acc: 0.7945\n",
            "Epoch 1434/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4746 - acc: 0.7803 - val_loss: 0.4901 - val_acc: 0.7794\n",
            "Epoch 1435/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4710 - acc: 0.7861 - val_loss: 0.4852 - val_acc: 0.7744\n",
            "Epoch 1436/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4715 - acc: 0.7845 - val_loss: 0.4847 - val_acc: 0.7769\n",
            "Epoch 1437/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4747 - acc: 0.7803 - val_loss: 0.4856 - val_acc: 0.7744\n",
            "Epoch 1438/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4714 - acc: 0.7920 - val_loss: 0.4994 - val_acc: 0.7744\n",
            "Epoch 1439/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4715 - acc: 0.7861 - val_loss: 0.5038 - val_acc: 0.7719\n",
            "Epoch 1440/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4730 - acc: 0.7828 - val_loss: 0.5248 - val_acc: 0.7820\n",
            "Epoch 1441/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4726 - acc: 0.7803 - val_loss: 0.5019 - val_acc: 0.7820\n",
            "Epoch 1442/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4718 - acc: 0.7870 - val_loss: 0.4966 - val_acc: 0.7845\n",
            "Epoch 1443/10000\n",
            "1197/1197 [==============================] - 0s 84us/step - loss: 0.4712 - acc: 0.7803 - val_loss: 0.4891 - val_acc: 0.7845\n",
            "Epoch 1444/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4696 - acc: 0.7886 - val_loss: 0.4861 - val_acc: 0.7845\n",
            "Epoch 1445/10000\n",
            "1197/1197 [==============================] - 0s 77us/step - loss: 0.4685 - acc: 0.7886 - val_loss: 0.4894 - val_acc: 0.7769\n",
            "Epoch 1446/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4761 - acc: 0.7811 - val_loss: 0.4872 - val_acc: 0.7895\n",
            "Epoch 1447/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4705 - acc: 0.7886 - val_loss: 0.5111 - val_acc: 0.7744\n",
            "Epoch 1448/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4719 - acc: 0.7853 - val_loss: 0.5284 - val_acc: 0.7920\n",
            "Epoch 1449/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4722 - acc: 0.7794 - val_loss: 0.5212 - val_acc: 0.7895\n",
            "Epoch 1450/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4684 - acc: 0.7953 - val_loss: 0.5177 - val_acc: 0.7820\n",
            "Epoch 1451/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4712 - acc: 0.7861 - val_loss: 0.5246 - val_acc: 0.7769\n",
            "Epoch 1452/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4739 - acc: 0.7836 - val_loss: 0.4874 - val_acc: 0.7820\n",
            "Epoch 1453/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4715 - acc: 0.7870 - val_loss: 0.4919 - val_acc: 0.7769\n",
            "Epoch 1454/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4699 - acc: 0.7845 - val_loss: 0.5041 - val_acc: 0.7870\n",
            "Epoch 1455/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4708 - acc: 0.7886 - val_loss: 0.5393 - val_acc: 0.7794\n",
            "Epoch 1456/10000\n",
            "1197/1197 [==============================] - 0s 79us/step - loss: 0.4717 - acc: 0.7903 - val_loss: 0.4992 - val_acc: 0.7744\n",
            "Epoch 1457/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4754 - acc: 0.7828 - val_loss: 0.4960 - val_acc: 0.7845\n",
            "Epoch 1458/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4720 - acc: 0.7920 - val_loss: 0.4850 - val_acc: 0.7870\n",
            "Epoch 1459/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4693 - acc: 0.7878 - val_loss: 0.4912 - val_acc: 0.7895\n",
            "Epoch 1460/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4729 - acc: 0.7794 - val_loss: 0.4941 - val_acc: 0.7895\n",
            "Epoch 1461/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4768 - acc: 0.7811 - val_loss: 0.4867 - val_acc: 0.7870\n",
            "Epoch 1462/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4729 - acc: 0.7886 - val_loss: 0.4943 - val_acc: 0.7820\n",
            "Epoch 1463/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4733 - acc: 0.7836 - val_loss: 0.4867 - val_acc: 0.7870\n",
            "Epoch 1464/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4694 - acc: 0.7836 - val_loss: 0.4894 - val_acc: 0.7870\n",
            "Epoch 1465/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4713 - acc: 0.7861 - val_loss: 0.4849 - val_acc: 0.7920\n",
            "Epoch 1466/10000\n",
            "1197/1197 [==============================] - 0s 80us/step - loss: 0.4693 - acc: 0.7820 - val_loss: 0.4840 - val_acc: 0.7719\n",
            "Epoch 1467/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4700 - acc: 0.7836 - val_loss: 0.4855 - val_acc: 0.7895\n",
            "Epoch 1468/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4694 - acc: 0.7911 - val_loss: 0.4948 - val_acc: 0.7870\n",
            "Epoch 1469/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4737 - acc: 0.7811 - val_loss: 0.4975 - val_acc: 0.7744\n",
            "Epoch 1470/10000\n",
            "1197/1197 [==============================] - 0s 70us/step - loss: 0.4709 - acc: 0.7861 - val_loss: 0.4865 - val_acc: 0.7945\n",
            "Epoch 1471/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4706 - acc: 0.7820 - val_loss: 0.4893 - val_acc: 0.7970\n",
            "Epoch 1472/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4700 - acc: 0.7861 - val_loss: 0.4917 - val_acc: 0.7845\n",
            "Epoch 1473/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4706 - acc: 0.7920 - val_loss: 0.4892 - val_acc: 0.7845\n",
            "Epoch 1474/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4723 - acc: 0.7845 - val_loss: 0.4878 - val_acc: 0.7995\n",
            "Epoch 1475/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4732 - acc: 0.7828 - val_loss: 0.4938 - val_acc: 0.7945\n",
            "Epoch 1476/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4690 - acc: 0.7937 - val_loss: 0.5034 - val_acc: 0.7920\n",
            "Epoch 1477/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4734 - acc: 0.7769 - val_loss: 0.5061 - val_acc: 0.7719\n",
            "Epoch 1478/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4698 - acc: 0.7870 - val_loss: 0.4999 - val_acc: 0.7845\n",
            "Epoch 1479/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4763 - acc: 0.7786 - val_loss: 0.4971 - val_acc: 0.7820\n",
            "Epoch 1480/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4728 - acc: 0.7853 - val_loss: 0.5055 - val_acc: 0.7694\n",
            "Epoch 1481/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4708 - acc: 0.7870 - val_loss: 0.4941 - val_acc: 0.7820\n",
            "Epoch 1482/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4717 - acc: 0.7853 - val_loss: 0.4877 - val_acc: 0.7820\n",
            "Epoch 1483/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4705 - acc: 0.7828 - val_loss: 0.4996 - val_acc: 0.7820\n",
            "Epoch 1484/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4702 - acc: 0.7886 - val_loss: 0.4952 - val_acc: 0.7820\n",
            "Epoch 1485/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4706 - acc: 0.7886 - val_loss: 0.4873 - val_acc: 0.7794\n",
            "Epoch 1486/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4715 - acc: 0.7828 - val_loss: 0.4869 - val_acc: 0.7744\n",
            "Epoch 1487/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4679 - acc: 0.7895 - val_loss: 0.4993 - val_acc: 0.7744\n",
            "Epoch 1488/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4695 - acc: 0.7920 - val_loss: 0.4921 - val_acc: 0.7945\n",
            "Epoch 1489/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.7820 - val_loss: 0.4872 - val_acc: 0.7794\n",
            "Epoch 1490/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4715 - acc: 0.7836 - val_loss: 0.4896 - val_acc: 0.7820\n",
            "Epoch 1491/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4688 - acc: 0.7794 - val_loss: 0.4936 - val_acc: 0.7719\n",
            "Epoch 1492/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4709 - acc: 0.7861 - val_loss: 0.4861 - val_acc: 0.7794\n",
            "Epoch 1493/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4714 - acc: 0.7886 - val_loss: 0.4860 - val_acc: 0.7794\n",
            "Epoch 1494/10000\n",
            "1197/1197 [==============================] - 0s 75us/step - loss: 0.4696 - acc: 0.7861 - val_loss: 0.5044 - val_acc: 0.7644\n",
            "Epoch 1495/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4681 - acc: 0.7903 - val_loss: 0.5296 - val_acc: 0.7769\n",
            "Epoch 1496/10000\n",
            "1197/1197 [==============================] - 0s 87us/step - loss: 0.4695 - acc: 0.7886 - val_loss: 0.4877 - val_acc: 0.7845\n",
            "Epoch 1497/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4703 - acc: 0.7878 - val_loss: 0.4847 - val_acc: 0.7945\n",
            "Epoch 1498/10000\n",
            "1197/1197 [==============================] - 0s 76us/step - loss: 0.4738 - acc: 0.7769 - val_loss: 0.4959 - val_acc: 0.7820\n",
            "Epoch 1499/10000\n",
            "1197/1197 [==============================] - 0s 78us/step - loss: 0.4718 - acc: 0.7794 - val_loss: 0.5031 - val_acc: 0.7794\n",
            "Epoch 1500/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4729 - acc: 0.7820 - val_loss: 0.4989 - val_acc: 0.7744\n",
            "Epoch 1501/10000\n",
            "1197/1197 [==============================] - 0s 74us/step - loss: 0.4714 - acc: 0.7853 - val_loss: 0.5393 - val_acc: 0.7769\n",
            "Epoch 1502/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4710 - acc: 0.7870 - val_loss: 0.5083 - val_acc: 0.7669\n",
            "Epoch 1503/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4704 - acc: 0.7945 - val_loss: 0.5062 - val_acc: 0.7719\n",
            "Epoch 1504/10000\n",
            "1197/1197 [==============================] - 0s 73us/step - loss: 0.4713 - acc: 0.7928 - val_loss: 0.4990 - val_acc: 0.7870\n",
            "Epoch 1505/10000\n",
            "1197/1197 [==============================] - 0s 72us/step - loss: 0.4696 - acc: 0.7870 - val_loss: 0.4944 - val_acc: 0.7820\n",
            "Epoch 1506/10000\n",
            "1197/1197 [==============================] - 0s 71us/step - loss: 0.4742 - acc: 0.7820 - val_loss: 0.4901 - val_acc: 0.7794\n",
            "Epoch 01506: early stopping\n",
            "Train: 0.791, Test: 0.779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9x6FQOc63Zr",
        "colab_type": "code",
        "outputId": "7ac2e1b3-f9e7-443b-953d-b3aae63a225f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Accuracy :',score)\n",
        "print('Time taken :' , time.time()-t0)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7888691953208082\n",
            "Time taken : 528.2063782215118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M70w7aMZ8iml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report # To get models info."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg-SFaYE7S4A",
        "colab_type": "code",
        "outputId": "474594ff-1bb9-4cd9-926e-c5d62eddd662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Confusion matrix_train_acc, _test_acc\n",
        "y_train_acc = [2, 0, 2, 2, 0, 1]\n",
        "y_test_acc = [0, 0, 2, 2, 0, 2]\n",
        "(y_train_acc, y_test_acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 0, 2, 2, 0, 1], [0, 0, 2, 2, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}